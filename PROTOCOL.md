# Spec-Driven Protocol (SDP) v0.3.0

Workstream-driven development protocol for AI agents with structured, one-shot execution.

---

> **ğŸ“ Meta-note:** This protocol was developed through AI-assisted iteration. The workflow described here reflects real experience, not theoretical design.

---

## Navigation

```
Need to...                            â†’  Use Command
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Gather requirements                   â†’  /idea or @idea
Design workstreams                    â†’  /design or @design
Execute a workstream                  â†’  /build or @build
Review quality                        â†’  /review or @review
Deploy to production                  â†’  /deploy or @deploy
Fix bugs                              â†’  /bugfix or @bugfix
Emergency fix (P0)                    â†’  /hotfix or @hotfix
Debug and route issues                â†’  /issue or @issue
Autonomous execution (Task-based)     â†’  /oneshot or @oneshot
See code patterns                     â†’  CODE_PATTERNS.md
Check the rules                       â†’  Guardrails (below)
Understand principles                 â†’  docs/PRINCIPLES.md
Project-specific rules                â†’  PROJECT_CONVENTIONS.md
```

---

## Command Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /idea   â”‚â”€â”€â†’â”‚ /design  â”‚â”€â”€â†’â”‚  /build  â”‚â”€â”€â†’â”‚ /review  â”‚â”€â”€â†’â”‚ /deploy  â”‚
â”‚  @idea   â”‚   â”‚ @design  â”‚   â”‚  @build  â”‚   â”‚ @review  â”‚   â”‚ @deploy  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚              â”‚              â”‚              â”‚              â”‚
     â–¼              â–¼              â–¼              â–¼              â–¼
  Draft         Workstreams      Code         Quality      Production
```

**Commands:**
- `/idea` â€” Requirements gathering â†’ `docs/drafts/`
- `/design` â€” Create workstreams â†’ `docs/workstreams/backlog/`
- `/build` â€” Execute workstream â†’ code + tests
- `/review` â€” Quality check â†’ APPROVED/CHANGES_REQUESTED
- `/deploy` â€” Production deployment â†’ Docker, CI/CD, release notes

**Alternative:**
- `/oneshot` â€” Autonomous execution of entire feature via Task tool orchestrator
  - Spawns isolated agent with TodoWrite progress tracking
  - Supports background execution (`--background`)
  - Resume capability via agent_id (`--resume {id}`)
  - Executes all workstreams with PR approval gate

---

## Terminology

| Term | Scope | Size | Example |
|------|-------|------|---------|
| **Release** | Product milestone | 10-30 Features | R1: MVP |
| **Feature** | Large capability | 5-30 Workstreams | F1: User Auth |
| **Workstream (WS)** | Atomic task | SMALL/MEDIUM/LARGE | WS-001: Domain entities |

**Scope metrics for Workstream:**
- **SMALL**: < 500 LOC, < 1500 tokens
- **MEDIUM**: 500-1500 LOC, 1500-5000 tokens
- **LARGE**: > 1500 LOC â†’ split into 2+ WS

### NO TIME-BASED ESTIMATES

**FORBIDDEN to use time for estimation:**
- "This will take 2 hours"
- "Need 3 days"
- "Won't finish this week"
- "No time for this"
- "This takes too long"

**USE scope metrics:**
- "This is MEDIUM workstream (1000 LOC, 3000 tokens)"
- "Scope exceeded, need to split into 2 WS"
- "By scope this is SMALL task"

#### Permitted Time References (Exceptions)

Time **is allowed** only in these cases (and **is not a scope estimate**):

- **Telemetry / measurements**: elapsed time, timestamps in logs, execution metrics (e.g., `"elapsed": "1h 23m"`)
- **SLA / operational targets**: hotfix/bugfix target windows (e.g., "P0 hotfix: <2h", "P1/P2 bugfix: <24h")
- **Human Verification (UAT)**: guidance for human testers ("Smoke test: 30 sec", "Scenarios: 5-10 min")

In all other contexts **time is forbidden** â€” use only LOC/tokens and sizing (SMALL/MEDIUM/LARGE).

**Why NOT time:**
1. AI agents work at different speeds (Sonnet â‰  Haiku â‰  GPT)
2. Scope is objective (LOC, tokens), time is subjective
3. Time creates false pressure ("running out of time" â†’ rushing â†’ bugs)
4. One-shot execution: agent completes WS in one pass, regardless of "time"

### Hierarchy (Product)

```
VISION.md (product vision)
    â†“
RELEASE_PLAN.md (releases)
    â†“
Feature (F01-F99) â€” large capabilities
    â†“
Workstream (WS-001-WS-999) â€” atomic tasks
```

### Deprecated Terms

- ~~Epic (EP)~~ â†’ **Feature (F)** (since 2026-01-07)
- ~~Sprint~~ â†’ not used
- ~~Phase 1-4 workflow~~ â†’ **Slash commands** (since 2026-01-12)

---

## Guardrails

### AI-Readiness (BLOCKING)

| Rule | Threshold | Check |
|------|-----------|-------|
| File size | < 200 LOC | `wc -l` |
| Complexity | CC < 10 | `ruff --select=C901` |
| Type hints | 100% public | mypy --strict |
| Nesting | â‰¤ 3 levels | Visual |

### Clean Architecture (BLOCKING)

```
Domain      â†’  Does NOT import from other layers
Application â†’  Does NOT import infrastructure directly
```

```bash
# Check for violations
grep -r "from infrastructure" domain/ application/
# Should be empty
```

**See**: [docs/PRINCIPLES.md](docs/PRINCIPLES.md) | [docs/concepts/clean-architecture/](docs/concepts/clean-architecture/README.md)

### Error Handling (BLOCKING)

```python
# FORBIDDEN
except:
    pass

except Exception:
    return None

# REQUIRED
except SpecificError as e:
    log.error("operation.failed", error=str(e), exc_info=True)
    raise
```

### Security

- [ ] No `privileged: true`
- [ ] No `/var/run/docker.sock` mounts
- [ ] Resource limits defined
- [ ] No string interpolation in shell commands

---

## Quality Gates

### Gate 1: idea â†’ design
- [ ] Requirements clear and complete
- [ ] Success criteria defined
- [ ] Non-goals identified

### Gate 2: design â†’ build
- [ ] **WS does not exist** in INDEX (verified)
- [ ] **Scope estimated**, not exceeding MEDIUM
- [ ] Dependencies identified
- [ ] Acceptance criteria include: tests + coverage + regression
- [ ] **NO time estimates** (hours/days)
- [ ] DO/DON'T rules defined (from PROJECT_CONVENTIONS.md)

### Gate 3: build â†’ review
- [ ] All acceptance criteria met
- [ ] **Coverage â‰¥ 80%** for changed files
- [ ] **Regression passed** (all tests)
- [ ] **No TODO/FIXME** in code
- [ ] Execution report filled

### Gate 4: review â†’ deploy
- [ ] AI-Readiness: âœ…
- [ ] Clean Architecture: âœ…
- [ ] Error Handling: âœ…
- [ ] Tests & Coverage: âœ… (â‰¥80%)
- [ ] Regression: âœ… (all tests)
- [ ] DO/DON'T rules followed: âœ…

### Gate 5: deploy â†’ production (Human UAT)

**UAT (User Acceptance Testing)** â€” human verification before deploy:

| Step | Description | Time |
|------|-------------|------|
| 1 | Quick Smoke Test | 30 sec |
| 2 | Detailed Scenarios (happy path + errors) | 5-10 min |
| 3 | Red Flags Check | 2 min |
| 4 | Sign-off | 1 min |

**UAT Guide created automatically** after `/review` returns APPROVED:
- Feature-level: `docs/uat/F{XX}-uat-guide.md`
- WS-level: "Human Verification (UAT)" section in WS file

**Without human Sign-off â†’ Deploy blocked.**

---

## WS Scope Control

**Size metrics (instead of time):**

| Size | Lines of Code | Tokens | Action |
|------|---------------|--------|--------|
| **SMALL** | < 500 | < 1500 | âœ… Optimal |
| **MEDIUM** | 500-1500 | 1500-5000 | âœ… Acceptable |
| **LARGE** | > 1500 | > 5000 | âŒ **SPLIT** |

**Rule:** All WS must be SMALL or MEDIUM.

**If scope exceeded during /build:**
â†’ STOP, use `/design` to split into WS-XXX-01, WS-XXX-02

---

## Test Coverage Gate

**Minimum:** 80% for changed/created files

```bash
pytest tests/unit/test_module.py -v \
  --cov=src/module \
  --cov-report=term-missing \
  --cov-fail-under=80
```

**If coverage < 80% â†’ CHANGES REQUESTED (HIGH)**

---

## Regression Gate

**After each /build:**

```bash
# All tests MUST pass
pytest tests/
```

**If regression broken â†’ CHANGES REQUESTED (CRITICAL)**

---

## TODO/Later Gate

**STRICTLY FORBIDDEN in code:**
- `# TODO: ...`
- `# FIXME: ...`
- Comments like "will do later", "temporary solution"

**Exception:** `# NOTE:` â€” only for clarifications

**If found â†’ CHANGES REQUESTED (HIGH)**

---

## NO TECH DEBT

**The Tech Debt concept is FORBIDDEN in this protocol.**

- "This is tech debt, we'll do it later"
- "Temporary solution, will return later"
- "Dirty code but it works"
- "Postpone refactoring"

âœ… **Rule: fix all issues immediately.**

**If code doesn't meet standards:**
1. Fix in current WS
2. If scope exceeded â†’ split into substreams (see below)
3. DO NOT leave "for later"

**Philosophy:** Every WS leaves code in ideal state. No accumulating debt.

---

## Substreams: Splitting Rules

**If WS needs to be split:**

### Numbering Format (STRICT)

```
WS-{PARENT_ID}-{SEQ}

Where:
- PARENT_ID = parent WS ID (3 digits with leading zeros)
- SEQ = substream sequence number (2 digits: 01, 02, ... 99)
```

**Examples:**
```
WS-050         â† parent (being split)
â”œâ”€â”€ WS-050-01  â† first substream
â”œâ”€â”€ WS-050-02  â† second substream
â”œâ”€â”€ WS-050-03  â† third substream
â”œâ”€â”€ ...
â”œâ”€â”€ WS-050-10  â† tenth (sorting works!)
â””â”€â”€ WS-050-15  â† fifteenth
```

**FORBIDDEN formats:**
```
âŒ WS-050-A, WS-050-B      (letters)
âŒ WS-050-part1            (words)
âŒ WS-050.1, WS-050.2      (dots)
âŒ WS-50-1                 (no leading zeros in PARENT)
âŒ WS-050-1                (single-digit SEQ â€” always 01, 02...)
```

### REQUIRED when splitting:

1. **Create ALL substream files** in `docs/workstreams/backlog/`:
   ```
   WS-050-01-domain-entities.md
   WS-050-02-application-layer.md
   WS-050-03-infrastructure.md
   ```

2. **Fill each substream** completely (not stub):
   - Goal
   - Context
   - Dependencies (WS-XXX-01 â†’ WS-XXX-02 â†’ ...)
   - Acceptance criteria
   - DO/DON'T rules (from PROJECT_CONVENTIONS.md)
   - Test plan

3. **Update INDEX.md** with new WS

4. **Delete or mark parent WS** as "Split â†’ WS-XXX-01, WS-XXX-02"

### FORBIDDEN:

- Referencing non-existent WS ("see WS-050-02" without creating file)
- Leaving empty stubs ("TODO: fill in")
- Splitting without creating files
- Partial execution ("did part, rest in another WS")
- Formats: `24.1`, `WS-24-1`, `WS-050-1`, `WS-050-part1`
- Time estimates: "0.5 days", "3 days" â€” only LOC/tokens

---

## ADR Template

When making an architectural decision, create:

`docs/adr/YYYY-MM-DD-{title}.md`

```markdown
# ADR: {Title}

## Status
Proposed / Accepted / Deprecated

## Context
[What is the problem? What constraints?]

## Decision
[What did we decide to do?]

## Alternatives Considered
1. [Alternative 1] â€” why not
2. [Alternative 2] â€” why not

## Consequences
- [+] Benefit
- [-] Drawback
- [!] Risk
```

---

## Workstream Format

See `templates/workstream.md` for complete template with DO/DON'T blocks.

**Essential sections:**
```markdown
# Workstream: {Title}

**ID:** WS-XXX-YY
**Feature:** F-XXX
**Status:** READY/EXECUTING/DONE
**Complexity:** SMALL/MEDIUM/LARGE

## Goal
[Clear, one-sentence goal]

## Context
[Why this workstream exists]

## Dependencies
- [ ] WS-XXX-YY: [Description]

## Acceptance Criteria
- [ ] Criterion 1
- [ ] Coverage â‰¥ 80%
- [ ] Type hints complete
- [ ] No TODO/FIXME
- [ ] Clean Architecture followed

## DO / DON'T
### Architecture
âœ… DO: ...
âŒ DON'T: ...

### Code Quality
âœ… DO: ...
âŒ DON'T: ...

[See templates/workstream.md for full template]
```

---

## Documentation Hierarchy (C4-like)

```
L1: System      docs/SYSTEM_OVERVIEW.md
    â†“ General system context, boundaries, main domains

L2: Domain      docs/domains/{domain}/DOMAIN_MAP.md
    â†“ Domain structure, components, integrations

L3: Component   docs/domains/{domain}/components/{comp}/SPEC.md
    â†“ Detailed component specification

L4: Workstream  docs/workstreams/{status}/WS-XXX.md
    â†“ Specific task for execution
```

### Navigation Flow

**Using /idea:**
1. User describes feature
2. AI uses AskUserQuestion for deep requirements gathering (Claude Code)
3. AI reads L1 (`SYSTEM_OVERVIEW.md`) for context
4. AI generates comprehensive draft in `docs/drafts/idea-{slug}.md`

**Using /design:**
1. AI reads idea draft
2. AI enters Plan Mode (Claude Code: EnterPlanMode) for codebase exploration
3. AI uses AskUserQuestion for architecture decisions
4. AI reads L1/L2 for architecture context
5. AI reads `docs/workstreams/INDEX.md` to avoid duplicates
6. AI requests approval via ExitPlanMode (Claude Code)
7. AI generates workstreams (L4) in `docs/workstreams/backlog/`

**Using /build:**
1. AI creates TodoWrite list for progress tracking
2. AI reads workstream file (L4)
3. AI reads L1/L2/L3 for context
4. AI executes workstream according to plan (TDD: Red â†’ Green â†’ Refactor)
5. AI updates TodoWrite throughout execution
6. AI moves WS to `docs/workstreams/completed/`

**Using /review:**
1. AI reads all completed WS for feature
2. AI checks quality gates (AI-Readiness, Clean Architecture, Coverage, etc.)
3. AI generates review report with verdict: APPROVED or CHANGES REQUESTED

**Using /oneshot:**
1. Main AI spawns Task tool orchestrator agent
2. Agent creates TodoWrite list for high-level tracking
3. Agent waits for PR approval (gate)
4. Agent executes each WS using /build (with internal TodoWrite)
5. Agent runs /review after all WS complete
6. Agent generates UAT guide
7. Agent returns summary to main AI

### Product vs Architecture Hierarchy

**Product (feature planning):**
```
VISION.md â†’ RELEASE_PLAN.md â†’ Feature (F) â†’ Workstream (WS)
```

**Architecture (code/documentation structure):**
```
L1 (System) â†’ L2 (Domain) â†’ L3 (Component) â†’ L4 (Workstream)
```

**Intersection:**
- Feature F24 â†’ creates/modifies L2 (content domain)
- Workstream WS-140 â†’ creates L3 (vault component)

---

## Core Principles

All work must follow these principles. See [docs/PRINCIPLES.md](docs/PRINCIPLES.md) for details.

| Principle | Summary |
|-----------|---------|
| **SOLID** | SRP, OCP, LSP, ISP, DIP |
| **DRY** | Don't Repeat Yourself |
| **KISS** | Keep It Simple, Stupid |
| **YAGNI** | You Ain't Gonna Need It |
| **TDD** | Tests first (Red â†’ Green â†’ Refactor) |
| **Clean Code** | Readable, maintainable, testable |
| **Clean Architecture** | Dependencies point inward |

---

## Project Conventions

**Every project must define:**

`PROJECT_CONVENTIONS.md` â€” Project-specific DO/DON'T rules

**Sections:**
- Language & Communication
- Code Style (formatters, linters)
- Architecture (layer boundaries)
- Naming Conventions
- Testing (coverage, mocking)
- Error Handling
- Git Workflow
- Documentation
- Security
- Performance
- Project-Specific DO/DON'T

See `templates/PROJECT_CONVENTIONS.md` for template.

---

## Quick Reference

```bash
# AI-Readiness check
find src -name "*.py" -exec wc -l {} + | awk '$1 > 200'
ruff check src --select=C901
mypy src --strict

# Clean Architecture check
grep -r "from infrastructure" domain/ application/

# Error handling check
grep -rn "except:" src/
grep -rn "except Exception" src/ | grep -v "exc_info"

# Test coverage (â‰¥80%)
pytest tests/unit/test_module.py -v \
  --cov=src/module \
  --cov-report=term-missing \
  --cov-fail-under=80

# Regression (all tests)
pytest tests/

# TODO/Later check
grep -rn "TODO\|FIXME" src/ --include="*.py" | grep -v "# NOTE"

# Full test suite with coverage
pytest --cov=src --cov-report=term-missing
```

---

## Observability

### Telegram Notifications

Automated notifications for critical events:

```bash
# Setup
export TELEGRAM_BOT_TOKEN="..."
export TELEGRAM_CHAT_ID="..."

# Events: oneshot_started, oneshot_completed, oneshot_blocked,
#         ws_failed, review_failed, breaking_changes, e2e_failed,
#         deploy_success, hotfix_deployed
```

See: `notifications/TELEGRAM.md`

### Audit Log

Centralized logging of all workflow events:

```bash
# Configuration
export AUDIT_LOG_FILE="/var/log/sdp-audit.log"

# Format: ISO8601|EVENT_TYPE|USER|GIT_BRANCH|EVENT_DATA
# Example:
# 2026-01-11T00:30:15+03:00|WS_START|user|feature/lms|ws=WS-060-01

# Query
grep "feature=F60" /var/log/sdp-audit.log
grep "WS_FAILED" /var/log/sdp-audit.log
```

See: `notifications/AUDIT_LOG.md`

### Breaking Changes Detection

Automatic detection and documentation:

```bash
# Runs in pre-commit hook
python scripts/detect_breaking_changes.py --staged

# Generates:
# - BREAKING_CHANGES.md
# - MIGRATION_GUIDE.md (template)
```

---

## Git Hooks

Automatic validation via hooks (see `hooks/`):

| Hook | Purpose |
|------|---------|
| `pre-commit.sh` | Linting, tests, no secrets |
| `commit-msg.sh` | Conventional commit format |
| `pre-build.sh` | WS exists, dependencies satisfied |
| `post-build.sh` | Tests pass, coverage â‰¥80%, no TODO |
| `pre-deploy.sh` | All tests pass, UAT signed-off |
| `post-oneshot.sh` | Session quality, checkpoint saved |

Install: `python scripts/init.py` (interactive setup)

---

## Resources

| Resource | Purpose |
|----------|---------|
| [README.md](README.md) | Quick start and overview |
| [CLAUDE.md](CLAUDE.md) | Claude Code integration |
| [docs/guides/CURSOR.md](docs/guides/CURSOR.md) | Cursor IDE integration |
| [docs/guides/CLAUDE_CODE.md](docs/guides/CLAUDE_CODE.md) | Claude Code detailed guide |
| [docs/PRINCIPLES.md](docs/PRINCIPLES.md) | SOLID, DRY, KISS, YAGNI, Clean Code |
| [docs/concepts/](docs/concepts/README.md) | Clean Architecture, Artifacts, Roles |
| [CODE_PATTERNS.md](CODE_PATTERNS.md) | Implementation patterns |
| [MODELS.md](MODELS.md) | AI model recommendations |
| [RULES_COMMON.md](RULES_COMMON.md) | Common rules for all work |
| [PROJECT_CONVENTIONS.md](PROJECT_CONVENTIONS.md) | Project-specific DO/DON'T (fill this!) |
| [prompts/commands/](prompts/commands/) | Slash command instructions |
| [templates/](templates/) | Document templates |

---

**Version:** 0.3.0  
**Last Updated:** 2026-01-12  
**Status:** Active
