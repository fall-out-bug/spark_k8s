{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Quick Start: Spark + Pandas-like UX\n",
        "\n",
        "–≠—Ç–æ—Ç notebook –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ JupyterHub —Å–æ Spark 3.5.7.\n",
        "–í—Å–µ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –∏ –≥–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
        "\n",
        "–í—Å–µ –æ–±—ä–µ–∫—Ç—ã —É–∂–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ kernel.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –≥–æ—Ç–æ–≤–æ\n",
        "print(f\"Spark version: {spark.version}\")\n",
        "print(f\"Spark master: {spark.sparkContext.master}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Pandas-like –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ Spark DataFrame\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º `display_spark_df()` –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–∞–∫ –≤ pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π DataFrame\n",
        "test_data = [\n",
        "    Row(id=1, name=\"Alice\", value=100, category=\"A\"),\n",
        "    Row(id=2, name=\"Bob\", value=200, category=\"B\"),\n",
        "    Row(id=3, name=\"Charlie\", value=300, category=\"A\"),\n",
        "    Row(id=4, name=\"David\", value=150, category=\"C\"),\n",
        "    Row(id=5, name=\"Eve\", value=250, category=\"B\"),\n",
        "]\n",
        "df = spark.createDataFrame(test_data)\n",
        "\n",
        "# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ pandas\n",
        "display_spark_df(df, n=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ pandas –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "\n",
        "–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ª–∏–º–∏—Ç–æ–º —Å—Ç—Ä–æ–∫.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ pandas (–±–µ–∑–æ–ø–∞—Å–Ω–æ, —Å –ª–∏–º–∏—Ç–æ–º)\n",
        "df_pd = to_pandas_safe(df, max_rows=1000)\n",
        "\n",
        "print(f\"Converted to pandas: {len(df_pd)} rows\")\n",
        "display(df_pd.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å seaborn –∏ plotly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seaborn –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_pd, x=\"category\", y=\"value\")\n",
        "plt.title(\"Value by category\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotly –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter(df_pd, x=\"id\", y=\"value\", color=\"category\",\n",
        "                title=\"Interactive scatter plot\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –†–∞–±–æ—Ç–∞ —Å S3 (MinIO)\n",
        "\n",
        "–ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ S3-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ S3\n",
        "s3_path = \"s3a://data-lake/bronze/test-data\"\n",
        "write_s3_parquet(df, s3_path, mode=\"overwrite\")\n",
        "print(f\"‚úÖ Data written to {s3_path}\")\n",
        "\n",
        "# –ß–∏—Ç–∞–µ–º –∏–∑ S3\n",
        "df_read = read_s3_parquet(spark, s3_path)\n",
        "print(f\"‚úÖ Data read from {s3_path}\")\n",
        "display_spark_df(df_read, n=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ì–æ—Ç–æ–≤–æ! üéâ\n",
        "\n",
        "–¢–µ–ø–µ—Ä—å –≤—ã –º–æ–∂–µ—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–∞–Ω–Ω—ã–º–∏ –∫–∞–∫ —Å pandas, –Ω–æ –Ω–∞ Spark!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
