# Persistent Spark Infrastructure for minikube
# Namespace: spark-infra (NEVER delete this namespace)
# Components: MinIO + Hive Metastore + PostgreSQL + History Server
# Usage: helm install spark-infra charts/spark-3.5 -f charts/spark-3.5/presets/spark-infra.yaml -n spark-infra

global:
  s3:
    endpoint: "http://minio.spark-infra.svc.cluster.local:9000"
    accessKey: "minioadmin"
    secretKey: "minioadmin"
    pathStyleAccess: true
    sslEnabled: false
  postgresql:
    host: "spark-infra-spark-base-postgresql.spark-infra.svc.cluster.local"
    port: 5432
    user: "postgres"
    password: "spark123"

# Enable base infrastructure components
spark-base:
  enabled: true
  minio:
    enabled: true
    persistence:
      enabled: true
      size: "30Gi"  # Larger for persistent data
    buckets:
      - raw-data        # Input datasets for load tests
      - processed-data  # Results from transformations
      - checkpoint      # Spark checkpointing
      - warehouse       # Hive/Iceberg warehouse
      - spark-logs      # Spark event logs
    resources:
      requests:
        cpu: "200m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "2Gi"
    service:
      type: ClusterIP
      port: 9000
      consolePort: 9001

  postgresql:
    enabled: true
    auth:
      username: postgres
      password: spark123
      database: spark_db
    databases:
      - spark_db
    # md5 required for Hive 3.1.x JDBC driver (does not support SCRAM-SHA-256)
    authMethod: "md5"
    primary:
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "1Gi"
          cpu: "500m"
    persistence:
      enabled: true
      size: "5Gi"

# RBAC: create SA for hive-metastore and history-server pods
rbac:
  create: true
  serviceAccountName: "spark-35"

connect:
  enabled: false

jupyter:
  enabled: false

airflow:
  enabled: false

sparkStandalone:
  enabled: false

jupyterGateway:
  enabled: false

sparkOperator:
  enabled: false

# Hive Metastore with S3 warehouse (build: docker/hive with HIVE_VERSION=3.1.3)
hiveMetastore:
  enabled: true
  image:
    repository: spark-k8s/hive
    tag: "3.1.3-pg"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/"
  database:
    name: "spark_db"
  postgresql:
    enabled: false  # Use Postgres from spark-base in same release
    host: "spark-infra-spark-base-postgresql.spark-infra.svc.cluster.local"
    port: 5432
    database: "spark_db"
    username: "postgres"
    password: "spark123"
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# History Server (build: docker/spark-custom Dockerfile.3.5.7 â†’ spark-custom:3.5.7-new)
historyServer:
  enabled: true
  sparkVersion: "3.5.7"
  image:
    repository: spark-custom
    tag: "3.5.7-new"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 18080
  # Use MinIO for logs (requires hadoop-aws jars)
  logDirectory: "s3a://spark-logs/events"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Ingress for local access (optional)
ingress:
  enabled: false

# Security settings for Minikube
security:
  podSecurityStandards: false

# Monitoring: Grafana dashboards (ConfigMaps); deploy OTEL collector + Grafana separately (see scripts/tests/minikube/deploy-observability.sh)
monitoring:
  enabled: true
  grafanaDashboards:
    enabled: true
    namespace: ""  # release namespace
