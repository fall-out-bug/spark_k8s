# Persistent Spark Infrastructure for minikube
# Namespace: spark-infra (NEVER delete this namespace)
# Components: MinIO + Hive Metastore + PostgreSQL + History Server
# Usage: helm install spark-infra charts/spark-3.5 -f charts/spark-3.5/presets/spark-infra.yaml -n spark-infra

global:
  s3:
    endpoint: "http://minio.spark-infra.svc.cluster.local:9000"
    accessKey: "minioadmin"
    secretKey: "minioadmin"
    pathStyleAccess: true
    sslEnabled: false

# Enable base infrastructure components
spark-base:
  enabled: true
  minio:
    enabled: true
    persistence:
      enabled: true
      size: "30Gi"  # Larger for persistent data
    buckets:
      - raw-data        # Input datasets for load tests
      - processed-data  # Results from transformations
      - checkpoint      # Spark checkpointing
      - warehouse       # Hive/Iceberg warehouse
      - spark-logs      # Spark event logs
    resources:
      requests:
        cpu: "200m"
        memory: "512Mi"
      limits:
        cpu: "1000m"
        memory: "2Gi"
    service:
      type: ClusterIP
      port: 9000
      consolePort: 9001

  postgresql:
    enabled: true
    auth:
      username: postgres
      password: spark123
      database: spark_db
    primary:
      resources:
        requests:
          memory: "256Mi"
          cpu: "100m"
        limits:
          memory: "1Gi"
          cpu: "500m"
    persistence:
      enabled: true
      size: "5Gi"

# Disable Spark components
rbac:
  create: false

connect:
  enabled: false

jupyter:
  enabled: false

airflow:
  enabled: false

sparkStandalone:
  enabled: false

jupyterGateway:
  enabled: false

sparkOperator:
  enabled: false

# Hive Metastore with S3 warehouse
hiveMetastore:
  enabled: true
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/"
  database:
    name: "spark_db"
  postgresql:
    enabled: false  # Use global Postgres
    host: "postgresql.spark-infra.svc.cluster.local"
    port: 5432
    database: "spark_db"
    username: "postgres"
    password: "spark123"
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
    persistence:
      enabled: true  # Store metastore DB on disk

# History Server
historyServer:
  enabled: true
  sparkVersion: "3.5.7"
  service:
    type: ClusterIP
    port: 18080
  # Use MinIO for logs (requires hadoop-aws jars)
  logDirectory: "s3a://spark-logs/"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
    persistence:
      enabled: false  # Logs stored in MinIO

# Ingress for local access (optional)
ingress:
  enabled: false

# Security settings for Minikube
security:
  podSecurityStandards: false

# Monitoring
monitoring:
  enabled: false  # Can be enabled later
