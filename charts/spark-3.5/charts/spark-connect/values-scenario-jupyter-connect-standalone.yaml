# Preset: Jupyter + Spark Connect + Standalone backend
# Source: scripts/test-e2e-jupyter-connect.sh (Spark 3.5, BACKEND_MODE=standalone)
# Components: Connect + Jupyter + MinIO + Standalone
# Note: Requires standalone master to be deployed separately

s3:
  endpoint: "http://minio:9000"
  accessKey: "minioadmin"
  secretKey: "minioadmin"
  pathStyleAccess: true

serviceAccount:
  create: true
  name: spark

rbac:
  create: true

sparkConnect:
  enabled: true
  backendMode: standalone
  image:
    repository: spark-custom
    tag: "3.5.7"
    pullPolicy: IfNotPresent
  resources:
    requests:
      cpu: "50m"
      memory: "1Gi"
    limits:
      cpu: "500m"
      memory: "3Gi"
  driver:
    host: ""  # Set to "spark-connect.<namespace>.svc.cluster.local"
  standalone:
    masterService: "spark-sa-spark-standalone-master"
    masterPort: 7077
  # Fixed executor instances for standalone backend
  sparkConf:
    spark.executor.instances: "1"
    spark.executor.cores: "1"
    spark.executor.memory: "1g"
    spark.dynamicAllocation.enabled: "false"

jupyter:
  enabled: true
  service:
    type: ClusterIP
  resources:
    requests:
      cpu: "100m"
      memory: "256Mi"
    limits:
      cpu: "500m"
      memory: "1Gi"

jupyterhub:
  enabled: false

historyServer:
  enabled: false

hiveMetastore:
  enabled: false

postgresql:
  enabled: false

minio:
  enabled: true
  persistence:
    enabled: false
  resources:
    requests:
      cpu: "50m"
      memory: "128Mi"
    limits:
      cpu: "200m"
      memory: "512Mi"

security:
  podSecurityStandards: false
