{{- if .Values.hiveMetastore.enabled }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "spark-standalone.fullname" . }}-hive-metastore-config
  labels:
    app: hive-metastore
    {{- include "spark-standalone.labels" . | nindent 4 }}
data:
  hive-site.xml: |
    <?xml version="1.0" encoding="UTF-8"?>
    <?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
    <configuration>
      <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:postgresql://{{ .Values.hiveMetastore.postgresql.host }}:{{ .Values.hiveMetastore.postgresql.port }}/{{ .Values.hiveMetastore.postgresql.database }}</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionDriverName</name>
        <value>org.postgresql.Driver</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionUserName</name>
        <value>{{ .Values.hiveMetastore.postgresql.username }}</value>
      </property>
      <property>
        <name>javax.jdo.option.ConnectionPassword</name>
        <value>{{ .Values.hiveMetastore.postgresql.password }}</value>
      </property>

      <property>
        <name>hive.metastore.uris</name>
        <!-- For the metastore server itself: bind/listen locally. Clients use Spark config. -->
        <value>thrift://0.0.0.0:{{ .Values.hiveMetastore.service.port }}</value>
      </property>
      <property>
        <name>hive.metastore.thrift.port</name>
        <value>{{ .Values.hiveMetastore.service.port }}</value>
      </property>
      <property>
        <name>hive.metastore.thrift.bind.host</name>
        <value>0.0.0.0</value>
      </property>
      <property>
        <name>hive.metastore.warehouse.dir</name>
        <value>{{ .Values.hiveMetastore.metastoreWarehouseDir }}</value>
      </property>

      <!-- Avoid touching warehouse FS on metastore startup (important for S3A setups). -->
      <property>
        <name>hive.metastore.checkForDefaultDb</name>
        <value>false</value>
      </property>

      <property>
        <name>datanucleus.schema.autoCreateAll</name>
        <!-- Schema is managed by `schematool` in the container command. -->
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.schema.validateTables</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.schema.validateColumns</name>
        <value>false</value>
      </property>
      <property>
        <name>datanucleus.schema.validateConstraints</name>
        <value>false</value>
      </property>
      <property>
        <name>hive.metastore.schema.verification</name>
        <value>false</value>
      </property>
    </configuration>
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "spark-standalone.fullname" . }}-metastore
  labels:
    app: hive-metastore
    {{- include "spark-standalone.labels" . | nindent 4 }}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: hive-metastore
      {{- include "spark-standalone.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        app: hive-metastore
        {{- include "spark-standalone.selectorLabels" . | nindent 8 }}
    spec:
      serviceAccountName: {{ include "spark-standalone.serviceAccountName" . }}
      {{- if .Values.security.podSecurityStandards }}
      securityContext:
        {{- include "spark-standalone.podSecurityContext" . | nindent 8 }}
      {{- end }}
      initContainers:
      - name: wait-for-postgresql
        image: busybox:1.36
        {{- if .Values.security.podSecurityStandards }}
        securityContext:
          {{- include "spark-standalone.containerSecurityContext" . | nindent 10 }}
          runAsUser: 1000
          runAsGroup: 1000
        {{- end }}
        command:
        - sh
        - -c
        - >
          until nc -z {{ .Values.hiveMetastore.postgresql.host }} {{ .Values.hiveMetastore.postgresql.port }};
          do echo "Waiting for PostgreSQL..."; sleep 2; done; echo "PostgreSQL is ready!"
      containers:
      - name: hive-metastore
        {{- if .Values.security.podSecurityStandards }}
        securityContext:
          {{- include "spark-standalone.containerSecurityContext" . | nindent 10 }}
          {{- with .Values.security.runAsUser }}
          runAsUser: {{ . }}
          {{- end }}
          {{- with .Values.security.runAsGroup }}
          runAsGroup: {{ . }}
          {{- end }}
        {{- end }}
        image: "{{ .Values.hiveMetastore.image.repository }}:{{ .Values.hiveMetastore.image.tag }}"
        imagePullPolicy: {{ .Values.hiveMetastore.image.pullPolicy }}
        env:
        - name: HIVE_CONF_DIR
          value: /opt/hive/conf
        command:
        - bash
        - -lc
        - |
          /opt/hive/bin/schematool -dbType postgres -initSchema --verbose 2>/dev/null || true
          exec /opt/hive/bin/hive --service metastore
        ports:
        - name: thrift
          containerPort: {{ .Values.hiveMetastore.service.port }}
        resources:
          {{- toYaml .Values.hiveMetastore.resources | nindent 10 }}
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: hive-config
          mountPath: /opt/hive/conf/hive-site.xml
          subPath: hive-site.xml
      volumes:
      - name: tmp
        emptyDir: {}
      - name: hive-config
        configMap:
          name: {{ include "spark-standalone.fullname" . }}-hive-metastore-config
---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "spark-standalone.fullname" . }}-metastore
  labels:
    app: hive-metastore
    {{- include "spark-standalone.labels" . | nindent 4 }}
spec:
  selector:
    app: hive-metastore
    {{- include "spark-standalone.selectorLabels" . | nindent 4 }}
  ports:
  - name: thrift
    port: {{ .Values.hiveMetastore.service.port }}
    targetPort: thrift
{{- end }}
