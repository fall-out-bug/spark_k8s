# Spark Standalone Helm Chart Values

# Global settings
global:
  imageRegistry: ""
  imagePullSecrets: []

# S3 credentials (MinIO or external S3)
s3:
  endpoint: "http://minio:9000"
  accessKey: "minioadmin"
  secretKey: "minioadmin"
  pathStyleAccess: true
  sslEnabled: false

# Spark History Server (typically separate component)
# Keep this section aligned with `charts/spark-platform` for easier shared values overlays.
historyServer:
  enabled: false
  # Used by Spark for event logging.
  logDirectory: "s3a://spark-logs/events"
  # Optional informational URL (used by shared `spark-env` compatibility keys)
  url: ""
  image:
    repository: spark-custom
    tag: "3.5.7"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 18080
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Optional informational Spark Connect URL (compatibility with `charts/spark-platform`)
sparkConnectServer: ""

# MinIO (S3-compatible storage) - optional for local/test
minio:
  enabled: true
  image:
    repository: quay.io/minio/minio
    tag: "latest"
    pullPolicy: IfNotPresent
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"
  persistence:
    enabled: true
    size: 10Gi
    storageClass: ""
  buckets:
    - warehouse
    - spark-logs
    - spark-standalone-logs
    - mlflow-artifacts
    - spark-jobs
    - raw-data
    - processed-data
    - checkpoints

# Standalone cluster (detailed in subsequent workstreams)
sparkMaster:
  enabled: true
  image:
    repository: spark-custom
    tag: "3.5.7"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    ports:
      spark: 7077
      webui: 8080
      rest: 6066
  ha:
    enabled: false
    # Spark Standalone HA uses `spark.deploy.recoveryMode=FILESYSTEM`, which requires a
    # POSIX-like filesystem path. `s3a://...` is NOT supported for master recovery state.
    # Use a PVC-backed directory here.
    # NOTE: this must be a plain filesystem path (no `file:` prefix).
    recoveryDir: "/opt/spark/recovery"
    persistence:
      enabled: true
      size: 1Gi
      storageClass: ""
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"

sparkWorker:
  enabled: true
  replicas: 2
  image:
    repository: spark-custom
    tag: "3.5.7"
    pullPolicy: IfNotPresent
  cores: 2
  memory: "2g"
  service:
    ports:
      worker: 7078
      webui: 8081
  resources:
    requests:
      memory: "2Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"

shuffleService:
  enabled: true
  image:
    repository: spark-custom
    tag: "3.5.7"
    pullPolicy: IfNotPresent
  port: 7337
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"

hiveMetastore:
  enabled: true
  image:
    # For local/test, use an off-the-shelf Hive image.
    # Prod typically uses an external metastore service.
    repository: apache/hive
    tag: "3.1.3"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  # `warehouseDir` is used by Spark SQL (and table locations). Keep it on S3 in local/test.
  warehouseDir: "s3a://warehouse/standalone"
  # The metastore service itself should not require S3A client jars.
  # Use a local path so metastore startup doesn't fail if the image lacks hadoop-aws.
  metastoreWarehouseDir: "file:/tmp/hive-warehouse"
  postgresql:
    enabled: true
    host: "postgresql-metastore"
    port: 5432
    database: "metastore_standalone"
    username: "hive"
    password: "hive123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  security:
    # Use numeric UID/GID for PSS runAsNonRoot (override for OpenShift UID ranges).
    runAsUser: 1000
    runAsGroup: 1000

airflow:
  enabled: true
  # Fernet key must be shared across all Airflow components (scheduler/webserver/worker pods),
  # otherwise Variables/Connections cannot be decrypted.
  # Generate with: python3 -c 'import os,base64; print(base64.urlsafe_b64encode(os.urandom(32)).decode())'
  fernetKey: ""
  kubernetesExecutor:
    # Delete ephemeral worker pods after completion (prod default).
    deleteWorkerPods: true
  image:
    repository: apache/airflow
    tag: "2.11.0-python3.11"
    pullPolicy: IfNotPresent
  webserver:
    service:
      type: ClusterIP
      port: 8080
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
  scheduler:
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits:
        memory: "2Gi"
        cpu: "1000m"
  auth:
    username: "admin"
    password: "admin"
  postgresql:
    enabled: true
    host: "postgresql-airflow"
    port: 5432
    database: "airflow"
    username: "airflow"
    password: "airflow123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  kubernetesExecutor:
    namespace: "" # defaults to .Release.Namespace
    workerImage:
      repository: ""
      tag: ""

mlflow:
  enabled: true
  image:
    repository: ghcr.io/mlflow/mlflow
    tag: "v2.14.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 5000
  artifactBucket: "mlflow-artifacts"
  postgresql:
    enabled: true
    host: "postgresql-mlflow"
    port: 5432
    database: "mlflow"
    username: "mlflow"
    password: "mlflow123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "256Mi"
      cpu: "100m"
    limits:
      memory: "1Gi"
      cpu: "500m"

ingress:
  enabled: true
  className: ""
  annotations: {}
  hosts:
    sparkMaster: "spark.local"
    airflow: "airflow.local"
    mlflow: "mlflow.local"
    historyServer: "history.local"
  tls: []

security:
  podSecurityStandards: true
  createNamespace: false
  # Embedded Postgres is only for local/test (prod uses external DB).
  # The official `postgres:16-alpine` image is not compatible with strict PSS `restricted`
  # hardening in many setups, so we run it in a relaxed mode by default.
  postgresql:
    relaxed: true

serviceAccount:
  create: true
  # Keep default aligned with `charts/spark-platform`
  name: spark
  annotations: {}

rbac:
  create: true
