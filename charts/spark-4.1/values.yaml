global:
  imagePullSecrets: []
  s3:
    endpoint: "http://minio:9000"
    accessKey: "minioadmin"
    secretKey: "minioadmin"
    pathStyleAccess: true
    sslEnabled: false
    existingSecret: "s3-credentials"
  postgresql:
    host: "postgresql-metastore-41"
    port: 5432
    user: "hive"
    password: "hive123"

spark-base:
  enabled: true
  serviceAccount:
    create: false
    name: spark
  rbac:
    create: false
  minio:
    enabled: false
  postgresql:
    enabled: false
  security:
    podSecurityStandards: false

rbac:
  create: true
  serviceAccountName: "spark-41"

# Spark Connect server (4.1.0)
connect:
  enabled: true
  replicas: 1
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 15002
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
  driver:
    host: ""
    port: 7078
    blockManagerPort: 7079
  # Backend mode: "k8s" or "standalone"
  # k8s: dynamic executor pods created on demand (recommended)
  # standalone: submit to existing Spark Standalone master/workers
  backendMode: "k8s"
  # Standalone backend configuration (used when backendMode=standalone)
  standalone:
    masterService: "spark-sa-spark-standalone-master"
    masterPort: 7077
  executor:
    cores: "1"
    coresLimit: "2"
    memory: "1Gi"
    memoryLimit: "2Gi"
  dynamicAllocation:
    enabled: true
    minExecutors: 0
    maxExecutors: 10
  eventLog:
    enabled: true
    dir: "s3a://spark-logs/4.1/events"
  sparkConf: {}

# Hive Metastore 4.0.0 (separate instance for Spark 4.1.0)
hiveMetastore:
  enabled: true
  image:
    repository: apache/hive
    tag: "4.0.0"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/spark-41"
  metastoreWarehouseDir: "file:/tmp/hive-warehouse"
  database:
    name: "metastore_spark41"
  postgresql:
    enabled: true
    host: "postgresql-metastore-41"
    port: 5432
    database: "metastore_spark41"
    username: "hive"
    password: "hive123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# History Server 4.1.0
historyServer:
  enabled: true
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  logDirectory: "s3a://spark-logs/4.1/events"
  service:
    type: ClusterIP
    port: 18080
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Ingress
ingress:
  enabled: false
  hosts:
    historyServer: "history-41.local"
    jupyter: "jupyter-41.local"

# Jupyter (Spark Connect client)
jupyter:
  enabled: true
  image:
    repository: jupyter-spark
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8888
  env:
    SPARK_CONNECT_URL: "sc://spark-connect:15002"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2"
  persistence:
    enabled: false
    size: "10Gi"
    storageClass: ""

# Celeborn integration (optional)
# Requires separate Celeborn deployment:
#   helm install celeborn charts/celeborn
#
# For Spark Operator integration, see:
#   docs/examples/spark-application-celeborn.yaml
celeborn:
  enabled: false
  masterEndpoints: "celeborn-master-0.celeborn-master:9097,celeborn-master-1.celeborn-master:9097,celeborn-master-2.celeborn-master:9097"
  image:
    repository: apache/celeborn
    tag: "0.6.1"
    pullPolicy: IfNotPresent
  masters:
    replicas: 3
  workers:
    replicas: 3
    storage:
      size: "100Gi"
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Spark Operator (optional)
sparkOperator:
  enabled: false
  image:
    repository: ghcr.io/googlecloudplatform/spark-operator
    tag: "v1beta2-1.3.8-3.5.0"
    pullPolicy: IfNotPresent

# Security settings
security:
  podSecurityStandards: false
  runAsUser: 185
  runAsGroup: 185
  fsGroup: 185
  readOnlyRootFilesystem: false
