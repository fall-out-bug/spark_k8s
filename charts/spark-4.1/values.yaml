global:
  imagePullSecrets: []
  s3:
    enabled: true
    endpoint: "http://minio:9000"
    # REQUIRED: Set via --set or ExternalSecrets (see docs/recipes/security/credential-management.md)
    accessKey: ""
    secretKey: ""
    pathStyleAccess: true
    sslEnabled: false
    existingSecret: ""
  postgresql:
    host: "postgresql-metastore-41"
    port: 5432
    user: "hive"
    # REQUIRED: Set via --set or ExternalSecrets
    password: ""

# Secret Management
# Choose one: externalSecrets, sealedSecrets, or vault
secrets:
  externalSecrets:
    enabled: false
    provider: "aws"  # aws, gcp, azure, ibm
    region: "us-east-1"
    prefix: "spark"
    aws:
      iamRole: ""
    gcp:
      project: ""
      clusterLocation: ""
      clusterName: ""
      serviceAccountEmail: ""
    azure:
      tenantId: ""
      clientId: ""
      vaultName: ""
      secretName: ""
    ibm:
      serviceUrl: ""

  sealedSecrets:
    enabled: false
    data:
      access-key: ""
      secret-key: ""

  vault:
    enabled: false
    address: "https://vault.example.com:8200"
    role: "spark-connect"

# Cost exporter CronJob (optional)
costExporter:
  enabled: false

rbac:
  create: true
  serviceAccountName: "spark-41"

# Core Infrastructure Components (anchor for spark-base)
# Unified configuration for core infrastructure components (passed to spark-base)
core: &core
  minio:
    enabled: false  # Set to true to enable MinIO S3-compatible storage
    fullnameOverride: ""
    image:
      repository: quay.io/minio/minio
      tag: "RELEASE.2024-01-01T16-36-33Z"
      pullPolicy: IfNotPresent
    service:
      port: 9000
      consolePort: 9001
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "1Gi"
        cpu: "500m"
    persistence:
      enabled: true
      size: "10Gi"
      storageClass: ""
    buckets:
      - warehouse
      - spark-logs
      - spark-standalone-logs
      - spark-jobs
      - raw-data
      - processed-data
      - checkpoints

  postgresql:
    enabled: false  # Set to true to enable PostgreSQL database
    fullnameOverride: ""
    image:
      repository: postgres
      tag: "15-alpine"
      pullPolicy: IfNotPresent
    auth:
      username: "spark"
      # REQUIRED: Set via --set or ExternalSecrets
      password: ""
    service:
      port: 5432
    persistence:
      enabled: true
      size: "8Gi"
      storageClass: ""
    databases: []
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"

  hiveMetastore:
    enabled: true  # Hive Metastore for Spark SQL
    fullnameOverride: ""
    image:
      repository: spark-k8s/hive
      tag: "4.0.0-pg"
      pullPolicy: IfNotPresent
    service:
      port: 9083
    warehouseDir: "s3a://warehouse/spark-41"
    metastoreWarehouseDir: "file:/tmp/hive-warehouse"
    database:
      name: "metastore_spark41"
    postgresql:
      enabled: true
      host: "postgresql-metastore-41"
      port: 5432
      database: "metastore_spark41"
      username: "hive"
      # REQUIRED: Set via --set or ExternalSecrets
      password: ""
      persistence:
        enabled: true
        size: 5Gi
        storageClass: ""
    resources:
      requests:
        memory: "512Mi"
        cpu: "200m"
      limits:
        memory: "2Gi"
        cpu: "1000m"

spark-base:
  enabled: true
  serviceAccount:
    create: false
    name: spark
  rbac:
    create: false
    serviceAccountName: "spark-41"
  core: *core
  minio:
    enabled: false
  postgresql:
    enabled: false
  security:
    podSecurityStandards: true
    runAsUser: 185
    runAsGroup: 185
    fsGroup: 185
    readOnlyRootFilesystem: false

historyServer:
  enabled: true  # Spark History Server for completed applications
  fullnameOverride: ""
  image:
    repository: ghcr.io/fall-out-bug/spark-k8s-spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  logDirectory: "s3a://spark-logs/events"
  updateInterval: "10s"
  provider: ""
  s3aImpl: ""
  credentialsProvider: ""
  s3ConnectionMax: ""
  s3ConnectionTimeout: ""
  maxApplications: "1000"
  service:
    type: ClusterIP
    port: 18080
  podAnnotations: {}
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  sparkConf:
    spark.history.fs.cleaner.enabled: true
    spark.history.fs.cleaner.interval: "1d"
    spark.history.fs.cleaner.maxAge: "7d"

# Feature flags and configuration
features:
  iceberg:
    enabled: false
    catalogType: "hadoop"  # hadoop, hive, rest
    warehouse: "s3a://warehouse/iceberg"
    ioImpl: "org.apache.iceberg.hadoop.HadoopFileIO"
    restCatalogUri: ""  # Required when catalogType is "rest"
    restCatalogToken: ""  # Optional token for REST catalog
  gpu:
    enabled: false  # Enable GPU support with RAPIDS
    cudaVersion: ""  # Optional: e.g., "12.0"
    nvidiaVisibleDevices: "all"  # GPU devices to use
    taskResourceAmount: "0.25"  # GPU amount per task
    # RAPIDS configuration
    rapids:
      plugins: "com.nvidia.spark.SQLPlugin"
      sql:
        enabled: true
        python:
          enabled: true
        fallback:
          enabled: true
      memory:
        allocFraction: "0.8"
        maxAllocFraction: "0.9"
        minAllocFraction: "0.3"
      shuffle:
        enabled: true
      format:
        parquet:
          read: true
          write: true
        orc:
          read: true
        csv:
          read: true
        json:
          read: true
      jars:
        enabled: false  # Set to true to enable custom RAPIDS jars
        urls:
          - "local:///opt/spark/rapids/jars/rapids-4-spark_2.12-24.02.0.jar"
          - "local:///opt/spark/rapids/jars/cudf-24.02.0-cuda12.jar"
  openLineage:
    enabled: false
    # OpenLineage backend endpoint (Marquez, Datakin, etc.)
    endpoint: "http://marquez:5000"
    # Namespace for lineage events (e.g., team, environment)
    namespace: "spark-k8s"
    # Job name prefix (optional)
    jobPrefix: ""
    # Custom facets (optional)
    facets:
      enabled: true
      sparkVersion: true
      sourceCode: false
    # Transport configuration
    transport:
      type: "http"  # http, kafka, file
      # Kafka config (if type=kafka)
      kafka:
        topic: "openlineage.events"
        brokers: "kafka:9092"
      # File config (if type=file)
      file:
        path: "/tmp/openlineage/events.json"

# Spark Connect server (4.1.0)
connect:
  enabled: true
  replicas: 1
  image:
    repository: ghcr.io/fall-out-bug/spark-k8s-spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 15002
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
  driver:
    host: ""
    port: 7078
    blockManagerPort: 7079
  # Backend mode: "k8s" or "standalone"
  # k8s: dynamic executor pods created on demand (recommended)
  # standalone: submit to existing Spark Standalone master/workers
  backendMode: "k8s"
  # Standalone backend configuration (used when backendMode=standalone)
  standalone:
    masterService: "spark-sa-spark-standalone-master"
    masterPort: 7077
  executor:
    cores: "1"
    coresLimit: "2"
    memory: "1Gi"
    memoryLimit: "2Gi"
    # GPU configuration for executors
    gpu:
      enabled: false  # Enable GPU resources for executors
      count: "1"  # Number of GPUs per executor
      vendor: "nvidia.com/gpu"  # GPU vendor: nvidia.com/gpu, amd.com/gpu
      nodeSelector:
        nvidia.com/gpu: "true"  # Node selector for GPU nodes
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
  dynamicAllocation:
    enabled: true
    minExecutors: 0
    maxExecutors: 10
  eventLog:
    enabled: true
    dir: "s3a://spark-logs/events"
  sparkConf: {}
  extraJars:
    enabled: false
    configMap: ""

# Hive Metastore 4.0.0 (separate instance for Spark 4.1.0)
hiveMetastore:
  enabled: false
  image:
    repository: spark-k8s/hive
    tag: "4.0.0-pg"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/spark-41"
  metastoreWarehouseDir: "file:/tmp/hive-warehouse"
  database:
    name: "metastore_spark41"
  postgresql:
    enabled: true
    host: "postgresql-metastore-41"
    port: 5432
    database: "metastore_spark41"
    username: "hive"
    # REQUIRED: Set via --set or ExternalSecrets
    password: ""
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Ingress
ingress:
  enabled: false
  hosts:
    historyServer: "history-41.local"
    jupyter: "jupyter-41.local"

# Jupyter (Spark Connect client)
jupyter:
  enabled: true
  image:
    repository: spark-k8s-jupyter
    tag: "4.1-4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8888
  env:
    SPARK_CONNECT_URL: "sc://spark-connect:15002"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2"
  persistence:
    enabled: false
    size: "10Gi"
    storageClass: ""

# Celeborn integration (optional)
# Requires separate Celeborn deployment:
#   helm install celeborn charts/celeborn
#
# For Spark Operator integration, see:
#   docs/examples/spark-application-celeborn.yaml
celeborn:
  enabled: false
  masterEndpoints: "celeborn-master-0.celeborn-master:9097,celeborn-master-1.celeborn-master:9097,celeborn-master-2.celeborn-master:9097"
  image:
    repository: apache/celeborn
    tag: "0.6.1"
    pullPolicy: IfNotPresent
  masters:
    replicas: 3
  workers:
    replicas: 3
    storage:
      size: "100Gi"
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Spark Operator (optional)
sparkOperator:
  enabled: false
  image:
    repository: ghcr.io/googlecloudplatform/spark-operator
    tag: "v1beta2-1.3.8-3.5.0"
    pullPolicy: IfNotPresent

# Security settings
security:
  podSecurityStandards: true
  runAsUser: 185
  runAsGroup: 185
  fsGroup: 185
  readOnlyRootFilesystem: false
  # PSS profile for namespace labels (restricted/baseline/privileged)
  pssProfile: restricted
  # Create namespace with PSS labels
  createNamespace: false
  networkPolicies:
    enabled: false
  rbac:
    create: true
    pspEnabled: false
# Monitoring settings
monitoring:
  serviceMonitor:
    enabled: false
    interval: "15s"
    scrapeTimeout: "10s"
    labels: {}
    relabelings: []
  podMonitor:
    enabled: false
    interval: "30s"
    scrapeTimeout: "10s"
    labels: {}
    relabelings: []
  grafanaDashboards:
    enabled: false
    namespace: ""  # Defaults to release namespace
  podAnnotations: {}
  prometheusAnnotations:
    prometheus.io/scrape: "false"
    prometheus.io/port: "4040"
    prometheus.io/path: "/metrics/executors"
  # OpenTelemetry integration
  openTelemetry:
    enabled: false
    endpoint: "http://opentelemetry-collector:4317"
    protocol: "grpc"  # grpc or http# Auto-scaling configuration
autoscaling:
  clusterAutoscaler:
    enabled: false
    scaleDown:
      enabled: true
      delayAfterAdd: 10m
      unneededTime: 5m
      unreadyTime: 20m
      utilizationThreshold: 0.5
    nodeGroups: []
  keda:
    enabled: false
    pollingInterval: 30
    cooldownPeriod: 300
    minReplicaCount: 0
    maxReplicaCount: 10
    s3:
      bucket: ""
      prefix: "spark-jobs/"
      targetObjectSize: "10"
      region: "us-east-1"
      accessKey: ""
      secretKey: ""
      existingSecret: ""
