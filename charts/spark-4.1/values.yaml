global:
  imagePullSecrets: []

spark-base:
  enabled: true
  serviceAccount:
    create: false
    name: spark
  rbac:
    create: false
  minio:
    enabled: false
  postgresql:
    enabled: false
  security:
    podSecurityStandards: false

# Spark Connect server (4.1.0)
connect:
  enabled: true
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 15002
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "4Gi"
      cpu: "2000m"
  sparkConf:
    spark.master: "k8s://https://kubernetes.default.svc.cluster.local:443"
    spark.sql.catalogImplementation: "hive"
    spark.dynamicAllocation.enabled: "true"
    spark.dynamicAllocation.shuffleTracking.enabled: "true"

# Hive Metastore 4.0.0 (separate instance for Spark 4.1.0)
hiveMetastore:
  enabled: true
  image:
    repository: apache/hive
    tag: "4.0.0"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/spark-41"
  metastoreWarehouseDir: "file:/tmp/hive-warehouse"
  postgresql:
    enabled: true
    host: "postgresql-metastore-41"
    port: 5432
    database: "metastore_41"
    username: "hive"
    password: "hive123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# History Server 4.1.0
historyServer:
  enabled: true
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  logDirectory: "s3a://spark-logs/4.1/events"
  service:
    type: ClusterIP
    port: 18080
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Jupyter (Spark Connect client)
jupyter:
  enabled: true
  image:
    repository: jupyter-spark
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8888
  env:
    SPARK_CONNECT_URL: "sc://spark-connect:15002"
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Celeborn (optional shuffle service for Spark 4.1.0)
celeborn:
  enabled: false
  image:
    repository: apache/celeborn
    tag: "0.6.1"
    pullPolicy: IfNotPresent
  masters:
    replicas: 3
  workers:
    replicas: 3
    storage:
      size: "100Gi"
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Spark Operator (optional)
sparkOperator:
  enabled: false
  image:
    repository: ghcr.io/googlecloudplatform/spark-operator
    tag: "v1beta2-1.3.8-3.5.0"
    pullPolicy: IfNotPresent

# Shared S3 credentials (MinIO or external S3)
s3:
  endpoint: "http://minio:9000"
  accessKey: "minioadmin"
  secretKey: "minioadmin"
  pathStyleAccess: true
  sslEnabled: false

# Security settings
security:
  podSecurityStandards: false
  runAsUser: 185
  runAsGroup: 185
  fsGroup: 185
  readOnlyRootFilesystem: false
