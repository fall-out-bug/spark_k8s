global:
  imagePullSecrets: []
  s3:
    endpoint: "http://minio:9000"
    accessKey: "minioadmin"
    secretKey: "minioadmin"
    pathStyleAccess: true
    sslEnabled: false

spark-base:
  enabled: true
  serviceAccount:
    create: false
    name: spark
  rbac:
    create: false
  minio:
    enabled: false
  postgresql:
    enabled: false
  security:
    podSecurityStandards: false

# Spark Connect server (4.1.0)
connect:
  enabled: true
  replicas: 1
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 15002
  resources:
    requests:
      memory: "2Gi"
      cpu: "1"
    limits:
      memory: "4Gi"
      cpu: "2"
  executor:
    cores: "1"
    coresLimit: "2"
    memory: "1Gi"
    memoryLimit: "2Gi"
  dynamicAllocation:
    enabled: true
    minExecutors: 0
    maxExecutors: 10

# Hive Metastore 4.0.0 (separate instance for Spark 4.1.0)
hiveMetastore:
  enabled: true
  image:
    repository: apache/hive
    tag: "4.0.0"
    pullPolicy: IfNotPresent
  service:
    port: 9083
  warehouseDir: "s3a://warehouse/spark-41"
  metastoreWarehouseDir: "file:/tmp/hive-warehouse"
  postgresql:
    enabled: true
    host: "postgresql-metastore-41"
    port: 5432
    database: "metastore_41"
    username: "hive"
    password: "hive123"
    persistence:
      enabled: true
      size: 5Gi
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# History Server 4.1.0
historyServer:
  enabled: true
  image:
    repository: spark-custom
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  logDirectory: "s3a://spark-logs/4.1/events"
  service:
    type: ClusterIP
    port: 18080
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Jupyter (Spark Connect client)
jupyter:
  enabled: true
  image:
    repository: jupyter-spark
    tag: "4.1.0"
    pullPolicy: IfNotPresent
  service:
    type: ClusterIP
    port: 8888
  env:
    SPARK_CONNECT_URL: "sc://spark-connect:15002"
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Celeborn (optional shuffle service for Spark 4.1.0)
celeborn:
  enabled: false
  image:
    repository: apache/celeborn
    tag: "0.6.1"
    pullPolicy: IfNotPresent
  masterEndpoints: "celeborn-master:9097"
  masters:
    replicas: 3
  workers:
    replicas: 3
    storage:
      size: "100Gi"
      storageClass: ""
  resources:
    requests:
      memory: "512Mi"
      cpu: "200m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Spark Operator (optional)
sparkOperator:
  enabled: false
  image:
    repository: ghcr.io/googlecloudplatform/spark-operator
    tag: "v1beta2-1.3.8-3.5.0"
    pullPolicy: IfNotPresent

# Security settings
security:
  podSecurityStandards: false
  runAsUser: 185
  runAsGroup: 185
  fsGroup: 185
  readOnlyRootFilesystem: false
