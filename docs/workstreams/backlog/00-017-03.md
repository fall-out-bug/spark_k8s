---
ws_id: 00-017-03
feature: F17
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-017-01  # Go client library
---

## WS-00-017-03: Go E2E tests

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 16 E2E test ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÐµÐ² Ð´Ð»Ñ Go ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
- Full dataset queries (NYC Taxi)
- Complex operations
- Performance comparison Ñ Python client

**Acceptance Criteria:**
- [ ] AC1: 16 E2E test ÑÑ†ÐµÐ½Ð°Ñ€Ð¸ÐµÐ² ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹
- [ ] AC2: NYC Taxi dataset queries Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚
- [ ] AC3: Complex aggregations Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚
- [ ] AC4: JOIN operations Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚
- [ ] AC5: Window functions Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÑŽÑ‚
- [ ] AC6: Performance ÑÑ€Ð°Ð²Ð½Ð¸Ð¼ Ñ Python

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Dependencies

WS-017-01 (Go client library)

### Scenarios

| Scenario | Spark Version | Query Type | Dataset |
|----------|---------------|------------|---------|
| 1 | 3.5.7 | COUNT aggregation | NYC Taxi |
| 2 | 3.5.8 | GROUP BY aggregation | NYC Taxi |
| 3 | 4.1.0 | JOIN with filter | NYC Taxi |
| 4 | 4.1.1 | Window function | NYC Taxi |
| 5 | 3.5.7 | Complex multi-step | NYC Taxi |
| 6 | 3.5.8 | Subquery | NYC Taxi |
| 7 | 4.1.0 | UNION | NYC Taxi |
| 8 | 4.1.1 | CTE (WITH clause) | NYC Taxi |
| 9-12 | Various | Performance tests | NYC Taxi |
| 13-16 | Various | Error handling | NYC Taxi |

### Code

```go
// tests/go/e2e/queries_test.go
package e2e

import (
	"context"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	spark "github.com/fall-out-bug/spark_k8s/tests/go/client"
)

func TestGoE2E_CountQuery_357(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-3-5-7-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Q1: SELECT COUNT(*) â€” validate row count
	df, err := session.SQL(ctx, `
		SELECT COUNT(*) as total_rows
		FROM nyc_taxi
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	require.Len(t, rows, 1)

	total, err := rows[0].GetInt(0)
	require.NoError(t, err)
	assert.Greater(t, total, int32(0), "Should have rows in NYC Taxi dataset")
}

func TestGoE2E_GroupByAggregation_358(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-3-5-8-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Q2: GROUP BY aggregation â€” validate aggregation
	df, err := session.SQL(ctx, `
		SELECT
			passenger_count,
			SUM(fare_amount) as total_fare,
			AVG(trip_distance) as avg_distance
		FROM nyc_taxi
		GROUP BY passenger_count
		HAVING passenger_count > 0
		ORDER BY passenger_count
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Greater(t, len(rows), 0, "Should have aggregation results")
}

func TestGoE2E_JoinWithFilter_410(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-4-1-0-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Q3: JOIN with filter â€” validate join performance
	df, err := session.SQL(ctx, `
		SELECT
			t1.passenger_count,
			COUNT(*) as trip_count,
			AVG(t1.fare_amount) as avg_fare
		FROM nyc_taxi t1
		INNER JOIN (
			SELECT passenger_count
			FROM nyc_taxi
			GROUP BY passenger_count
			HAVING COUNT(*) > 1000
		) t2 ON t1.passenger_count = t2.passenger_count
		WHERE t1.trip_distance > 0
		GROUP BY t1.passenger_count
		ORDER BY t1.passenger_count
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Greater(t, len(rows), 0, "Should have join results")
}

func TestGoE2E_WindowFunction_411(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-4-1-1-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Q4: Window function â€” validate complex queries
	df, err := session.SQL(ctx, `
		SELECT
			passenger_count,
			fare_amount,
			AVG(fare_amount) OVER (
				PARTITION BY passenger_count
				ORDER BY fare_amount
				ROWS BETWEEN 10 PRECEDING AND 10 FOLLOWING
			) as rolling_avg_fare
		FROM (
			SELECT passenger_count, fare_amount
			FROM nyc_taxi
			WHERE passenger_count > 0 AND fare_amount > 0
			LIMIT 1000
		)
		ORDER BY passenger_count, fare_amount
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Greater(t, len(rows), 0, "Should have window function results")
}

func TestGoE2E_ComplexMultiStep_357(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-3-5-7-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Create temporary views
	_, err = session.SQL(ctx, `
		CREATE OR REPLACE TEMPORARY VIEW taxi_filtered AS
		SELECT * FROM nyc_taxi
		WHERE passenger_count > 0
		AND trip_distance > 0
		AND fare_amount > 0
		AND tip_amount >= 0
	`)
	require.NoError(t, err)

	// Create statistics view
	_, err = session.SQL(ctx, `
		CREATE OR REPLACE TEMPORARY VIEW taxi_stats AS
		SELECT
			passenger_count,
			COUNT(*) as trip_count,
			SUM(fare_amount) as total_fare,
			AVG(trip_distance) as avg_distance,
			STDDEV(tip_amount) as stddev_tip
		FROM taxi_filtered
		GROUP BY passenger_count
	`)
	require.NoError(t, err)

	// Query final results
	df, err := session.SQL(ctx, `
		SELECT * FROM taxi_stats
		ORDER BY passenger_count
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Greater(t, len(rows), 0)
}

func TestGoE2E_Subquery_358(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-3-5-8-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Subquery test
	df, err := session.SQL(ctx, `
		SELECT
			passenger_count,
			fare_amount,
			(SELECT AVG(fare_amount) FROM nyc_taxi WHERE passenger_count > 0) as global_avg_fare
		FROM nyc_taxi
		WHERE passenger_count > 0
		AND fare_amount > 0
		LIMIT 100
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Len(t, rows, 100)
}

func TestGoE2E_CTExpression_411(t *testing.T) {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-4-1-1-connect:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// CTE (WITH clause)
	df, err := session.SQL(ctx, `
		WITH high_fare_trips AS (
			SELECT * FROM nyc_taxi
			WHERE fare_amount > 50
			AND passenger_count > 0
			LIMIT 100
		),
		long_trips AS (
			SELECT * FROM nyc_taxi
			WHERE trip_distance > 10
			AND passenger_count > 0
			LIMIT 100
		)
		SELECT
			COALESCE(h.passenger_count, l.passenger_count) as passenger_count,
			COALESCE(h.fare_amount, 0) as high_fare,
			COALESCE(l.trip_distance, 0) as long_distance
		FROM high_fare_trips h
		FULL OUTER JOIN long_trips l
		ON h.passenger_count = l.passenger_count
		ORDER BY passenger_count
	`)
	require.NoError(t, err)

	rows, err := df.Collect(ctx)
	require.NoError(t, err)
	assert.Greater(t, len(rows), 0)
}

func TestGoE2E_PerformanceVsPython(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping performance test in short mode")
	}

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Minute)
	defer cancel()

	client, err := spark.NewClient(ctx, "spark-connect-test:15002")
	require.NoError(t, err)
	defer client.Close()

	session, err := client.CreateSession(ctx)
	require.NoError(t, err)
	defer session.Close(ctx)

	// Measure query execution time
	start := time.Now()

	df, err := session.SQL(ctx, `
		SELECT
			passenger_count,
			SUM(fare_amount) as total_fare,
			COUNT(*) as trip_count
		FROM nyc_taxi
		WHERE passenger_count > 0
		GROUP BY passenger_count
	`)
	require.NoError(t, err)

	_, err = df.Collect(ctx)
	require.NoError(t, err)

	duration := time.Since(start)

	// Should complete in reasonable time (benchmark: < 5 min for Go client)
	assert.Less(t, duration, 5*time.Minute,
		"Go client should complete query in less than 5 minutes")

	t.Logf("Query execution time: %v", duration)
}
```

### Scope Estimate

- Files: 8
- Lines: ~700 (MEDIUM)
- Tokens: ~5500

### Constraints

- DO use same queries as Python client tests
- DO measure performance for comparison
- DO use NYC Taxi dataset (11GB)
- DO NOT exceed 30 min per test

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______

---

### Review Result

**Reviewed by:** Cursor Composer
**Date:** 2026-02-10

#### ðŸŽ¯ Goal Status

- [ ] AC1â€“AC6: 16 E2E scenarios â€” âŒ Not implemented

**Goal Achieved:** âŒ NO (depends on WS-017-01)
