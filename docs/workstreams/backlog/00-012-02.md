---
ws_id: 00-012-02
feature: F12
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Phase 0: Helm charts
  - 00-006-06  # Phase 0: GPU feature templates
  - 00-022-01  # Phase 1: Security templates
---

## WS-00-012-02: GPU E2E (16 scenarios)

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 16 GPU E2E test scenarios with NYC Taxi dataset
- Tests validate Spark 4.1.0, 4.1.1 Ã— Jupyter, Airflow Ã— connect-k8s Ã— GPU mode
- RAPIDS acceleration verification (GPU vs CPU comparison)

**Acceptance Criteria:**
- [ ] AC1: 16 GPU E2E scenarios created (Jupyter/Airflow Ã— 4.1.0/4.1.1 Ã— connect-k8s Ã— GPU)
- [ ] AC2: GPU utilization metrics collected (gpu_utilization, gpu_memory_used)
- [ ] AC3: RAPIDS acceleration validated (GPU faster than CPU for supported operations)
- [ ] AC4: All scenarios complete with timeout < 1200s
- [ ] AC5: GPU resource limits enforced

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Context

GPU E2E tests validate RAPIDS acceleration with CUDA 12.1. Tests use Spark 4.1.0/4.1.1 which includes native GPU support. Metrics verify GPU utilization and performance improvements over CPU-only execution.

### Dependencies

- Phase 0 (F06): GPU feature templates
- Phase 1 (F07): Security templates
- Phase 5 (F11): GPU runtime images (Spark 4.1.x with CUDA)

### Input Files

- `scripts/tests/e2e/conftest.py` â€” Base E2E fixtures (from WS-00-012-01)
- `scripts/tests/e2e/queries/` â€” Standard SQL queries
- `charts/spark-4.1/` â€” Spark 4.1.x charts with GPU support

### Steps

1. **Create GPU-specific fixtures:**
   - Add GPU detection fixture to `conftest.py`
   - Add GPU metrics collection (nvidia-smi parsing)
   - Add CUDA availability check

2. **Implement GPU E2E test scenarios:**
   - `test_jupyter_gpu_410.py` â€” Jupyter with GPU, Spark 4.1.0
   - `test_jupyter_gpu_411.py` â€” Jupyter with GPU, Spark 4.1.1
   - `test_airflow_gpu_410.py` â€” Airflow with GPU, Spark 4.1.0
   - `test_airflow_gpu_411.py` â€” Airflow with GPU, Spark 4.1.1

3. **Add GPU-specific queries:**
   - GPU-accelerated operations: GROUP BY, JOIN, SORT
   - Compare GPU vs CPU execution time

4. **Implement GPU metrics collection:**
   - `gpu_utilization` via nvidia-smi
   - `gpu_memory_used` via nvidia-smi
   - Comparison metrics (speedup factor)

5. **Validate locally (requires GPU-enabled cluster):**
   - Run pytest on GPU scenarios
   - Verify GPU is utilized (gpu_utilization > 0%)
   - Check speedup factor > 1.0 for supported operations

### Code

**GPU fixture example:**

```python
@pytest.fixture(scope="session")
def gpu_available():
    """Check if NVIDIA GPU is available."""
    import subprocess
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0 and result.stdout.strip():
            return True
    except (FileNotFoundError, subprocess.TimeoutExpired):
        pass
    pytest.skip("No GPU available")

@pytest.fixture(scope="function")
def gpu_metrics():
    """Collect GPU metrics during test."""
    import subprocess
    import json

    def get_gpu_stats():
        try:
            result = subprocess.run([
                "nvidia-smi",
                "--query-gpu=utilization.gpu,memory.used",
                "--format=csv,noheader,nounits"
            ], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                util, mem = result.stdout.strip().split(",")
                return {"gpu_utilization": int(util), "gpu_memory_used": int(mem)}
        except (FileNotFoundError, subprocess.TimeoutExpired, ValueError):
            pass
        return {"gpu_utilization": 0, "gpu_memory_used": 0}

    yield {}
    return {"gpu_stats": get_gpu_stats()}
```

### Expected Outcome

- Files: 4 test modules
- All 16 scenarios (4 modules Ã— 4 queries) pass
- GPU metrics collected for all GPU tests

### Scope Estimate

- Files: ~5
- Lines: ~900 (MEDIUM)
- Tokens: ~3500

### Completion Criteria

```bash
# Run GPU E2E tests
pytest scripts/tests/e2e/ -v --timeout=1200 -k "gpu"

# Verify GPU utilization
# Check test output for gpu_utilization > 0
```

### Constraints

- Tests skip gracefully if no GPU available
- DO NOT break existing E2E tests
- MUST validate GPU is actually used (not just enabled)

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC5 â€” âœ…

**Goal Achieved:** ______

### Files Changed
| File | Action | LOC |
|------|--------|-----|
|      |        |     |

### Statistics
- **Files Changed:** ______
- **Lines Added:** ______
- **Tests Passed:** ______
- **Tests Failed:** ______

### Deviations from Plan
- ______

### Commit
______
