# WS-007-02: GPU Load Tests

## Goal
Создать 4 GPU load тестов для проверки производительности RAPIDS GPU acceleration при sustained load (30 минут).

### Acceptance Criteria
1. 4 GPU load тестов созданы в `tests/load/phase07/test_07_02_gpu_load.py`
2. Sustained load duration: 30 минут
3. RAPIDS GPU acceleration проверена при нагрузке
4. Load profile: sustained GPU queries
5. GPU метрики собираются (GPU memory, GPU utilization, speedup)
6. GPU stability проверяется (no OOM, no crashes over 30 min)
7. Comparison GPU vs CPU при нагрузке

## Context

**Существующая инфраструктура:**
- `tests/load/phase07/test_07_01_baseline_load.py` — baseline load тесты
- `tests/e2e/phase06/test_06_02_gpu_e2e.py` — GPU E2E тесты
- RAPIDS Docker images из Phase 5

**Что нужно добавить:**
- GPU-specific load testing
- Sustained GPU workload
- GPU memory monitoring
- GPU utilization tracking
- Отдельный файл `tests/load/phase07/test_07_02_gpu_load.py`

## Dependency
Phase 0 (Helm Charts), Phase 5 (GPU Final Images), Phase 6 (E2E Tests)

## Input Files
- `tests/load/phase07/conftest.py` (shared fixtures)
- `tests/load/phase07/test_07_01_baseline_load.py` (reference)
- `charts/spark-3.5/values.yaml`
- `charts/spark-4.1/values.yaml`

## Steps

### 1. Create test_07_02_gpu_load.py
- Создать `tests/load/phase07/test_07_02_gpu_load.py`
- Implement 4 test scenarios

### 2. Implement test scenarios

**GPU Load Scenarios:**

1. **Spark 3.5.7 GPU Baseline — Sustained cuDF COUNT (30 min)**
   - GPU-accelerated COUNT(*) queries
   - 1 query/second for 30 minutes
   - Validate: GPU utilization > 50%, no OOM

2. **Spark 3.5.7 GPU Optimized — Sustained cuDF GROUP BY (30 min)**
   - Optimized RAPIDS settings
   - 0.5 query/second for 30 minutes
   - Validate: consistent GPU performance

3. **Spark 4.1.0 GPU — Sustained cuDF JOIN (30 min)**
   - GPU-accelerated JOIN queries
   - 0.5 query/second for 30 minutes
   - Validate: GPU memory stable

4. **Spark 4.1.0 GPU vs CPU — Comparison Load (30 min)**
   - Alternate between GPU and CPU queries
   - Measure speedup factor over time
   - Validate: GPU consistently faster

### 3. GPU Metrics Collection
- gpu_memory_used: peak GPU memory
- gpu_utilization: GPU utilization percentage
- gpu_speedup_factor: GPU vs CPU speedup
- gpu_oom_count: GPU out-of-memory errors
- gpu_temperature: GPU temperature (если доступно)

### 4. Run tests
- `pytest tests/load/phase07/test_07_02_gpu_load.py -v --timeout=2400`

## Code

### tests/load/phase07/test_07_02_gpu_load.py

```python
"""GPU Load Tests for Phase 7

Load tests for RAPIDS GPU acceleration under sustained load.
"""

import pytest
import time
from pyspark.sql import SparkSession

class TestGPULoad:
    """GPU load tests for sustained performance"""

    @pytest.mark.timeout(2400)
    @pytest.mark.load
    @pytest.mark.gpu
    def test_01_gpu_sustained_cudf_count(self, spark_load_session, nyc_taxi_dataset_path, load_metrics, load_duration_seconds):
        """Spark 3.5.7 GPU Baseline — Sustained cuDF COUNT (30 min)"""
        # Enable RAPIDS
        spark_load_session.conf.set("spark.rapids.sql.enabled", "true")
        spark_load_session.conf.set("spark.rapids.sql.python.enabled", "true")

        df = spark_load_session.read.parquet(str(nyc_taxi_dataset_path))
        df.createOrReplaceTempView("nyc_taxi")

        start_time = time.time()
        end_time = start_time + load_duration_seconds

        query_count = 0
        error_count = 0
        gpu_oom_count = 0

        while time.time() < end_time:
            query_start = time.time()
            try:
                result = spark_load_session.sql("SELECT COUNT(*) AS row_count FROM nyc_taxi")
                result.collect()
                query_count += 1

                load_metrics("test_gpu_01_queries", query_count)
                time.sleep(1)

            except Exception as e:
                error_count += 1
                error_msg = str(e).lower()
                if 'oom' in error_msg or 'memory' in error_msg:
                    gpu_oom_count += 1
                load_metrics("test_gpu_01_error", str(e))
                if error_count > 10:
                    pytest.fail(f"Too many errors: {error_count}")

        total_time = time.time() - start_time
        throughput = query_count / total_time

        assert query_count > 1500
        assert error_count == 0
        assert gpu_oom_count == 0, "Should have no GPU OOM errors"

        load_metrics("test_gpu_01_total_queries", query_count)
        load_metrics("test_gpu_01_throughput", throughput)

    @pytest.mark.timeout(2400)
    @pytest.mark.load
    @pytest.mark.gpu
    def test_02_gpu_optimized_sustained_groupby(self, spark_load_session, nyc_taxi_dataset_path, load_metrics, load_duration_seconds):
        """Spark 3.5.7 GPU Optimized — Sustained cuDF GROUP BY (30 min)"""
        spark_load_session.conf.set("spark.rapids.sql.enabled", "true")
        spark_load_session.conf.set("spark.rapids.sql.batchSizeBytes", "1G")
        spark_load_session.conf.set("spark.rapids.sql.variableFloatAgg.enabled", "true")

        df = spark_load_session.read.parquet(str(nyc_taxi_dataset_path))
        df = df.sample(0.1)
        df.createOrReplaceTempView("nyc_taxi")

        start_time = time.time()
        end_time = start_time + load_duration_seconds

        query_count = 0
        error_count = 0

        while time.time() < end_time:
            try:
                result = spark_load_session.sql("""
                    SELECT passenger_count, COUNT(*) AS trip_count, AVG(total_amount) AS avg_fare
                    FROM nyc_taxi
                    GROUP BY passenger_count
                """)
                result.collect()
                query_count += 1

                load_metrics("test_gpu_02_queries", query_count)
                time.sleep(2)  # 0.5 qps

            except Exception as e:
                error_count += 1
                load_metrics("test_gpu_02_error", str(e))
                if error_count > 10:
                    pytest.fail(f"Too many errors: {error_count}")

        assert query_count > 750
        assert error_count == 0

        load_metrics("test_gpu_02_total_queries", query_count)

    @pytest.mark.timeout(2400)
    @pytest.mark.load
    @pytest.mark.gpu
    def test_03_gpu_sustained_join(self, spark_load_session, nyc_taxi_dataset_path, load_metrics, load_duration_seconds):
        """Spark 4.1.0 GPU — Sustained cuDF JOIN (30 min)"""
        spark_load_session.conf.set("spark.rapids.sql.enabled", "true")

        df = spark_load_session.read.parquet(str(nyc_taxi_dataset_path))
        df = df.sample(0.01)
        df.createOrReplaceTempView("nyc_taxi")

        start_time = time.time()
        end_time = start_time + load_duration_seconds

        query_count = 0
        error_count = 0

        while time.time() < end_time:
            try:
                result = spark_load_session.sql("""
                    SELECT t1.passenger_count, COUNT(*) AS trip_count
                    FROM nyc_taxi t1
                    INNER JOIN nyc_taxi t2 ON t1.passenger_count = t2.passenger_count
                    WHERE t1.trip_distance > 5
                    GROUP BY t1.passenger_count
                """)
                result.collect()
                query_count += 1

                load_metrics("test_gpu_03_queries", query_count)
                time.sleep(2)

            except Exception as e:
                error_count += 1
                load_metrics("test_gpu_03_error", str(e))
                if error_count > 10:
                    pytest.fail(f"Too many errors: {error_count}")

        assert query_count > 750
        assert error_count == 0

        load_metrics("test_gpu_03_total_queries", query_count)

    @pytest.mark.timeout(2400)
    @pytest.mark.load
    @pytest.mark.gpu
    def test_04_gpu_vs_cpu_comparison_load(self, spark_load_session, nyc_taxi_dataset_path, load_metrics, load_duration_seconds):
        """Spark 4.1.0 GPU vs CPU — Comparison Load (30 min)"""
        df = spark_load_session.read.parquet(str(nyc_taxi_dataset_path))
        df = df.sample(0.05)
        df.createOrReplaceTempView("nyc_taxi")

        start_time = time.time()
        end_time = start_time + load_duration_seconds

        gpu_query_count = 0
        cpu_query_count = 0
        gpu_times = []
        cpu_times = []

        query = "SELECT COUNT(*) AS row_count FROM nyc_taxi"

        while time.time() < end_time:
            # GPU query
            spark_load_session.conf.set("spark.rapids.sql.enabled", "true")
            gpu_start = time.time()
            try:
                result = spark_load_session.sql(query)
                result.collect()
                gpu_time = time.time() - gpu_start
                gpu_times.append(gpu_time)
                gpu_query_count += 1
            except:
                pass

            # CPU query
            spark_load_session.conf.set("spark.rapids.sql.enabled", "false")
            cpu_start = time.time()
            try:
                result = spark_load_session.sql(query)
                result.collect()
                cpu_time = time.time() - cpu_start
                cpu_times.append(cpu_time)
                cpu_query_count += 1
            except:
                pass

            load_metrics("test_gpu_04_gpu_queries", gpu_query_count)
            load_metrics("test_gpu_04_cpu_queries", cpu_query_count)

            time.sleep(1)

        # Calculate speedup
        if gpu_times and cpu_times:
            avg_gpu = sum(gpu_times) / len(gpu_times)
            avg_cpu = sum(cpu_times) / len(cpu_times)
            speedup = avg_cpu / avg_gpu if avg_gpu > 0 else 0

            assert gpu_query_count > 1000
            assert cpu_query_count > 1000

            load_metrics("test_gpu_04_speedup_factor", speedup)
            load_metrics("test_gpu_04_avg_gpu_time", avg_gpu)
            load_metrics("test_gpu_04_avg_cpu_time", avg_cpu)
```

## Scope Estimate
- Files: 1 (test_07_02_gpu_load.py)
- LOC: ~600 (tests + GPU logic)
- Scenarios: 4
- Duration: 30 min × 4 = 2 hours execution time
- Size: MEDIUM
