## WS-020-12: Spark Operator Chart (CRDs + Operator Deployment)

### üéØ Goal

**What should WORK after WS completion:**
- Helm chart `charts/spark-operator/` exists with CRD and operator deployment
- Operator manages `SparkApplication` CRDs
- Operator supports Spark 4.1.0 images
- `helm lint charts/spark-operator` passes

**Acceptance Criteria:**
- [ ] `charts/spark-operator/Chart.yaml` defines chart metadata
- [ ] `charts/spark-operator/values.yaml` contains operator configuration
- [ ] `charts/spark-operator/templates/crds/sparkapplication-crd.yaml` defines SparkApplication CRD
- [ ] `charts/spark-operator/templates/operator-deployment.yaml` defines operator Deployment
- [ ] `charts/spark-operator/templates/rbac.yaml` defines operator RBAC (ClusterRole for CRD management)
- [ ] `helm lint charts/spark-operator` passes

**‚ö†Ô∏è WS is NOT complete until Goal is achieved (all AC ‚úÖ).**

---

### Context

Feature F04 includes Spark Operator as optional component for declarative Spark job management via Kubernetes CRDs. This enables DataOps to define Spark jobs as YAML manifests.

### Dependency

Independent (standalone chart)

### Input Files

**Reference:**
- [Spark Operator Documentation](https://googlecloudplatform.github.io/spark-on-k8s-operator/)
- [Spark Operator Helm Chart](https://github.com/googlecloudplatform/spark-on-k8s-operator/tree/master/charts/spark-operator-chart)

### Steps

1. **Create directory:**
   ```bash
   mkdir -p charts/spark-operator/templates/crds
   ```

2. **Create `charts/spark-operator/Chart.yaml`:**
   ```yaml
   apiVersion: v2
   name: spark-operator
   version: 0.1.0
   appVersion: "v1beta2-1.3.8-3.1.1"
   description: Kubernetes Operator for Apache Spark
   ```

3. **Create `charts/spark-operator/values.yaml`:**
   ```yaml
   image:
     repository: gcr.io/spark-operator/spark-operator
     tag: "v1beta2-1.3.8-3.1.1"
     pullPolicy: IfNotPresent
   
   replicas: 1
   
   sparkJobNamespace: "default"
   
   webhook:
     enable: true
     port: 8080
   
   resources:
     requests:
       memory: "256Mi"
       cpu: "100m"
     limits:
       memory: "512Mi"
       cpu: "500m"
   
   rbac:
     create: true
   ```

4. **Create `charts/spark-operator/templates/crds/sparkapplication-crd.yaml`:**
   
   Download official CRD from Spark Operator repository:
   ```bash
   curl -o charts/spark-operator/templates/crds/sparkapplication-crd.yaml \
     https://raw.githubusercontent.com/googlecloudplatform/spark-on-k8s-operator/master/charts/spark-operator-chart/crds/sparkoperator.k8s.io_sparkapplications.yaml
   ```
   
   Add Helm conditional:
   ```yaml
   {{- if .Values.rbac.create }}
   # ... CRD content ...
   {{- end }}
   ```

5. **Create `charts/spark-operator/templates/operator-deployment.yaml`:**
   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: {{ include "spark-operator.fullname" . }}
   spec:
     replicas: {{ .Values.replicas }}
     selector:
       matchLabels:
         app: spark-operator
     template:
       metadata:
         labels:
           app: spark-operator
       spec:
         serviceAccountName: {{ include "spark-operator.serviceAccountName" . }}
         containers:
         - name: spark-operator
           image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
           args:
           - -v=2
           - -namespace={{ .Values.sparkJobNamespace }}
           - -enable-webhook={{ .Values.webhook.enable }}
           - -webhook-svc-name={{ include "spark-operator.fullname" . }}-webhook
           - -webhook-svc-namespace={{ .Release.Namespace }}
           ports:
           - containerPort: 10254
             name: metrics
           {{- if .Values.webhook.enable }}
           - containerPort: {{ .Values.webhook.port }}
             name: webhook
           {{- end }}
           resources:
             {{- toYaml .Values.resources | nindent 12 }}
   ```

6. **Create `charts/spark-operator/templates/rbac.yaml`:**
   
   ClusterRole (operator needs cluster-wide permissions for CRDs):
   ```yaml
   apiVersion: rbac.authorization.k8s.io/v1
   kind: ClusterRole
   metadata:
     name: {{ include "spark-operator.fullname" . }}
   rules:
   - apiGroups: [""]
     resources: ["pods", "services", "configmaps"]
     verbs: ["create", "get", "list", "watch", "delete", "update", "patch"]
   - apiGroups: ["sparkoperator.k8s.io"]
     resources: ["sparkapplications", "scheduledsparkapplications"]
     verbs: ["create", "get", "list", "watch", "delete", "update", "patch"]
   - apiGroups: ["sparkoperator.k8s.io"]
     resources: ["sparkapplications/status", "scheduledsparkapplications/status"]
     verbs: ["update", "patch"]
   ```

7. **Create webhook Service (if enabled):**
   ```yaml
   {{- if .Values.webhook.enable }}
   apiVersion: v1
   kind: Service
   metadata:
     name: {{ include "spark-operator.fullname" . }}-webhook
   spec:
     ports:
     - port: 443
       targetPort: {{ .Values.webhook.port }}
     selector:
       app: spark-operator
   {{- end }}
   ```

8. **Validate:**
   ```bash
   helm lint charts/spark-operator
   helm template spark-operator charts/spark-operator
   ```

### Expected Result

```
charts/spark-operator/
‚îú‚îÄ‚îÄ Chart.yaml                              # ~10 LOC
‚îú‚îÄ‚îÄ values.yaml                             # ~60 LOC
‚îî‚îÄ‚îÄ templates/
    ‚îú‚îÄ‚îÄ _helpers.tpl                        # ~40 LOC
    ‚îú‚îÄ‚îÄ crds/
    ‚îÇ   ‚îî‚îÄ‚îÄ sparkapplication-crd.yaml       # ~500 LOC (from upstream)
    ‚îú‚îÄ‚îÄ operator-deployment.yaml            # ~120 LOC
    ‚îú‚îÄ‚îÄ rbac.yaml                           # ~100 LOC
    ‚îî‚îÄ‚îÄ webhook-service.yaml                # ~30 LOC
```

### Scope Estimate

- Files: 7 created
- Lines: ~860 LOC (MEDIUM, but most is CRD YAML from upstream)
- Tokens: ~3500

### Completion Criteria

```bash
# Lint
helm lint charts/spark-operator

# Template render
helm template spark-operator charts/spark-operator

# Validate YAML
helm template spark-operator charts/spark-operator | kubectl apply --dry-run=client -f -

# Check CRD exists
helm template spark-operator charts/spark-operator | grep "kind: CustomResourceDefinition"
```

### Constraints

- DO NOT modify upstream CRD (use official version)
- DO NOT create namespace-scoped Role (operator needs ClusterRole)
- ENSURE webhook is optional (configurable)
- USE official Spark Operator image (no custom build)

---

### Execution Report

**Executed by:** Auto (agent)  
**Date:** 2026-01-18

#### üéØ Goal Status

- [x] AC1: `charts/spark-operator/Chart.yaml` defines chart metadata ‚Äî ‚úÖ
- [x] AC2: `charts/spark-operator/values.yaml` contains operator configuration ‚Äî ‚úÖ
- [x] AC3: `charts/spark-operator/templates/crds/sparkapplication-crd.yaml` defines SparkApplication CRD ‚Äî ‚úÖ
- [x] AC4: `charts/spark-operator/templates/operator-deployment.yaml` defines operator Deployment ‚Äî ‚úÖ
- [x] AC5: `charts/spark-operator/templates/rbac.yaml` defines operator RBAC (ClusterRole for CRD management) ‚Äî ‚úÖ
- [x] AC6: `helm lint charts/spark-operator` passes ‚Äî ‚úÖ

**Goal Achieved:** ‚úÖ YES

#### Modified Files

| File | Action | LOC |
|------|--------|-----|
| `charts/spark-operator/Chart.yaml` | added | 5 |
| `charts/spark-operator/values.yaml` | added | 23 |
| `charts/spark-operator/templates/_helpers.tpl` | added | 23 |
| `charts/spark-operator/templates/operator-deployment.yaml` | added | 38 |
| `charts/spark-operator/templates/rbac.yaml` | added | 40 |
| `charts/spark-operator/templates/webhook-service.yaml` | added | 15 |
| `charts/spark-operator/templates/crds/sparkapplication-crd.yaml` | added | 12414 |

**Total:** 7 added, 12558 LOC

#### Completed Steps

- [x] Step 1: Created `charts/spark-operator/templates/crds` directory
- [x] Step 2: Added `Chart.yaml`
- [x] Step 3: Added `values.yaml`
- [x] Step 4: Added upstream SparkApplication CRD with Helm conditional
- [x] Step 5: Added operator Deployment template
- [x] Step 6: Added ClusterRole/ClusterRoleBinding and ServiceAccount
- [x] Step 7: Added optional webhook Service
- [x] Step 8: Lint + template validation

#### Self-Check Results

```bash
$ helm lint charts/spark-operator
1 chart(s) linted, 0 chart(s) failed

$ helm template spark-operator charts/spark-operator
rendered successfully

$ helm template spark-operator charts/spark-operator | kubectl apply --dry-run=client -f -
serviceaccount/spark-operator-spark-operator created (dry run)
customresourcedefinition.apiextensions.k8s.io/sparkapplications.sparkoperator.k8s.io created (dry run)
clusterrole.rbac.authorization.k8s.io/spark-operator-spark-operator created (dry run)
clusterrolebinding.rbac.authorization.k8s.io/spark-operator-spark-operator created (dry run)
service/spark-operator-spark-operator-webhook created (dry run)
deployment.apps/spark-operator-spark-operator created (dry run)

$ rg "kind: CustomResourceDefinition" charts/spark-operator/templates/crds/sparkapplication-crd.yaml
4:kind: CustomResourceDefinition
```

#### Issues

- None
