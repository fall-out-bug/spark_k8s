---
ws_id: 00-013-01
feature: F13
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-012-01  # Core E2E
---

## WS-00-013-01: Baseline load (4 scenarios)

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 4 baseline load test scenarios (Spark 3.5.8, 4.1.1 Ã— Airflow)
- 30-minute sustained load tests
- Performance metrics collection (throughput, latency, error rate)

**Acceptance Criteria:**
- [ ] AC1: 4 baseline load test scenarios created
- [ ] AC2: Each test runs for 30 minutes sustained load
- [ ] AC3: Throughput metrics collected (queries/sec)
- [ ] AC4: Latency percentiles captured (p50, p95, p99)
- [ ] AC5: Error rate < 1% for all scenarios
- [ ] AC6: Fixed resources (no dynamic allocation)

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Scenarios

| Scenario | Spark Version | Component | Mode | Queries |
|----------|---------------|-----------|------|---------|
| 1 | 3.5.8 | Airflow | connect-k8s | SELECT + aggregation |
| 2 | 3.5.8 | Airflow | connect-k8s | JOIN + filter |
| 3 | 4.1.1 | Airflow | connect-k8s | SELECT + aggregation |
| 4 | 4.1.1 | Airflow | connect-k8s | JOIN + filter |

### Dependencies

- WS-006-01 (Helm charts)
- WS-012-01 (Core E2E)

### Code

```python
# tests/load/baseline/test_baseline_load_358.py
import pytest
from datetime import datetime, timedelta

@pytest.mark.timeout(2400)  # 40 minutes
def test_baseline_sustained_load_358(spark_connect_client):
    """
    Sustained load test: 1 query/second for 30 minutes
    Spark 3.5.8, Airflow, connect-k8s mode
    """
    duration_sec = 1800  # 30 minutes
    interval_sec = 1     # 1 query per second

    start_time = datetime.now()
    end_time = start_time + timedelta(seconds=duration_sec)

    metrics = {
        "queries_total": 0,
        "queries_success": 0,
        "queries_failed": 0,
        "latencies": []
    }

    while datetime.now() < end_time:
        try:
            query_start = datetime.now()
            result = spark_connect_client.sql("""
                SELECT
                    passenger_count,
                    SUM(fare_amount) as total_fare,
                    AVG(trip_distance) as avg_distance
                FROM nyc_taxi
                GROUP BY passenger_count
            """)
            result.collect()
            query_end = datetime.now()

            latency_ms = (query_end - query_start).total_seconds() * 1000
            metrics["latencies"].append(latency_ms)
            metrics["queries_success"] += 1
        except Exception as e:
            metrics["queries_failed"] += 1
        finally:
            metrics["queries_total"] += 1
            time.sleep(interval_sec)

    # Assertions
    error_rate = metrics["queries_failed"] / metrics["queries_total"]
    assert error_rate < 0.01, f"Error rate too high: {error_rate:.2%}"

    throughput = metrics["queries_total"] / duration_sec
    assert throughput >= 0.9, f"Throughput too low: {throughput:.2f} qps"

    return metrics
```

### Scope Estimate

- Files: 6
- Lines: ~600 (MEDIUM)
- Tokens: ~4500

### Constraints

- DO require E2E tests passing first
- DO use fixed executor/memory configuration
- DO NOT enable dynamic allocation
- DO use isolated namespace for load tests

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______
