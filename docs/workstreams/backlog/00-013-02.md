---
ws_id: 00-013-02
feature: F13
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-012-02  # GPU E2E
---

## WS-00-013-02: GPU load (4 scenarios)

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 4 GPU load test scenarios (Spark 4.1.0, 4.1.1 Ã— Airflow Ã— GPU)
- RAPIDS acceleration validation under sustained load
- GPU-specific metrics (memory, utilization, speedup vs CPU)

**Acceptance Criteria:**
- [ ] AC1: 4 GPU load test scenarios created
- [ ] AC2: Each test runs for 30 minutes sustained load
- [ ] AC3: GPU utilization > 60% sustained
- [ ] AC4: Speedup vs CPU >= 2x for heavy queries
- [ ] AC5: GPU memory stable (no leaks)
- [ ] AC6: Error rate < 1%

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Scenarios

| Scenario | Spark Version | Component | Mode | Queries |
|----------|---------------|-----------|------|---------|
| 1 | 4.1.0 | Airflow | connect-k8s | Heavy aggregation |
| 2 | 4.1.0 | Airflow | connect-k8s | Window functions |
| 3 | 4.1.1 | Airflow | connect-k8s | Heavy aggregation |
| 4 | 4.1.1 | Airflow | connect-k8s | Window functions |

### Dependencies

- WS-006-01 (Helm charts)
- WS-012-02 (GPU E2E)

### Code

```python
# tests/load/gpu/test_gpu_load_410.py
import pytest
import subprocess

@pytest.mark.timeout(2400)
def test_gpu_sustained_load_410(spark_connect_client):
    """
    Sustained load test: 0.5-1 query/second for 30 minutes
    Spark 4.1.0, Airflow, connect-k8s, GPU enabled
    Validates RAPIDS acceleration under load
    """
    duration_sec = 1800
    interval_sec = 2  # 0.5 qps (heavier queries)

    start_time = datetime.now()
    end_time = start_time + timedelta(seconds=duration_sec)

    metrics = {
        "queries_total": 0,
        "queries_success": 0,
        "latencies": [],
        "gpu_utilization": [],
        "gpu_memory_mb": []
    }

    while datetime.now() < end_time:
        try:
            # Heavy aggregation query (GPU accelerated)
            query_start = datetime.now()
            result = spark_connect_client.sql("""
                SELECT
                    passenger_count,
                    COUNT(*) as cnt,
                    AVG(fare_amount) as avg_fare,
                    STDDEV(trip_distance) as stddev_distance,
                    PERCENTILE(tip_amount, 0.5) as median_tip
                FROM nyc_taxi
                GROUP BY passenger_count
                HAVING COUNT(*) > 1000
            """)
            result.collect()
            query_end = datetime.now()

            latency_ms = (query_end - query_start).total_seconds() * 1000
            metrics["latencies"].append(latency_ms)
            metrics["queries_success"] += 1

            # Collect GPU metrics
            gpu_stats = subprocess.check_output(
                ["nvidia-smi", "--query-gpu=utilization.gpu,memory.used",
                 "--format=csv,noheader,nounits"]
            ).decode().strip().split(",")
            metrics["gpu_utilization"].append(int(gpu_stats[0]))
            metrics["gpu_memory_mb"].append(int(gpu_stats[1]))

        except Exception as e:
            metrics["queries_success"] -= 1
        finally:
            metrics["queries_total"] += 1
            time.sleep(interval_sec)

    # Assertions
    error_rate = (metrics["queries_total"] - metrics["queries_success"]) / metrics["queries_total"]
    assert error_rate < 0.01, f"Error rate too high: {error_rate:.2%}"

    avg_gpu_util = sum(metrics["gpu_utilization"]) / len(metrics["gpu_utilization"])
    assert avg_gpu_util > 60, f"GPU utilization too low: {avg_gpu_util:.1f}%"

    return metrics
```

### Scope Estimate

- Files: 6
- Lines: ~600 (MEDIUM)
- Tokens: ~4500

### Constraints

- DO require GPU E2E tests passing first
- DO use GPU-specific queries (heavy aggregations)
- DO monitor GPU memory for leaks
- DO NOT exceed 80% GPU memory

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______
