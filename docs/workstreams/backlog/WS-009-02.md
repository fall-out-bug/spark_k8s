# WS-009-02: Result Aggregation

## Goal
Создать систему агрегации результатов тестирования с историческим отслеживанием, trend analysis и алертингом.

### Acceptance Criteria
1. Result aggregation system создан в `tests/parallel/aggregator.py`
2. History tracking реализован (хранение предыдущих запусков)
3. Trend analysis работает (определение регрессий/улучшений)
4. Alerting механизмы реализованы (email, Slack, GitHub Status)
5. HTML отчеты генерируются
6. Coverage report aggregation
7. Performance metrics aggregation (latency percentiles, throughput)
8. Flaky test detection

## Context

**Существующая инфраструктура:**
- `tests/parallel/executor.py` — базовый ParallelExecutor (будет создан в WS-009-01)
- `tests/parallel/aggregator.py` — базовый ResultAggregator (будет создан в WS-009-01)

**Что нужно добавить:**
- Историческое хранение результатов (SQLite backend)
- Trend analysis для выявления регрессий
- Alerting механизмы
- HTML отчеты с графиками
- Flaky test detection
- Performance regression detection

## Dependency
WS-009-01 (Parallel Execution Framework)

## Input Files
- `tests/parallel/executor.py` (reference)
- `tests/parallel/aggregator.py` (reference - из WS-009-01)
- `scripts/run-smoke-tests.sh` (reference)

## Steps

### 1. Extend aggregator.py
- Add `HistoryManager` class for SQLite storage
- Add `TrendAnalyzer` class for regression detection
- Add `Alerter` class for notifications
- Add `HTMLReporter` class for visual reports
- Add `FlakyTestDetector` class

### 2. Implement SQLite storage
- Schema: test_runs, test_results, metrics tables
- Insert results after each run
- Query historical data for trends
- Cleanup old data (retention policy)

### 3. Implement trend analysis
- Compare current vs previous runs
- Detect performance regressions (>10% slowdown)
- Detect coverage regressions (>2% drop)
- Calculate moving averages

### 4. Implement alerting
- Email notifications (SMTP)
- Slack webhook
- GitHub commit status
- Threshold-based alerts

### 5. Implement HTML reporting
- Generate HTML with trend charts
- Include coverage badges
- Include performance metrics
- Include flaky test list

## Code

### tests/parallel/aggregator_extended.py

```python
"""Extended Result Aggregation with History, Trends, and Alerting"""

import json
import sqlite3
import smtplib
import statistics
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from urllib.parse import quote
from urllib.request import Request, urlopen
import xml.etree.ElementTree as ET

from tests.parallel.executor import TestResult, TestStatus


@dataclass
class TestRun:
    """Metadata for a test run"""
    run_id: int
    timestamp: str
    branch: str
    commit: str
    trigger: str  # 'manual', 'ci', 'scheduled'
    total_tests: int
    passed: int
    failed: int
    skipped: int
    duration: float


@dataclass
class TrendMetric:
    """Trend analysis result"""
    metric_name: str
    current_value: float
    previous_value: float
    change_percent: float
    trend: str  # 'improved', 'regressed', 'stable'
    significant: bool


class HistoryManager:
    """Manage historical test results in SQLite"""

    def __init__(self, db_path: Path = Path("test_history.db")):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """Initialize SQLite database schema"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Test runs table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS test_runs (
                run_id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                branch TEXT NOT NULL,
                commit TEXT NOT NULL,
                trigger TEXT NOT NULL,
                total_tests INTEGER NOT NULL,
                passed INTEGER NOT NULL,
                failed INTEGER NOT NULL,
                skipped INTEGER NOT NULL,
                duration REAL NOT NULL
            )
        """)

        # Test results table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS test_results (
                result_id INTEGER PRIMARY KEY AUTOINCREMENT,
                run_id INTEGER NOT NULL,
                test_name TEXT NOT NULL,
                test_file TEXT NOT NULL,
                status TEXT NOT NULL,
                duration REAL NOT NULL,
                error_message TEXT,
                retry_count INTEGER DEFAULT 0,
                FOREIGN KEY (run_id) REFERENCES test_runs(run_id)
            )
        """)

        # Metrics table (for performance, coverage, etc.)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS metrics (
                metric_id INTEGER PRIMARY KEY AUTOINCREMENT,
                run_id INTEGER NOT NULL,
                metric_name TEXT NOT NULL,
                metric_value REAL NOT NULL,
                tags TEXT,
                FOREIGN KEY (run_id) REFERENCES test_runs(run_id)
            )
        """)

        # Flaky tests table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS flaky_tests (
                test_id INTEGER PRIMARY KEY AUTOINCREMENT,
                test_name TEXT NOT NULL UNIQUE,
                total_runs INTEGER NOT NULL,
                failed_runs INTEGER NOT NULL,
                flaky_rate REAL NOT NULL,
                last_seen TEXT NOT NULL
            )
        """)

        conn.commit()
        conn.close()

    def store_run(self, results: Dict[str, TestResult], metadata: Dict[str, Any]) -> int:
        """Store a test run in the database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Insert test run
        total = len(results)
        passed = sum(1 for r in results.values() if r.status == TestStatus.PASSED)
        failed = sum(1 for r in results.values() if r.status == TestStatus.FAILED)
        skipped = sum(1 for r in results.values() if r.status == TestStatus.SKIPPED)
        duration = sum(r.duration for r in results.values())

        cursor.execute("""
            INSERT INTO test_runs (timestamp, branch, commit, trigger, total_tests, passed, failed, skipped, duration)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            metadata.get('timestamp', datetime.now().isoformat()),
            metadata.get('branch', 'unknown'),
            metadata.get('commit', 'unknown'),
            metadata.get('trigger', 'manual'),
            total, passed, failed, skipped, duration
        ))

        run_id = cursor.lastrowid

        # Insert test results
        for result in results.values():
            cursor.execute("""
                INSERT INTO test_results (run_id, test_name, test_file, status, duration, error_message, retry_count)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                run_id, result.name, result.file, result.status.value,
                result.duration, result.error_message, result.retry_count
            ))

        # Insert metrics
        for metric_name, metric_value in metadata.get('metrics', {}).items():
            cursor.execute("""
                INSERT INTO metrics (run_id, metric_name, metric_value, tags)
                VALUES (?, ?, ?, ?)
            """, (run_id, metric_name, float(metric_value), metadata.get('tags', '')))

        conn.commit()
        conn.close()

        return run_id

    def get_previous_run(self, branch: str, limit: int = 1) -> Optional[TestRun]:
        """Get the previous run on a branch"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT run_id, timestamp, branch, commit, trigger, total_tests, passed, failed, skipped, duration
            FROM test_runs
            WHERE branch = ?
            ORDER BY timestamp DESC
            LIMIT ?
        """, (branch, limit + 1))

        rows = cursor.fetchall()
        conn.close()

        if len(rows) <= 1:
            return None

        row = rows[-1]  # Get the second-to-last row
        return TestRun(*row)

    def get_recent_runs(self, branch: str, days: int = 7) -> List[TestRun]:
        """Get recent runs for trend analysis"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        since = (datetime.now() - timedelta(days=days)).isoformat()

        cursor.execute("""
            SELECT run_id, timestamp, branch, commit, trigger, total_tests, passed, failed, skipped, duration
            FROM test_runs
            WHERE branch = ? AND timestamp > ?
            ORDER BY timestamp ASC
        """, (branch, since))

        rows = cursor.fetchall()
        conn.close()

        return [TestRun(*row) for row in rows]


class TrendAnalyzer:
    """Analyze test trends for regressions and improvements"""

    def __init__(self, history: HistoryManager):
        self.history = history

    def analyze_suite_trends(self, branch: str) -> List[TrendMetric]:
        """Analyze overall test suite trends"""
        recent_runs = self.history.get_recent_runs(branch, days=7)

        if len(recent_runs) < 2:
            return []

        current = recent_runs[-1]
        previous = recent_runs[-2]

        metrics = []

        # Pass rate trend
        current_pass_rate = current.passed / current.total_tests if current.total_tests > 0 else 0
        previous_pass_rate = previous.passed / previous.total_tests if previous.total_tests > 0 else 0
        pass_rate_change = (current_pass_rate - previous_pass_rate) / previous_pass_rate if previous_pass_rate > 0 else 0

        metrics.append(TrendMetric(
            metric_name="pass_rate",
            current_value=current_pass_rate * 100,
            previous_value=previous_pass_rate * 100,
            change_percent=pass_rate_change * 100,
            trend="improved" if pass_rate_change > 0.01 else "regressed" if pass_rate_change < -0.01 else "stable",
            significant=abs(pass_rate_change) > 0.02  # 2% threshold
        ))

        # Duration trend
        duration_change = (current.duration - previous.duration) / previous.duration if previous.duration > 0 else 0

        metrics.append(TrendMetric(
            metric_name="duration",
            current_value=current.duration,
            previous_value=previous.duration,
            change_percent=duration_change * 100,
            trend="improved" if duration_change < -0.05 else "regressed" if duration_change > 0.05 else "stable",
            significant=abs(duration_change) > 0.10  # 10% threshold
        ))

        return metrics

    def analyze_performance_trends(self, branch: str, test_name: str) -> List[TrendMetric]:
        """Analyze performance trends for a specific test"""
        conn = self.history.db_path
        cursor = sqlite3.connect(conn).cursor()

        # Get last 10 runs for this test
        cursor.execute("""
            SELECT r.duration, r.timestamp
            FROM test_results r
            JOIN test_runs t ON r.run_id = t.run_id
            WHERE r.test_name = ? AND t.branch = ?
            ORDER BY t.timestamp DESC
            LIMIT 10
        """, (test_name, branch))

        rows = cursor.fetchall()
        sqlite3.connect(conn).close()

        if len(rows) < 2:
            return []

        durations = [row[0] for row in rows]
        current = durations[0]
        previous_avg = statistics.mean(durations[1:6]) if len(durations) >= 6 else statistics.mean(durations[1:])

        change = (current - previous_avg) / previous_avg if previous_avg > 0 else 0

        return [TrendMetric(
            metric_name=f"{test_name}_duration",
            current_value=current,
            previous_value=previous_avg,
            change_percent=change * 100,
            trend="improved" if change < -0.10 else "regressed" if change > 0.10 else "stable",
            significant=abs(change) > 0.15  # 15% threshold
        )]

    def detect_regression(self, metrics: List[TrendMetric]) -> List[str]:
        """Detect significant regressions"""
        regressions = []

        for metric in metrics:
            if metric.trend == "regressed" and metric.significant:
                regressions.append(
                    f"{metric.metric_name}: {metric.previous_value:.2f} → {metric.current_value:.2f} "
                    f"({metric.change_percent:+.1f}%)"
                )

        return regressions


class Alerter:
    """Send alerts for test results"""

    def __init__(self, config: Dict[str, Any]):
        self.smtp_host = config.get('smtp_host')
        self.smtp_port = config.get('smtp_port', 587)
        self.smtp_user = config.get('smtp_user')
        self.smtp_password = config.get('smtp_password')
        self.from_email = config.get('from_email')
        self.to_emails = config.get('to_emails', [])

        self.slack_webhook = config.get('slack_webhook')
        self.github_token = config.get('github_token')
        self.github_repo = config.get('github_repo')

    def send_email_alert(self, subject: str, body: str, is_html: bool = False):
        """Send email notification"""
        if not self.smtp_host or not self.to_emails:
            return

        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = self.from_email
        msg['To'] = ', '.join(self.to_emails)

        if is_html:
            msg.attach(MIMEText(body, 'html'))
        else:
            msg.attach(MIMEText(body, 'plain'))

        with smtplib.SMTP(self.smtp_host, self.smtp_port) as server:
            server.starttls()
            if self.smtp_user and self.smtp_password:
                server.login(self.smtp_user, self.smtp_password)
            server.send_message(msg)

    def send_slack_alert(self, message: str, color: str = 'good'):
        """Send Slack webhook notification"""
        if not self.slack_webhook:
            return

        payload = json.dumps({
            "attachments": [{
                "color": color,
                "text": message
            }]
        }).encode('utf-8')

        req = Request(self.slack_webhook, data=payload, headers={'Content-Type': 'application/json'})

        with urlopen(req) as response:
            response.read()

    def set_github_status(self, commit: str, state: str, description: str, context: str = "ci/tests"):
        """Set GitHub commit status"""
        if not self.github_token or not self.github_repo:
            return

        url = f"https://api.github.com/repos/{self.github_repo}/statuses/{commit}"
        payload = json.dumps({
            "state": state,  # 'success', 'failure', 'pending'
            "description": description,
            "context": context
        }).encode('utf-8')

        req = Request(url, data=payload, headers={
            'Content-Type': 'application/json',
            'Authorization': f'token {self.github_token}'
        })

        with urlopen(req) as response:
            response.read()

    def alert_on_results(self, results: Dict[str, TestResult], trends: List[TrendMetric], metadata: Dict[str, Any]):
        """Send appropriate alerts based on results"""
        total = len(results)
        passed = sum(1 for r in results.values() if r.status == TestStatus.PASSED)
        failed = sum(1 for r in results.values() if r.status == TestStatus.FAILED)

        # Determine status
        if failed == 0:
            status = "success"
            color = "good"
            state = "success"
        elif failed <= total * 0.1:  # Up to 10% failures
            status = "partial"
            color = "warning"
            state = "failure"
        else:
            status = "failure"
            color = "danger"
            state = "failure"

        # Email subject
        subject = f"Test Results: {status.upper()} - {passed}/{total} passed"

        # Email body
        body_lines = [
            f"Test Run Summary",
            f"=" * 60,
            f"Total:  {total}",
            f"Passed: {passed}",
            f"Failed: {failed}",
            f"Skipped: {sum(1 for r in results.values() if r.status == TestStatus.SKIPPED)}",
            f"Duration: {sum(r.duration for r in results.values()):.2f}s",
            f"Branch: {metadata.get('branch', 'unknown')}",
            f"Commit: {metadata.get('commit', 'unknown')[:8]}",
            ""
        ]

        if failed > 0:
            body_lines.append("Failed tests:")
            for name, result in results.items():
                if result.status == TestStatus.FAILED:
                    body_lines.append(f"  - {name}: {result.error_message[:100]}")

        # Add trends
        if trends:
            body_lines.append("\nTrends:")
            for trend in trends:
                if trend.significant:
                    symbol = "↗" if trend.trend == "regressed" else "↘" if trend.trend == "improved" else "→"
                    body_lines.append(f"  {symbol} {trend.metric_name}: {trend.change_percent:+.1f}%")

        body = "\n".join(body_lines)

        # Send alerts
        self.send_email_alert(subject, body)
        self.send_slack_alert(f"```{body}```", color)

        # Set GitHub status
        self.set_github_status(
            metadata.get('commit', ''),
            state,
            f"{passed}/{total} tests passed",
            context="ci/tests"
        )


class HTMLReporter:
    """Generate HTML reports with trends and charts"""

    def __init__(self, output_dir: Path = Path("test-reports")):
        self.output_dir = output_dir
        self.output_dir.mkdir(exist_ok=True)

    def generate_report(self, results: Dict[str, TestResult], trends: List[TrendMetric],
                        metadata: Dict[str, Any], filename: str = "report.html"):
        """Generate HTML test report"""
        total = len(results)
        passed = sum(1 for r in results.values() if r.status == TestStatus.PASSED)
        failed = sum(1 for r in results.values() if r.status == TestStatus.FAILED)
        skipped = sum(1 for r in results.values() if r.status == TestStatus.SKIPPED)
        duration = sum(r.duration for r in results.values())

        pass_rate = (passed / total * 100) if total > 0 else 0

        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Test Report - {metadata.get('branch', 'unknown')}</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 40px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1 {{ color: #333; border-bottom: 2px solid #0366d6; padding-bottom: 10px; }}
        .summary {{ display: flex; justify-content: space-between; margin: 20px 0; }}
        .metric {{ text-align: center; padding: 20px; background: #f8f9fa; border-radius: 6px; min-width: 120px; }}
        .metric-value {{ font-size: 32px; font-weight: bold; }}
        .metric-label {{ color: #666; font-size: 14px; }}
        .passed {{ color: #28a745; }}
        .failed {{ color: #dc3545; }}
        .skipped {{ color: #ffc107; }}
        .tests {{ margin-top: 30px; }}
        .test {{ padding: 15px; margin: 10px 0; border-left: 4px solid #ddd; background: #f8f9fa; }}
        .test.passed {{ border-left-color: #28a745; }}
        .test.failed {{ border-left-color: #dc3545; }}
        .test.skipped {{ border-left-color: #ffc107; }}
        .test-name {{ font-weight: bold; }}
        .test-meta {{ color: #666; font-size: 12px; }}
        .error {{ background: #ffebee; padding: 10px; margin-top: 10px; border-radius: 4px; font-family: monospace; }}
        .trends {{ margin-top: 30px; }}
        .trend {{ padding: 10px; margin: 5px 0; border-radius: 4px; }}
        .trend.improved {{ background: #d4edda; }}
        .trend.regressed {{ background: #f8d7da; }}
        .trend.stable {{ background: #e2e3e5; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>Test Report</h1>
        <p style="color: #666;">
            Branch: <strong>{metadata.get('branch', 'unknown')}</strong> |
            Commit: <code>{metadata.get('commit', 'unknown')[:8]}</code> |
            {metadata.get('timestamp', '')}
        </p>

        <div class="summary">
            <div class="metric">
                <div class="metric-value passed">{passed}</div>
                <div class="metric-label">Passed</div>
            </div>
            <div class="metric">
                <div class="metric-value failed">{failed}</div>
                <div class="metric-label">Failed</div>
            </div>
            <div class="metric">
                <div class="metric-value skipped">{skipped}</div>
                <div class="metric-label">Skipped</div>
            </div>
            <div class="metric">
                <div class="metric-value">{pass_rate:.1f}%</div>
                <div class="metric-label">Pass Rate</div>
            </div>
            <div class="metric">
                <div class="metric-value">{duration:.0f}s</div>
                <div class="metric-label">Duration</div>
            </div>
        </div>

        <h2 style="color: #333;">Tests</h2>
        <div class="tests">
"""

        for result in sorted(results.values(), key=lambda r: (r.status != TestStatus.FAILED, r.name)):
            status_class = result.status.value
            html += f"""
            <div class="test {status_class}">
                <div class="test-name">{result.name}</div>
                <div class="test-meta">
                    {result.file} | {result.duration:.2f}s
                </div>
"""
            if result.error_message:
                html += f'<div class="error">{self._escape_html(result.error_message[:500])}</div>'

            html += "    </div>"

        # Add trends section
        if trends:
            html += '<h2 style="color: #333; margin-top: 30px;">Trends</h2><div class="trends">'
            for trend in trends:
                if trend.significant:
                    symbol = "↘" if trend.trend == "improved" else "↗" if trend.trend == "regressed" else "→"
                    html += f"""
                    <div class="trend {trend.trend}">
                        <strong>{symbol} {trend.metric_name}</strong>:
                        {trend.previous_value:.2f} → {trend.current_value:.2f}
                        ({trend.change_percent:+.1f}%)
                    </div>
"""
            html += "</div>"

        html += """
        </div>
    </div>
</body>
</html>
"""

        output_path = self.output_dir / filename
        with open(output_path, 'w') as f:
            f.write(html)

        return output_path

    def _escape_html(self, text: str) -> str:
        """Escape HTML special characters"""
        return (text
                .replace('&', '&amp;')
                .replace('<', '&lt;')
                .replace('>', '&gt;')
                .replace('"', '&quot;')
                .replace("'", '&#039;'))


class FlakyTestDetector:
    """Detect flaky tests from historical data"""

    def __init__(self, history: HistoryManager):
        self.history = history

    def detect_flaky_tests(self, branch: str, min_runs: int = 10, flaky_threshold: float = 0.3) -> List[Tuple[str, float]]:
        """Detect flaky tests on a branch"""
        conn = sqlite3.connect(self.history.db_path)
        cursor = conn.cursor()

        # Get all tests with multiple runs
        cursor.execute("""
            SELECT test_name,
                   COUNT(*) as total_runs,
                   SUM(CASE WHEN status = 'failed' THEN 1 ELSE 0 END) as failed_runs
            FROM test_results r
            JOIN test_runs t ON r.run_id = t.run_id
            WHERE t.branch = ?
            GROUP BY test_name
            HAVING total_runs >= ?
        """, (branch, min_runs))

        flaky_tests = []
        for test_name, total_runs, failed_runs in cursor.fetchall():
            flaky_rate = failed_runs / total_runs

            # Flaky if: fails sometimes but not always
            if 0.1 <= flaky_rate <= flaky_threshold:
                flaky_tests.append((test_name, flaky_rate))

        conn.close()

        return sorted(flaky_tests, key=lambda x: x[1], reverse=True)

    def update_flaky_test_tracking(self, branch: str):
        """Update flaky tests table"""
        flaky_tests = self.detect_flaky_tests(branch)

        conn = sqlite3.connect(self.history.db_path)
        cursor = conn.cursor()

        for test_name, flaky_rate in flaky_tests:
            cursor.execute("""
                INSERT OR REPLACE INTO flaky_tests (test_name, total_runs, failed_runs, flaky_rate, last_seen)
                VALUES (
                    ?,
                    (SELECT COUNT(*) FROM test_results r JOIN test_runs t ON r.run_id = t.run_id WHERE r.test_name = ? AND t.branch = ?),
                    (SELECT SUM(CASE WHEN r.status = 'failed' THEN 1 ELSE 0 END) FROM test_results r JOIN test_runs t ON r.run_id = t.run_id WHERE r.test_name = ? AND t.branch = ?),
                    ?,
                    ?
                )
            """, (test_name, test_name, branch, test_name, branch, flaky_rate, datetime.now().isoformat()))

        conn.commit()
        conn.close()
```

## Scope Estimate
- Files: 1 (aggregator_extended.py)
- LOC: ~700 (HistoryManager, TrendAnalyzer, Alerter, HTMLReporter, FlakyTestDetector)
- Size: MEDIUM
