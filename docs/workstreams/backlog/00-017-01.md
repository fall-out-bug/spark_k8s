---
ws_id: 00-017-01
feature: F17
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-011-01  # Spark 3.5 images
  - 00-011-02  # Spark 4.1 images
---

## WS-00-017-01: Spark Connect Go client library

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- Spark Connect Go client library
- gRPC integration with Spark Connect server
- SQL execution
- DataFrame operations
- Session management

**Acceptance Criteria:**
- [ ] AC1: Go client library ÑÐ¾Ð·Ð´Ð°Ð½
- [ ] AC2: gRPC ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ñ Spark Connect Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- [ ] AC3: SQL query execution Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- [ ] AC4: DataFrame collect Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- [ ] AC5: Session management Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚
- [ ] AC6: Error handling Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Dependencies

Phase 0 (F06), Phase 5 (F11)

### Code

```go
// tests/go/client/connect.go
// NOTE: This is a placeholder implementation structure.
// When official Apache Spark Connect Go client is available from
// https://github.com/apache/spark/tree/master/connect/client/go,
// switch to using that instead of custom gRPC implementation.

package spark

import (
	"context"
	"fmt"
	"time"
)

// Client represents a Spark Connect client
// This will use official Apache Spark Connect Go client when available
type Client struct {
	endpoint  string
	sessionID string
	timeout   time.Duration
}

// ClientOption configures a Spark Connect client
type ClientOption func(*Client)

// WithTimeout sets request timeout
func WithTimeout(timeout time.Duration) ClientOption {
	return func(c *Client) {
		c.timeout = timeout
	}
}

// WithTLS enables TLS connection
func WithTLS(config interface{}) ClientOption {
	return func(c *Client) {
		// Configure TLS credentials
	}
}

// NewClient creates a new Spark Connect client
func NewClient(ctx context.Context, endpoint string, opts ...ClientOption) (*Client, error) {
	client := &Client{
		endpoint: endpoint,
		timeout:  30 * time.Second,
	}

	// Apply options
	for _, opt := range opts {
		opt(client)
	}

	// TODO: Implement gRPC connection using official Spark Connect Go client
	// Reference: https://github.com/apache/spark/tree/master/connect/client/go
	return client, nil
}

// Close closes client connection
func (c *Client) Close() error {
	// TODO: Implement using official client
	return nil
}

// Session represents a Spark session
type Session struct {
	client    *Client
	sessionID string
	config    map[string]string
}

// CreateSession creates a new Spark session
func (c *Client) CreateSession(ctx context.Context) (*Session, error) {
	// TODO: Implement using official Spark Connect Go client
	sessionID := fmt.Sprintf("session-%d", time.Now().UnixNano())

	return &Session{
		client:    c,
		sessionID: sessionID,
		config:    make(map[string]string),
	}, nil
}

// ID returns the session ID
func (s *Session) ID() string {
	return s.sessionID
}

// Close closes the session
func (s *Session) Close(ctx context.Context) error {
	// TODO: Implement using official client
	return nil
}

// DataFrame represents a Spark DataFrame
type DataFrame struct {
	session *Session
	query    string
}

// SQL executes a SQL query and returns a DataFrame
func (s *Session) SQL(ctx context.Context, query string) (*DataFrame, error) {
	// TODO: Implement using official Spark Connect Go client
	return &DataFrame{
		session: s,
		query:    query,
	}, nil
}

// Collect collects all rows from the DataFrame
func (df *DataFrame) Collect(ctx context.Context) ([]Row, error) {
	// TODO: Implement using official Spark Connect Go client
	return make([]Row, 0), nil
}

// Show prints the first 20 rows
func (df *DataFrame) Show(ctx context.Context) error {
	// TODO: Implement using official client
	fmt.Printf("DataFrame: %s\n", df.query)
	return nil
}

// Count returns the number of rows
func (df *DataFrame) Count(ctx context.Context) (int64, error) {
	// TODO: Implement using official client
	return 0, nil
}

// Row represents a single row
type Row struct {
	values []interface{}
}

// String returns a string representation of the row
func (r *Row) String() string {
	return fmt.Sprint(r.values)
}

// GetInt gets an int value at index
func (r *Row) GetInt(i int) (int32, error) {
	if i >= len(r.values) {
		return 0, fmt.Errorf("index out of bounds")
	}
	val, ok := r.values[i].(int32)
	if !ok {
		return 0, fmt.Errorf("value at %d is not an int32", i)
	}
	return val, nil
}

// GetString gets a string value at index
func (r *Row) GetString(i int) (string, error) {
	if i >= len(r.values) {
		return "", fmt.Errorf("index out of bounds")
	}
	val, ok := r.values[i].(string)
	if !ok {
		return "", fmt.Errorf("value at %d is not a string", i)
	}
	return val, nil
}

// GetFloat gets a float value at index
func (r *Row) GetFloat(i int) (float64, error) {
	if i >= len(r.values) {
		return 0.0, fmt.Errorf("index out of bounds")
	}
	val, ok := r.values[i].(float64)
	if !ok {
		return 0.0, fmt.Errorf("value at %d is not a float64", i)
	}
	return val, nil
}
```

### Scope Estimate

- Files: 8
- Lines: ~800 (MEDIUM)
- Tokens: ~6000

### Constraints

- DO use official Spark Connect gRPC protocol
- DO support Spark 3.5+ and 4.1+
- DO use TLS for production connections
- DO handle connection errors gracefully
- DO NOT support Spark < 3.5 (no Connect)

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______
