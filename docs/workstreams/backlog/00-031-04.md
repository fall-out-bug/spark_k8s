# WS-031-04: CatBoost Training - pandas UDF

## Summary
Parallel CatBoost training using Spark pandas UDF for multiple borough models.

## Scope
- Implement pandas UDF for distributed CatBoost training
- Train separate models per borough
- Multi-target regression (revenue + trip_count)
- Save models to MinIO

## Acceptance Criteria
- [ ] pandas UDF trains models in parallel on workers
- [ ] Separate models for each borough
- [ ] Multi-target predictions work
- [ ] Models saved to `s3a://ml-models/taxi-predictor/`
- [ ] Training metrics logged

## Technical Details

### pandas UDF Implementation
```python
# dags/spark_jobs/catboost_trainer.py

import pandas as pd
import pickle
from pyspark.sql.functions import pandas_udf
from pyspark.sql.types import BinaryType, StringType, StructType, StructField
from catboost import CatBoostRegressor, Pool

# Schema for output
model_schema = StructType([
    StructField("borough", StringType(), False),
    StructField("model_binary", BinaryType(), False),
    StructField("mape_revenue", StringType(), False),
    StructField("mape_trips", StringType(), False),
])

@pandas_udf(model_schema)
def train_catboost_borough(df: pd.DataFrame) -> pd.DataFrame:
    """
    Train CatBoost model for a single borough.
    Called once per partition (borough).
    """
    borough = df['borough'].iloc[0]

    # Features
    feature_cols = [
        'hour_of_day', 'day_of_week', 'is_weekend', 'is_holiday',
        'month', 'is_rush_hour', 'trip_distance', 'avg_speed',
        'avg_trips_zone_hour_l30d', 'avg_revenue_zone_day_l30d',
        'trips_same_day_last_week', 'revenue_ma_7d'
    ]

    X = df[feature_cols]
    y_revenue = df['total_amount_7d']
    y_trips = df['trip_count_7d']

    # Train/test split (last 7 days for test)
    split_date = df['date'].max() - pd.Timedelta(days=7)
    X_train, X_test = X[df['date'] <= split_date], X[df['date'] > split_date]
    y_rev_train, y_rev_test = y_revenue[df['date'] <= split_date], y_revenue[df['date'] > split_date]
    y_trip_train, y_trip_test = y_trips[df['date'] <= split_date], y_trips[df['date'] > split_date]

    # Train revenue model
    model_rev = CatBoostRegressor(
        iterations=500,
        depth=8,
        learning_rate=0.05,
        loss_function='RMSE',
        verbose=False,
    )
    model_rev.fit(X_train, y_rev_train, eval_set=(X_test, y_rev_test), early_stopping_rounds=50)

    # Train trips model
    model_trips = CatBoostRegressor(
        iterations=500,
        depth=8,
        learning_rate=0.05,
        loss_function='RMSE',
        verbose=False,
    )
    model_trips.fit(X_train, y_trip_train, eval_set=(X_test, y_trip_test), early_stopping_rounds=50)

    # Calculate MAPE
    pred_rev = model_rev.predict(X_test)
    pred_trips = model_trips.predict(X_test)
    mape_rev = mean_absolute_percentage_error(y_rev_test, pred_rev)
    mape_trips = mean_absolute_percentage_error(y_trip_test, pred_trips)

    # Serialize both models
    models = {
        'revenue': model_rev,
        'trips': model_trips,
    }

    return pd.DataFrame({
        'borough': [borough],
        'model_binary': [pickle.dumps(models)],
        'mape_revenue': [f'{mape_rev:.4f}'],
        'mape_trips': [f'{mape_trips:.4f}'],
    })
```

### Model Storage
```
s3a://ml-models/taxi-predictor/
├── v20260220/
│   ├── manhattan.pkl
│   ├── brooklyn.pkl
│   ├── queens.pkl
│   └── bronx_si.pkl
├── latest/
│   └── (symlink to latest version)
└── metrics/
    └── v20260220.json
```

### Requirements
```
catboost>=1.2.0
pandas>=2.0.0
scikit-learn>=1.3.0
```

## Dependencies
- WS-031-02 (features ready)
- CatBoost installed in spark-custom image
- pandas UDF support in PySpark

## Estimated Complexity
High - pandas UDF + multi-target training

## Files to Create/Modify
- `dags/spark_jobs/catboost_trainer.py` (new)
- `docker/spark-custom/requirements.txt` (add catboost)
