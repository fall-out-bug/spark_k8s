# WS-006-01: Core E2E Tests

## Goal
Создать 24 core E2E тестов для проверки базовой функциональности Spark на Kubernetes с использованием полного датасета NYC Taxi (11GB).

### Acceptance Criteria
1. 24 core E2E тестов созданы в `tests/e2e/phase06/test_06_01_core_e2e.py`
2. NYC Taxi full dataset (11GB) используется для тестов
3. 4 SQL запроса выполняются для каждой комбинации (версия × режим × компонент)
4. Метрики собираются (execution time, throughput, resources)
5. Результаты валидируются (row count, checksum)
6. Timeout механизмы работают для каждого запроса
7. Все тесты используют pytest fixtures для повторного использования
8. Тесты работают с spark-connect и spark-k8s-submit

## Context

**Существующая инфраструктура:**
- `tests/e2e/test_e2e.py` — существующие E2E тесты с базовыми сценариями
- `scripts/run-smoke-tests.sh` — скрипт для запуска smoke тестов
- NYC Taxi dataset доступен для тестов

**Что нужно добавить:**
- Структурированные E2E тесты для core сценариев
- Использование полного датасета (11GB)
- Метрики collection framework
- Timeout механизмы
- Валидация результатов
- Отдельный файл `tests/e2e/phase06/test_06_01_core_e2e.py`

## Dependency
Phase 0 (Helm Charts), Phase 1 (Security), Phase 5 (Final Images)

## Input Files
- `tests/e2e/test_e2e.py` (reference)
- `charts/spark-3.5/values.yaml`
- `charts/spark-4.1/values.yaml`
- `scripts/run-smoke-tests.sh`

## Steps

### 1. Create Phase 6 E2E conftest.py
- Создать `tests/e2e/phase06/conftest.py`
- Добавить fixtures для NYC Taxi dataset
- Добавить fixtures для Spark session (connect, k8s-submit)
- Добавить fixtures для metrics collection
- Добавить fixtures для timeout handling

### 2. Create test_06_01_core_e2e.py
- Создать `tests/e2e/phase06/test_06_01_core_e2e.py`
- Implement 24 test scenarios

### 3. Implement test scenarios

**Spark Versions × Modes × Components:**

**Spark 3.5.7:**
1. spark-connect + k8s (baseline)
2. spark-connect + k8s (jupyter)
3. spark-k8s-submit + k8s (baseline)
4. spark-k8s-submit + k8s (jupyter)

**Spark 3.5.8:**
5. spark-connect + k8s (baseline)
6. spark-connect + k8s (jupyter)
7. spark-k8s-submit + k8s (baseline)
8. spark-k8s-submit + k8s (jupyter)

**Spark 4.1.0:**
9. spark-connect + k8s (baseline)
10. spark-connect + k8s (jupyter)
11. spark-k8s-submit + k8s (baseline)
12. spark-k8s-submit + k8s (jupyter)

**Spark 4.1.1:**
13. spark-connect + k8s (baseline)
14. spark-connect + k8s (jupyter)
15. spark-k8s-submit + k8s (baseline)
16. spark-k8s-submit + k8s (jupyter)

**Queries (4 SQL queries per scenario):**
- Q1: Simple SELECT COUNT(*) — validate row count
- Q2: GROUP BY aggregation — validate aggregation
- Q3: JOIN with filter — validate join performance
- Q4: Window function — validate complex queries

**Total: 16 scenarios × 4 queries = 64 tests**
(Упрощено до 24 основных сценариев для core E2E)

### 4. Metrics Collection
- execution_time: время выполнения каждого query
- throughput: rows/second
- memory_used: peak memory consumption
- cpu_used: CPU time

### 5. Run tests
- `pytest tests/e2e/phase06/test_06_01_core_e2e.py -v`
- Убедиться что все тесты проходят

## Code

### tests/e2e/phase06/conftest.py

```python
"""Shared fixtures for Phase 6 E2E tests"""

import pytest
import time
import subprocess
from pathlib import Path
from typing import Dict, Any
from pyspark.sql import SparkSession

@pytest.fixture(scope="session")
def project_root() -> Path:
    """Project root directory"""
    return Path(__file__).parent.parent.parent.parent

@pytest.fixture(scope="session")
def nyc_taxi_dataset_path() -> Path:
    """Path to NYC Taxi full dataset (11GB)"""
    # Assuming dataset is stored in tests/data/nyc_taxi/
    return Path(__file__).parent.parent.parent / "data" / "nyc_taxi" / "full"

@pytest.fixture(scope="session")
def nyc_taxi_sample_path() -> Path:
    """Path to NYC Taxi sample dataset (for quick testing)"""
    return Path(__file__).parent.parent.parent / "data" / "nyc_taxi" / "sample"

@pytest.fixture(scope="session")
def spark_connect_session():
    """Create Spark Connect session"""
    # This should connect to running Spark Connect server
    # For E2E tests, we assume Spark is already deployed
    spark = SparkSession.builder \
        .remote("sc://localhost:15002") \
        .appName("E2E Test") \
        .getOrCreate()
    yield spark
    spark.stop()

@pytest.fixture(scope="session")
def metrics_collector():
    """Metrics collector for E2E tests"""
    metrics = {}

    def collect_metric(test_name: str, metric_name: str, value: Any):
        if test_name not in metrics:
            metrics[test_name] = {}
        metrics[test_name][metric_name] = value

    yield collect_metric

    # Print summary at end
    print("\n=== E2E Test Metrics ===")
    for test_name, test_metrics in metrics.items():
        print(f"\n{test_name}:")
        for metric_name, value in test_metrics.items():
            print(f"  {metric_name}: {value}")

@pytest.fixture
def query_timeout(request):
    """Timeout for each query (default 300 seconds)"""
    return getattr(request.node, 'get_closest_marker', lambda x: None)('timeout') or 300

@pytest.fixture
def e2e_queries():
    """Standard E2E queries"""
    return {
        "q1_count": "SELECT COUNT(*) AS row_count FROM nyc_taxi",
        "q2_groupby": """
            SELECT passenger_count, COUNT(*) AS trip_count, AVG(total_amount) AS avg_fare
            FROM nyc_taxi
            GROUP BY passenger_count
            ORDER BY passenger_count
        """,
        "q3_join": """
            SELECT t1.passenger_count, COUNT(*) AS trip_count
            FROM nyc_taxi t1
            INNER JOIN nyc_taxi t2 ON t1.passenger_count = t2.passenger_count
            WHERE t1.trip_distance > 5 AND t2.trip_distance > 5
            GROUP BY t1.passenger_count
            ORDER BY t1.passenger_count
        """,
        "q4_window": """
            SELECT
                passenger_count,
                trip_distance,
                ROW_NUMBER() OVER (PARTITION BY passenger_count ORDER BY total_amount DESC) AS rank_by_fare,
                AVG(total_amount) OVER (PARTITION BY passenger_count) AS avg_fare_by_pax
            FROM nyc_taxi
            WHERE passenger_count > 0
            LIMIT 1000
        """
    }
```

### tests/e2e/phase06/test_06_01_core_e2e.py

```python
"""Core E2E Tests for Phase 6

Tests for basic Spark functionality with NYC Taxi full dataset (11GB).
"""

import pytest
import time
from pyspark.sql import SparkSession
from typing import Dict, Any

SPARK_VERSIONS = ["3.5.7", "3.5.8", "4.1.0", "4.1.1"]
SPARK_MODES = ["spark-connect", "spark-k8s-submit"]
COMPONENTS = ["baseline", "jupyter"]

class TestCoreE2E:
    """Core E2E tests for all Spark versions and modes"""

    @pytest.mark.timeout(600)
    def test_01_spark_357_connect_baseline_q1_count(self, spark_connect_session, nyc_taxi_dataset_path, metrics_collector):
        """Spark 3.5.7 spark-connect baseline - Q1: COUNT(*)"""
        start_time = time.time()

        # Load data
        df = spark_connect_session.read.parquet(str(nyc_taxi_dataset_path))
        df.createOrReplaceTempView("nyc_taxi")

        # Execute query
        result = spark_connect_session.sql("SELECT COUNT(*) AS row_count FROM nyc_taxi")
        count = result.collect()[0]['row_count']

        execution_time = time.time() - start_time

        # Validate
        assert count > 0, "Row count should be greater than 0"
        assert count > 1000000, "Full dataset should have more than 1M rows"

        # Collect metrics
        metrics_collector(self._testMethodName, "execution_time", execution_time)
        metrics_collector(self._testMethodName, "row_count", count)
        metrics_collector(self._testMethodName, "throughput", count / execution_time)

    @pytest.mark.timeout(600)
    def test_02_spark_357_connect_baseline_q2_groupby(self, spark_connect_session, nyc_taxi_dataset_path, metrics_collector):
        """Spark 3.5.7 spark-connect baseline - Q2: GROUP BY"""
        start_time = time.time()

        df = spark_connect_session.read.parquet(str(nyc_taxi_dataset_path))
        df.createOrReplaceTempView("nyc_taxi")

        result = spark_connect_session.sql("""
            SELECT passenger_count, COUNT(*) AS trip_count, AVG(total_amount) AS avg_fare
            FROM nyc_taxi
            GROUP BY passenger_count
            ORDER BY passenger_count
        """)
        rows = result.collect()

        execution_time = time.time() - start_time

        # Validate
        assert len(rows) > 0, "GROUP BY should return results"
        assert rows[0]['passenger_count'] >= 0, "passenger_count should be non-negative"

        metrics_collector(self._testMethodName, "execution_time", execution_time)
        metrics_collector(self._testMethodName, "result_count", len(rows))

    # Similar tests for other combinations...
    # test_03 through test_24 for all version/mode/component combinations

    @pytest.mark.timeout(600)
    def test_03_spark_357_connect_baseline_q3_join(self, spark_connect_session, nyc_taxi_dataset_path, metrics_collector):
        """Spark 3.5.7 spark-connect baseline - Q3: JOIN"""
        start_time = time.time()

        df = spark_connect_session.read.parquet(str(nyc_taxi_dataset_path))
        df.createOrReplaceTempView("nyc_taxi")

        result = spark_connect_session.sql("""
            SELECT t1.passenger_count, COUNT(*) AS trip_count
            FROM nyc_taxi t1
            INNER JOIN nyc_taxi t2 ON t1.passenger_count = t2.passenger_count
            WHERE t1.trip_distance > 5 AND t2.trip_distance > 5
            GROUP BY t1.passenger_count
            ORDER BY t1.passenger_count
        """)
        rows = result.collect()

        execution_time = time.time() - start_time

        assert len(rows) > 0, "JOIN should return results"

        metrics_collector(self._testMethodName, "execution_time", execution_time)
        metrics_collector(self._testMethodName, "result_count", len(rows))

    @pytest.mark.timeout(600)
    def test_04_spark_357_connect_baseline_q4_window(self, spark_connect_session, nyc_taxi_dataset_path, metrics_collector):
        """Spark 3.5.7 spark-connect baseline - Q4: Window function"""
        start_time = time.time()

        df = spark_connect_session.read.parquet(str(nyc_taxi_dataset_path))
        df.createOrReplaceTempView("nyc_taxi")

        result = spark_connect_session.sql("""
            SELECT
                passenger_count,
                trip_distance,
                ROW_NUMBER() OVER (PARTITION BY passenger_count ORDER BY total_amount DESC) AS rank_by_fare,
                AVG(total_amount) OVER (PARTITION BY passenger_count) AS avg_fare_by_pax
            FROM nyc_taxi
            WHERE passenger_count > 0
            LIMIT 1000
        """)
        rows = result.collect()

        execution_time = time.time() - start_time

        assert len(rows) > 0, "Window function should return results"
        assert len(rows) <= 1000, "LIMIT should restrict to 1000 rows"

        metrics_collector(self._testMethodName, "execution_time", execution_time)
        metrics_collector(self._testMethodName, "result_count", len(rows))

    # Remaining 20 tests follow similar pattern for:
    # - Spark 3.5.8, 4.1.0, 4.1.1
    # - spark-connect, spark-k8s-submit
    # - baseline, jupyter
    # - All 4 queries (or subset to reach 24 total tests)

    # Simplified: 6 versions × 4 queries = 24 core tests
    # (spark-connect + k8s-submit for each version, baseline mode only)
```

## Scope Estimate
- Files: 2 (conftest.py, test_06_01_core_e2e.py)
- LOC: ~1500 (tests + fixtures)
- Scenarios: 24
- Size: LARGE
