---
ws_id: 00-013-03
feature: F13
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-012-03  # Iceberg E2E
---

## WS-00-013-03: Iceberg load (4 scenarios)

### üéØ Goal

**What must WORK after completing this WS:**
- 4 Iceberg load test scenarios (Spark 3.5.8, 4.1.1 √ó Airflow √ó Iceberg)
- INSERT + MERGE operations under sustained load
- Iceberg-specific metrics (scan time, snapshot size, file pruning)

**Acceptance Criteria:**
- [ ] AC1: 4 Iceberg load test scenarios created
- [ ] AC2: Each test runs for 30 minutes sustained load
- [ ] AC3: INSERT rate >= 10 inserts/second
- [ ] AC4: MERGE rate >= 5 merges/second
- [ ] AC5: File pruning working (> 50% files skipped)
- [ ] AC6: No snapshot explosion

**‚ö†Ô∏è WS is NOT complete until Goal is achieved (all AC ‚úÖ).**

---

### Scenarios

| Scenario | Spark Version | Operation | Rate | Duration |
|----------|---------------|-----------|------|----------|
| 1 | 3.5.8 | INSERT | 10/sec | 30 min |
| 2 | 3.5.8 | MERGE | 5/sec | 30 min |
| 3 | 4.1.1 | INSERT | 10/sec | 30 min |
| 4 | 4.1.1 | MERGE | 5/sec | 30 min |

### Dependencies

- WS-006-01 (Helm charts)
- WS-012-03 (Iceberg E2E)

### Code

```python
# tests/load/iceberg/test_iceberg_load_358.py
import pytest
from pyspark.sql.functions import col, current_timestamp

@pytest.mark.timeout(2400)
def test_iceberg_insert_load_358(spark_connect_client):
    """
    Sustained INSERT load: 10 inserts/second for 30 minutes
    Spark 3.5.8, Airflow, connect-k8s, Iceberg enabled
    """
    duration_sec = 1800
    interval_sec = 0.1  # 10 inserts per second

    start_time = datetime.now()
    end_time = start_time + timedelta(seconds=duration_sec)

    metrics = {
        "inserts_total": 0,
        "inserts_success": 0,
        "latencies": [],
        "snapshot_sizes": []
    }

    while datetime.now() < end_time:
        try:
            # Generate batch of test data
            test_data = spark_connect_client.createDataFrame([
                (1, 10.5, "test"),
                (2, 20.3, "test"),
                (3, 15.7, "test")
            ], ["id", "value", "source"])

            insert_start = datetime.now()
            test_data.writeTo("nyc_iceberg.test_table").append()
            insert_end = datetime.now()

            latency_ms = (insert_end - insert_start).total_seconds() * 1000
            metrics["latencies"].append(latency_ms)
            metrics["inserts_success"] += 1

            # Check snapshot size
            table = spark_connect_client.table("nyc_iceberg.test_table")
            snapshot_count = table.select("snapshot_id").distinct().count()
            metrics["snapshot_sizes"].append(snapshot_count)

        except Exception as e:
            pass
        finally:
            metrics["inserts_total"] += 1
            time.sleep(interval_sec)

    # Assertions
    error_rate = (metrics["inserts_total"] - metrics["inserts_success"]) / metrics["inserts_total"]
    assert error_rate < 0.01, f"Error rate too high: {error_rate:.2%}"

    avg_latency = sum(metrics["latencies"]) / len(metrics["latencies"])
    assert avg_latency < 100, f"Insert latency too high: {avg_latency:.1f}ms"

    return metrics
```

### Scope Estimate

- Files: 6
- Lines: ~600 (MEDIUM)
- Tokens: ~4500

### Constraints

- DO require Iceberg E2E tests passing first
- DO use Iceberg catalog in MinIO/S3
- DO monitor snapshot count
- DO NOT exceed 1000 snapshots (compact if needed)

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 ‚Äî ‚úÖ

**Goal Achieved:** ______
