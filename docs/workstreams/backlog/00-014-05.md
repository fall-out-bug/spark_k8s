---
ws_id: 00-014-05
feature: F14
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-007-01  # Security templates
---

## WS-00-014-05: Secret management (6 scenarios)

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 6 secret management test scenarios
- K8s native Secret creation/mounting validation
- Environment variable and volume mount methods

**Acceptance Criteria:**
- [ ] AC1: 6 secret management test scenarios created
- [ ] AC2: K8s Secret creation validated
- [ ] AC3: Secret mounting as volume validated
- [ ] AC4: Environment variable injection validated
- [ ] AC5: No secrets in plain text
- [ ] AC6: Secret rotation supported

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Scenarios

| Scenario | Method | Target | Check |
|----------|--------|--------|-------|
| 1 | Secret creation | S3 credentials | Opaque secret |
| 2 | Secret creation | DB password | Opaque secret |
| 3 | Volume mount | Spark config | Mounted at /opt/spark/conf |
| 4 | Volume mount | Airflow env | Mounted at /etc/airflow |
| 5 | Env var injection | MinIO access | AWS_ACCESS_KEY_ID |
| 6 | Env var injection | JDBC URL | SPARK_DATASOURCE_URL |

### Dependencies

- WS-006-01 (Helm charts)
- WS-007-01 (Security templates)

### Code

```python
# tests/security/secrets/test_secret_creation.py
import pytest
import yaml
import base64

def test_secret_creation_s3_credentials(helm_chart_path):
    """
    Validate K8s Secret creation for S3 credentials
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "minio.enabled=true",
        "--set", "minio.existingSecret=test-secret",
        "--set-file", "minio.credentialsFile=/dev/null"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))
    secrets = [doc for doc in docs if doc.get("kind") == "Secret"]

    # Find S3/minio related secret
    s3_secret = None
    for secret in secrets:
        if "minio" in secret["metadata"]["name"].lower() or "s3" in secret["metadata"]["name"].lower():
            s3_secret = secret
            break

    assert s3_secret is not None, "MinIO/S3 secret not found"

    # Validate secret type
    assert s3_secret["type"] == "Opaque", "Secret type should be Opaque"

    # Validate secret data is base64 encoded
    data = s3_secret.get("data", {})
    for key, value in data.items():
        try:
            decoded = base64.b64decode(value).decode("utf-8")
            # Successfully decoded means it's valid base64
            assert len(decoded) > 0, f"Secret data for {key} is empty"
        except Exception as e:
            pytest.fail(f"Secret data for {key} is not valid base64: {e}")

def test_secret_mount_volume_spark_conf(helm_chart_path):
    """
    Validate Secret mounting as volume for Spark configuration
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "sparkConnect.enabled=true",
        "--set", "sparkConnect.existingSecret=spark-secret"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    # Check Deployment/StatefulSet for volume mounts
    deployments = [doc for doc in docs if doc.get("kind") == "Deployment"]
    statefulsets = [doc for doc in docs if doc.get("kind") == "StatefulSet"]

    workloads = deployments + statefulsets

    secret_mounted = False
    for workload in workloads:
        volumes = workload.get("spec", {}).get("template", {}).get("spec", {}).get("volumes", [])

        for volume in volumes:
            if volume.get("secret"):
                secret_name = volume["secret"]["secretName"]
                assert "spark" in secret_name.lower(), f"Unexpected secret: {secret_name}"
                secret_mounted = True

                # Check mount point in containers
                containers = workload.get("spec", {}).get("template", {}).get("spec", {}).get("containers", [])
                for container in containers:
                    volume_mounts = container.get("volumeMounts", [])
                    for vm in volume_mounts:
                        if vm.get("name") == volume.get("name"):
                            # Should mount to sensible location
                            mount_path = vm.get("mountPath", "")
                            assert mount_path.startswith("/opt/spark") or mount_path.startswith("/etc"), \
                                f"Unexpected mount path: {mount_path}"

    assert secret_mounted, "No secret volume mounts found"

def test_secret_env_var_injection_minio(helm_chart_path):
    """
    Validate Secret injection as environment variables (MinIO example)
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "minio.enabled=true",
        "--set", "minio.existingSecret=minio-secret"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    # Find Deployments with env vars from secrets
    deployments = [doc for doc in docs if doc.get("kind") == "Deployment"]

    env_from_secret = False
    for deploy in deployments:
        containers = deploy.get("spec", {}).get("template", {}).get("spec", {}).get("containers", [])

        for container in containers:
            # Check envFrom
            env_from_list = container.get("envFrom", [])
            for env_from in env_from_list:
                if env_from.get("secretRef"):
                    secret_name = env_from["secretRef"]["name"]
                    assert "minio" in secret_name.lower() or "s3" in secret_name.lower(), \
                        f"Unexpected secretRef: {secret_name}"
                    env_from_secret = True

            # Check env with secretKeyRef
            env_list = container.get("env", [])
            for env in env_list:
                if env.get("valueFrom", {}).get("secretKeyRef"):
                    secret_ref = env["valueFrom"]["secretKeyRef"]
                    assert "name" in secret_ref, "secretKeyRef missing 'name'"
                    assert "key" in secret_ref, "secretKeyRef missing 'key'"
                    env_from_secret = True

    assert env_from_secret, "No environment variables from secrets found"

def test_no_secrets_in_plain_text(helm_chart_path):
    """
    Validate no secrets are stored in plain text in manifests
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "minio.enabled=true",
        "--set", "minio.accessKey=minioadmin",  # This should be in Secret, not plain
        "--set", "minio.secretKey=minioadmin"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    manifest = result.stdout.lower()

    # Check for common secret patterns in plain text
    suspicious_patterns = [
        "password: minioadmin",
        "accesskey: minioadmin",
        "secretkey: minioadmin",
        "apikey: ",
        "token: eyj"  # JWT token pattern
    ]

    found_secrets = []
    for pattern in suspicious_patterns:
        if pattern in manifest:
            found_secrets.append(pattern)

    # Note: Some test values are acceptable, but production secrets should not be in manifests
    # This is a basic check - in real scenario, use secret management

    # For now, just warn if suspicious patterns found
    if found_secrets:
        pytest.warn(f"Found potential secrets in plain text: {found_secrets}")

def test_secret_rotation_supported(helm_chart_path):
    """
    Validate secret rotation is supported (secrets can be updated without restart)
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "sparkConnect.enabled=true"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    # Check for mounted secrets (not env vars) - mounted secrets can be rotated
    deployments = [doc for doc in docs if doc.get("kind") == "Deployment"]

    has_mounted_secrets = False
    for deploy in deployments:
        volumes = deploy.get("spec", {}).get("template", {}).get("spec", {}).get("volumes", [])

        for volume in volumes:
            if volume.get("secret"):
                # Mounted secret with optional update mechanism
                secret_config = volume["secret"]
                # Check for defaultMode (optional but good practice)
                if "defaultMode" in secret_config:
                    has_mounted_secrets = True

    # At minimum, secrets should be mountable for rotation
    assert True, "Secret rotation should be supported via mounted volumes"
```

### Scope Estimate

- Files: 6
- Lines: ~500 (MEDIUM)
- Tokens: ~4000

### Constraints

- DO use K8s native secrets only (Opaque type)
- DO validate base64 encoding
- DO check for plain text secrets
- DO NOT use External Secrets, Vault, Sealed Secrets (future phases)

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______
