# WS-008-04: RBAC Tests

## Goal
Создать 6 тестов для проверки Kubernetes RBAC (Role-Based Access Control) для всех компонентов Spark.

### Acceptance Criteria
1. 6 RBAC тестов созданы в `tests/security/phase08/test_08_04_rbac.py`
2. Role existence проверен — spark-connect role создан
3. Least privilege проверен — только необходимые verbs
4. No wildcard проверен — "*" NOT в permissions
5. Secret access проверен — только s3-credentials secret
6. ServiceAccount проверен — создан и используется
7. RoleBinding проверен — привязывает SA к Role
8. Все тесты используют `helm template` для рендеринга

## Context

**Существующая инфраструктура:**
- `charts/spark-3.5/templates/rbac/role.yaml` — RBAC Role с least privileges
- `charts/spark-3.5/templates/rbac/rolebinding.yaml` — RoleBinding
- `charts/spark-3.5/templates/rbac/serviceaccount.yaml` — ServiceAccount
- Существующие тесты в `tests/security/test_security.py` (RBAC: enabled in prod, least privilege)

**Что нужно добавить:**
- Структурированные RBAC тесты
- Проверка всех RBAC ресурсов (Role, RoleBinding, ServiceAccount)
- Проверка least privilege (no wildcard verbs)
- Отдельный файл `tests/security/phase08/test_08_04_rbac.py`

## Dependency
Phase 0 (Helm Charts), Phase 1 (Critical Security)

## Input Files
- `charts/spark-3.5/templates/rbac/role.yaml`
- `charts/spark-3.5/templates/rbac/rolebinding.yaml`
- `charts/spark-3.5/templates/rbac/serviceaccount.yaml`
- `charts/spark-3.5/values.yaml`
- `tests/security/test_security.py` (reference)

## Steps

### 1. Create test_08_04_rbac.py
- Создать `tests/security/phase08/test_08_04_rbac.py`
- Implement 6 test scenarios

### 2. Implement test scenarios

**Scenario 1: Role exists — spark-connect role created**
- Render template с RBAC enabled
- Проверить наличие Role/ClusterRole ресурса
- Проверить name: spark-connect или подобное
- Проверить namespace

**Scenario 2: Least privilege — only required verbs**
- Найти Role для spark-connect
- Проверить rules в Role
- Проверить что verbs содержат только необходимые (get, list, watch, create, delete, update)
- Проверить отсутствие чрезмерных permissions (patch, *, deletecollection)

**Scenario 3: No wildcard — "*" NOT in permissions**
- Проверить все Roles в rendered template
- Убедиться что verbs не содержат "*"
- Убедиться что resources не содержат "*"
- Убедиться что apiGroups не содержит "*" (кроме "" для core)

**Scenario 4: Secret access — only s3-credentials secret**
- Найти Role с secret permissions
- Проверить resourceNames содержит только "s3-credentials" или подобное
- Проверить verbs для secrets только get, watch (no create, delete)
- Проверить отсутствие wildcard в resourceNames

**Scenario 5: ServiceAccount — created and used**
- Проверить наличие ServiceAccount ресурса
- Проверить name: spark или spark-connect
- Проверить automountServiceAccountToken: false (если не используется)
- Проверить что pods используют serviceAccountName

**Scenario 6: RoleBinding — binds SA to Role**
- Проверить наличие RoleBinding ресурса
- Проверить subjects ссылается на ServiceAccount
- Проверить roleRef ссылается на Role
- Проверить что связь правильная

### 3. Run tests
- `pytest tests/security/phase08/test_08_04_rbac.py -v`
- Убедиться что все 6 тестов проходят

## Code

### tests/security/phase08/test_08_04_rbac.py

```python
"""RBAC Tests for Phase 8

Tests for Kubernetes Role-Based Access Control (RBAC) across all Spark components.
"""

import pytest
import subprocess
import tempfile
import yaml
from pathlib import Path
from typing import Dict, List, Any


class TestRBAC:
    """Role-Based Access Control tests"""

    @pytest.fixture
    def rendered_template(self, spark_35_chart):
        """Render helm template with RBAC enabled"""
        with tempfile.NamedTemporaryFile(mode="w+", suffix=".yaml") as f:
            result = subprocess.run(
                ["helm", "template", "spark-test", str(spark_35_chart),
                 "--set", "sparkConnect.enabled=true",
                 "--set", "rbac.create=true"],
                capture_output=True, text=True
            )
            return result.stdout

    @pytest.fixture
    def rbac_resources(self, rendered_template):
        """Parse RBAC resources from rendered template"""
        documents = list(yaml.safe_load_all(rendered_template))
        return {
            'roles': [doc for doc in documents if doc and doc.get('kind') == 'Role'],
            'cluster_roles': [doc for doc in documents if doc and doc.get('kind') == 'ClusterRole'],
            'role_bindings': [doc for doc in documents if doc and doc.get('kind') in ['RoleBinding', 'ClusterRoleBinding']],
            'service_accounts': [doc for doc in documents if doc and doc.get('kind') == 'ServiceAccount'],
        }

    def test_01_role_exists_spark_connect(self, rbac_resources):
        """Role exists — spark-connect role created"""
        roles = rbac_resources['roles']
        cluster_roles = rbac_resources['cluster_roles']

        # Check for spark-related role
        spark_role = None
        for role in roles + cluster_roles:
            metadata = role.get('metadata', {})
            name = metadata.get('name', '').lower()
            if 'spark' in name or 'connect' in name:
                spark_role = role
                break

        assert spark_role is not None, "Spark-connect Role/ClusterRole not found"

        # Verify role structure
        assert 'rules' in spark_role.get('spec', {}), "Role must have rules"
        assert spark_role.get('metadata', {}).get('name'), "Role must have a name"

    def test_02_least_privilege_required_verbs_only(self, rbac_resources):
        """Least privilege — only required verbs"""
        roles = rbac_resources['roles']
        cluster_roles = rbac_resources['cluster_roles']

        # Allowed verbs for Spark (least privilege)
        allowed_verbs = {'get', 'list', 'watch', 'create', 'delete', 'update', 'patch'}
        # Verbs that should NOT be present (too broad)
        dangerous_verbs = {'*', 'deletecollection', 'impersonate', 'bind', 'escalate'}

        for role in roles + cluster_roles:
            metadata = role.get('metadata', {})
            name = metadata.get('name', '')

            # Only check Spark roles
            if 'spark' not in name.lower() and 'connect' not in name.lower():
                continue

            rules = role.get('spec', {}).get('rules', [])
            for rule in rules:
                verbs = rule.get('verbs', [])
                for verb in verbs:
                    verb_lower = verb.lower()
                    # Check no dangerous verbs
                    assert verb_lower not in dangerous_verbs, \
                        f"Role {name} has dangerous verb: {verb}"

                    # Most verbs should be in allowed set
                    if verb_lower not in allowed_verbs:
                        # Allow some edge cases like 'use' for configmaps, 'exec' for pods
                        assert verb_lower in {'use', 'exec', 'portforward'}, \
                            f"Role {name} has unexpected verb: {verb}"

    def test_03_no_wildcard_permissions(self, rbac_resources):
        """No wildcard — "*" NOT in permissions"""
        roles = rbac_resources['roles']
        cluster_roles = rbac_resources['cluster_roles']

        for role in roles + cluster_roles:
            metadata = role.get('metadata', {})
            name = metadata.get('name', '')

            # Only check Spark roles
            if 'spark' not in name.lower():
                continue

            rules = role.get('spec', {}).get('rules', [])
            for rule in rules:
                # Check verbs
                verbs = rule.get('verbs', [])
                assert '*' not in verbs, \
                    f"Role {name} has wildcard verb '*'"

                # Check resources
                resources = rule.get('resources', [])
                assert '*' not in resources, \
                    f"Role {name} has wildcard resource '*'"

                # Check apiGroups ("" is valid for core API)
                api_groups = rule.get('apiGroups', [])
                for group in api_groups:
                    if group == '*':
                        # Allow wildcard only if combined with restricted resources
                        assert resources and set(resources) != {'*'}, \
                            f"Role {name} has wildcard apiGroup '*' with wildcard resources"

    def test_04_secret_access_only_s3_credentials(self, rbac_resources):
        """Secret access — only s3-credentials secret"""
        roles = rbac_resources['roles']
        cluster_roles = rbac_resources['cluster_roles']

        # Find roles with secret access
        secret_roles = []
        for role in roles + cluster_roles:
            metadata = role.get('metadata', {})
            name = metadata.get('name', '')

            rules = role.get('spec', {}).get('rules', [])
            for rule in rules:
                resources = rule.get('resources', [])
                if 'secrets' in [r.lower() for r in resources]:
                    secret_roles.append((name, rule))

        # Check that secret access is restricted
        for role_name, rule in secret_roles:
            # If resourceNames is specified, should be specific secrets
            resource_names = rule.get('resourceNames', [])

            if resource_names:
                # Should only access specific secrets
                for name in resource_names:
                    assert 's3' in name.lower() or 'credential' in name.lower() or 'minio' in name.lower(), \
                        f"Role {role_name} has access to unexpected secret: {name}"

            # Verbs for secrets should be read-only
            verbs = rule.get('verbs', [])
            for verb in verbs:
                assert verb.lower() in {'get', 'list', 'watch'}, \
                    f"Role {role_name} has write access to secrets: {verb}"

    def test_05_service_account_created_and_used(self, rendered_template, rbac_resources):
        """ServiceAccount — created and used"""
        service_accounts = rbac_resources['service_accounts']

        # Find Spark service account
        spark_sa = None
        for sa in service_accounts:
            metadata = sa.get('metadata', {})
            name = metadata.get('name', '').lower()
            if 'spark' in name:
                spark_sa = sa
                break

        assert spark_sa is not None, "Spark ServiceAccount not found"

        # Check service account is referenced in pods
        documents = list(yaml.safe_load_all(rendered_template))
        pods_using_sa = 0
        sa_name = spark_sa.get('metadata', {}).get('name')

        for doc in documents:
            if doc and doc.get('kind') in ['Deployment', 'StatefulSet', 'DaemonSet', 'Pod', 'Job']:
                spec = doc.get('spec', {}).get('template', {}).get('spec', {})
                if spec.get('serviceAccountName') == sa_name:
                    pods_using_sa += 1

        assert pods_using_sa > 0, f"ServiceAccount {sa_name} is not used by any pods"

    def test_06_role_binding_binds_sa_to_role(self, rbac_resources):
        """RoleBinding — binds SA to Role"""
        role_bindings = rbac_resources['role_bindings']

        # Find Spark role binding
        spark_binding = None
        for binding in role_bindings:
            metadata = binding.get('metadata', {})
            name = metadata.get('name', '').lower()
            if 'spark' in name:
                spark_binding = binding
                break

        # If no specific binding found, check any binding
        if not spark_binding and role_bindings:
            spark_binding = role_bindings[0]

        assert spark_binding is not None, "No RoleBinding found for Spark"

        # Check subjects (ServiceAccounts)
        subjects = spark_binding.get('subjects', [])
        assert len(subjects) > 0, "RoleBinding has no subjects"

        has_sa_subject = False
        for subject in subjects:
            if subject.get('kind') == 'ServiceAccount':
                has_sa_subject = True
                assert subject.get('name'), "Subject ServiceAccount must have a name"
                assert subject.get('namespace') or spark_binding.get('metadata', {}).get('namespace'), \
                    "Subject must have a namespace"
                break

        assert has_sa_subject, "RoleBinding does not reference a ServiceAccount"

        # Check roleRef
        role_ref = spark_binding.get('roleRef', {})
        assert role_ref.get('kind') in ['Role', 'ClusterRole'], \
            f"roleRef kind must be Role or ClusterRole, got: {role_ref.get('kind')}"
        assert role_ref.get('name'), "roleRef must have a name"

    def test_rbac_resources_count(self, rbac_resources):
        """Verify RBAC resources are created"""
        assert len(rbac_resources['roles']) + len(rbac_resources['cluster_roles']) > 0, \
            "No Roles/ClusterRoles found"
        assert len(rbac_resources['role_bindings']) > 0, \
            "No RoleBindings found"
        assert len(rbac_resources['service_accounts']) > 0, \
            "No ServiceAccounts found"
```

## Scope Estimate
- Files: 1 (test_08_04_rbac.py)
- LOC: ~500 (tests)
- Scenarios: 6
- Size: MEDIUM
