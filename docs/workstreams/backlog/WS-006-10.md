---
ws_id: 00-006-10
feature: F06
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on: ["00-006-08", "00-006-09"]
---

## WS-006-10: Chart Documentation (README)

### üéØ Goal

**What must WORK after completing this WS:**
- README.md files created for both Spark 3.5 and 4.1 charts
- Core Components documentation first
- Feature guides (GPU, Iceberg)
- Preset usage examples
- Migration guide (4.1 only)

**Acceptance Criteria:**
- [ ] AC1: `charts/spark-3.5/README.md` created
- [ ] AC2: `charts/spark-4.1/README.md` created
- [ ] AC3: Core Components section documented first
- [ ] AC4: GPU and Iceberg feature guides included
- [ ] AC5: All preset examples validated

**‚ö†Ô∏è WS is NOT complete until Goal is achieved (all AC ‚úÖ).**

---

### Context

Documentation is critical for DevOps Engineers (primary users):
- Quick start guide
- Core Components configuration
- Feature toggles (GPU, Iceberg)
- Preset usage examples

### Dependencies

- WS-006-08 (Base presets)
- WS-006-09 (Scenario presets)

### Input Files

- Existing documentation in docs/
- New preset files
- Template structure

### Steps

1. **Create README.md structure**
   - Quick start
   - Core Components (Minio, PostgreSQL, Hive Metastore, History Server)
   - Features (GPU, Iceberg)
   - Presets
   - Configuration reference
   - Troubleshooting
   - Migration guide (4.1 only)

2. **Document Core Components first**
   - Architecture overview
   - Component interaction
   - Configuration examples

3. **Add feature guides**
   - GPU setup
   - Iceberg configuration
   - Catalog types

4. **Include preset examples**
   - Base presets usage
   - Scenario presets usage
   - Custom values

### Code

```markdown
# Apache Spark {VERSION} on Kubernetes

## Quick Start

\`\`\`bash
# Core Components only
helm install spark charts/spark-{version}/ \
  -f charts/spark-{version}/presets/core-baseline.yaml

# With Jupyter + Connect
helm install spark charts/spark-{version}/ \
  -f charts/spark-{version}/presets/scenarios/jupyter-connect-k8s.yaml
\`\`\`

## Core Components

### Minio (S3-compatible Storage)

Stores event logs, warehouse data, checkpoints.

\`\`\`yaml
core:
  minio:
    enabled: true
    buckets:
      - warehouse
      - spark-logs
\`\`\`

### PostgreSQL (Database)

Hive Metastore database backend.

\`\`\`yaml
core:
  postgresql:
    enabled: true
    auth:
      username: hive
\`\`\`

### Hive Metastore

Table metadata for Lakehouse operations.

\`\`\`yaml
core:
  hiveMetastore:
    enabled: true
    warehouse: "s3a://warehouse/"
\`\`\`

### History Server

Job history and metrics UI.

\`\`\`yaml
core:
  historyServer:
    enabled: true
    eventLogDir: "s3a://spark-logs/"
\`\`\`

## Features

### GPU Support

Enable RAPIDS acceleration for GPU workloads.

\`\`\`bash
helm install spark charts/spark-{version}/ \
  -f presets/core-gpu.yaml
\`\`\`

### Iceberg Support

Enable Apache Iceberg for ACID Lakehouse tables.

\`\`\`bash
helm install spark charts/spark-{version}/ \
  -f presets/core-iceberg.yaml
\`\`\`

## Presets

| Preset | Description | Use Case |
|--------|-------------|----------|
| core-baseline | Core Components only | Minimal stack |
| core-gpu | Core + GPU | ML workloads |
| core-iceberg | Core + Iceberg | Lakehouse operations |
| core-gpu-iceberg | Core + GPU + Iceberg | GPU Lakehouse |

## Configuration

See [values.yaml](values.yaml) for full reference.
```

### Expected Outcome

- README.md files created for both charts
- Core Components documented first
- Feature guides included
- Preset examples validated

### Scope Estimate

- Files: ~2 README.md
- Lines: ~600 (MEDIUM)
- Tokens: ~9000

### Completion Criteria

```bash
# Verify README exists
ls -la charts/spark-3.5/README.md
ls -la charts/spark-4.1/README.md

# Validate examples in README
grep -E "helm install" charts/spark-3.5/README.md | while read cmd; do
  eval $cmd --dry-run
done
```

### Constraints

- DO NOT include broken examples
- DO NOT skip Core Components section

---

## Execution Report

**Executed by:** Claude Code
**Date:** 2026-02-02
**Duration:** 15 minutes

### Goal Status
- [x] AC1: `charts/spark-3.5/README.md` created
- [x] AC2: `charts/spark-4.1/README.md` created
- [x] AC3: Core Components section documented first
- [x] AC4: GPU and Iceberg feature guides included
- [x] AC5: All preset examples validated (26 examples)

**Goal Achieved:** Yes

### Files Changed
| File | Action | LOC |
|------|--------|-----|
| charts/spark-3.5/README.md | Created | 567 |
| charts/spark-4.1/README.md | Created | 808 |

### Statistics
- **Files Changed:** 2
- **Lines Added:** 1,375
- **Lines Removed:** 0
- **Examples Validated:** 26 (11 in 3.5, 15 in 4.1)

### Deviations from Plan
- None

### Commit
```bash
git add charts/spark-3.5/README.md charts/spark-4.1/README.md docs/workstreams/backlog/WS-006-10.md
git commit -m "$(cat <<'EOF'
docs(ws-006-10): create chart README documentation

Create comprehensive README.md files for Spark 3.5 and 4.1 charts.

- Quick Start section with 8+ helm install examples per chart
- Core Components documented first: MinIO, PostgreSQL, Hive Metastore, History Server
- Architecture overview with component interaction diagrams
- Feature guides for GPU (RAPIDS) and Iceberg (Hadoop/Hive/REST catalogs)
- Complete preset reference (base + scenario presets)
- Configuration reference with YAML examples
- Troubleshooting section with 6+ common issues
- Migration guide from Spark 3.5 to 4.1 (4.1 only)

Acceptance Criteria:
- [x] AC1: charts/spark-3.5/README.md created (567 LOC)
- [x] AC2: charts/spark-4.1/README.md created (808 LOC)
- [x] AC3: Core Components section documented first
- [x] AC4: GPU and Iceberg feature guides included
- [x] AC5: All 26 preset examples validated with helm template

Examples validated:
- Spark 3.5: core-baseline, core-gpu, core-iceberg, jupyter-connect-k8s
- Spark 4.1: core-baseline, jupyter-connect-k8s, airflow-connect-k8s

Co-Authored-By: Claude <noreply@anthropic.com>
EOF
)"
```
