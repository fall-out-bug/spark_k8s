---
ws_id: 00-016-02
feature: F16
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
---

## WS-00-016-02: Logging aggregation (Loki)

### üéØ Goal

**What must WORK after completing this WS:**
- Loki Helm chart –¥–ª—è –ª–æ–≥ aggregation
- Fluent Bit/Promtail –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- Structured JSON logs —Å trace ID
- Log sampling (INFO 10%, ERROR/WARN 100%)

**Acceptance Criteria:**
- [ ] AC1: Loki Helm chart —Å–æ–∑–¥–∞–Ω
- [ ] AC2: Promtail collects logs from all pods
- [ ] AC3: JSON structured logging —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] AC4: Trace ID correlation —Ä–∞–±–æ—Ç–∞–µ—Ç
- [ ] AC5: Log sampling –Ω–∞—Å—Ç—Ä–æ–µ–Ω
- [ ] AC6: Grafana datasource –Ω–∞—Å—Ç—Ä–æ–µ–Ω

**‚ö†Ô∏è WS is NOT complete until Goal is achieved (all AC ‚úÖ).**

---

### Dependencies

Phase 0 (F06)

### Code

```yaml
# charts/observability/loki/values.yaml
loki:
  enabled: true
  config:
    server:
      http_listen_port: 3100

    ingester:
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1

    schema_config:
      configs:
      - from: 2024-01-01
        store: boltdb-shipper
        object_store: filesystem
        schema: v11
        index:
          prefix: index_
          period: 24h

    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      ingestion_rate_mb: 16
      ingestion_burst_size_mb: 32

    chunk_store_config:
      max_look_back_period: 0s

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

  retention:
    enabled: true
    days: 30

promtail:
  enabled: true
  config:
    server:
      http_listen_port: 3101

    clients:
    - url: http://loki:3100/loki/api/v1/push

    scrape_configs:
    # Spark logs with trace ID
    - job_name: spark-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels:
        - __meta_kubernetes_pod_label_app
        regex: spark.*
        action: keep
      - source_labels:
        - __meta_kubernetes_pod_name
        target_label: pod
      - source_labels:
        - __meta_kubernetes_pod_namespace
        target_label: namespace
      - source_labels:
        - __meta_kubernetes_pod_label_app
        target_label: app
      - source_labels:
        - __meta_kubernetes_pod_label_component
        target_label: component

      # Extract trace ID from logs
      - source_labels:
        - __meta_kubernetes_pod_annotation_opentelemetry_io_trace_id
        target_label: trace_id
        regex: (.*)
        action: replace

      # Log level routing
      - source_labels:
        - __meta_kubernetes_pod_label_level
        regex: (ERROR|WARN)
        action: keep

    pipeline_stages:
    # Parse JSON logs
    - json:
        expressions:
          level: level
          msg: message
          trace_id: trace_id
          timestamp: timestamp

    # Log sampling for INFO
    - drop:
        source: level
        regex: INFO
        drop_counter_reason: info_sampling
        sampling_rate: 0.1  # 10% sampling for INFO

    # Keep all ERROR and WARN
    - drop:
        source: level
        regex: (ERROR|WARN)
        drop_counter_reason: error_warn_keep
        action: keep

    # Set timestamps
    - timestamp:
        source: timestamp
        format: RFC3339

# Grafana datasource
grafana:
  enabled: false  # Deployed separately
```

### Scope Estimate

- Files: 6
- Lines: ~600 (MEDIUM)
- Tokens: ~4500

### Constraints

- DO use Loki for log storage (lightweight)
- DO use Promtail for log collection
- DO structured JSON logging
- DO log sampling: INFO 10%, ERROR/WARN 100%
- DO NOT use ELK (too heavy)

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 ‚Äî ‚úÖ

**Goal Achieved:** ______
