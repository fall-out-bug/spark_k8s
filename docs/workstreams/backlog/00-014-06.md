---
ws_id: 00-014-06
feature: F14
status: backlog
size: MEDIUM
project_id: 00
github_issue: null
assignee: null
depends_on:
  - 00-006-01  # Helm charts
  - 00-007-01  # Security templates
---

## WS-00-014-06: Container security (8 scenarios)

### ðŸŽ¯ Goal

**What must WORK after completing this WS:**
- 8 container security test scenarios
- Non-root user validation
- No privilege escalation
- Read-only root filesystem
- Dropped capabilities

**Acceptance Criteria:**
- [ ] AC1: 8 container security test scenarios created
- [ ] AC2: Non-root user validated (runAsUser > 0)
- [ ] AC3: No privilege escalation (allowPrivilegeEscalation=false)
- [ ] AC4: Read-only root filesystem (readOnlyRootFilesystem=true)
- [ ] AC5: Capabilities dropped (ALL or specific)
- [ ] AC6: No privileged containers

**âš ï¸ WS is NOT complete until Goal is achieved (all AC âœ…).**

---

### Scenarios

| Scenario | Check | Target | Expected Value |
|----------|-------|--------|----------------|
| 1 | runAsUser | All containers | > 0 (non-root) |
| 2 | runAsGroup | All containers | > 0 |
| 3 | allowPrivilegeEscalation | All containers | false |
| 4 | readOnlyRootFilesystem | All containers | true |
| 5 | capabilities.drop | All containers | ALL or specific list |
| 6 | privileged | All containers | false/unset |
| 7 | seccompProfile.type | All containers | RuntimeDefault or Localhost |
| 8 | allowPrivilegeEscalation | init containers | false |

### Dependencies

- WS-006-01 (Helm charts)
- WS-007-01 (Security templates)

### Code

```python
# tests/security/container/test_container_non_root.py
import pytest
import yaml

def test_container_non_root_user(helm_chart_path):
    """
    Validate all containers run as non-root user
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "podSecurityContext.enabled=true",
        "--set", "containerSecurityContext.runAsNonRoot=true"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    # Check all pods, deployments, statefulsets, etc.
    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet", "Job"]:
            # Get pod spec
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            # Check pod-level security context
            pod_sc = pod_spec.get("securityContext", {})

            # If runAsUser is set, must be > 0
            if "runAsUser" in pod_sc:
                uid = pod_sc["runAsUser"]
                assert uid is None or uid > 0, \
                    f"{doc['kind']}/{doc['metadata']['name']}: runAsUser must be > 0, got {uid}"

            if "runAsGroup" in pod_sc:
                gid = pod_sc["runAsGroup"]
                assert gid is None or gid > 0, \
                    f"{doc['kind']}/{doc['metadata']['name']}: runAsGroup must be > 0, got {gid}"

            # Check container-level security context
            for container in pod_spec.get("containers", []) + pod_spec.get("initContainers", []):
                container_sc = container.get("securityContext", {})

                # Check runAsUser at container level
                if "runAsUser" in container_sc:
                    uid = container_sc["runAsUser"]
                    assert uid is None or uid > 0, \
                        f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: runAsUser must be > 0"

def test_container_no_privilege_escalation(helm_chart_path):
    """
    Validate allowPrivilegeEscalation is false for all containers
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "containerSecurityContext.allowPrivilegeEscalation=false"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet", "Job"]:
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            for container in pod_spec.get("containers", []) + pod_spec.get("initContainers", []):
                container_sc = container.get("securityContext", {})

                # allowPrivilegeEscalation must be false
                allow_escalation = container_sc.get("allowPrivilegeEscalation")
                assert allow_escalation is False, \
                    f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                    f"allowPrivilegeEscalation must be false, got {allow_escalation}"

def test_container_readonly_root_filesystem(helm_chart_path):
    """
    Validate readOnlyRootFilesystem is true for all containers
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "containerSecurityContext.readOnlyRootFilesystem=true"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet"]:
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            for container in pod_spec.get("containers", []):
                container_sc = container.get("securityContext", {})

                # readOnlyRootFilesystem should be true
                read_only = container_sc.get("readOnlyRootFilesystem")
                assert read_only is True, \
                    f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                    f"readOnlyRootFilesystem must be true, got {read_only}"

def test_container_capabilities_dropped(helm_chart_path):
    """
    Validate capabilities are dropped for all containers
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "containerSecurityContext.capabilities.drop[0]=ALL"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet"]:
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            for container in pod_spec.get("containers", []):
                container_sc = container.get("securityContext", {})
                capabilities = container_sc.get("capabilities", {})

                # Should have drop list
                drop_caps = capabilities.get("drop", [])
                assert len(drop_caps) > 0, \
                    f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                    "capabilities.drop must be specified"

                # Should drop ALL or specific capabilities
                assert "ALL" in drop_caps or len(drop_caps) > 0, \
                    f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                    "Must drop ALL or specific capabilities"

                # Should not add unnecessary capabilities
                add_caps = capabilities.get("add", [])
                # Empty add list is OK (no additional capabilities)
                # If add is specified, validate it's minimal
                for cap in add_caps:
                    assert cap in ["NET_BIND_SERVICE"],  # Only allow specific caps if needed
                        f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                        f"Unexpected capability to add: {cap}"

def test_container_no_privileged(helm_chart_path):
    """
    Validate no containers run as privileged
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet"]:
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            for container in pod_spec.get("containers", []) + pod_spec.get("initContainers", []):
                container_sc = container.get("securityContext", {})

                # privileged must not be true
                privileged = container_sc.get("privileged", False)
                assert privileged is not True, \
                    f"{doc['kind']}/{doc['metadata']['name']}/{container['name']}: " \
                    "privileged must not be true"

def test_container_seccomp_profile(helm_chart_path):
    """
    Validate seccomp profile is set for all pods
    """
    cmd = [
        "helm", "template", "spark-3.5",
        helm_chart_path,
        "--set", "podSecurityContext.seccompProfile.type=RuntimeDefault"
    ]

    result = subprocess.run(cmd, capture_output=True, text=True)
    assert result.returncode == 0

    docs = list(yaml.safe_load_all(result.stdout))

    for doc in docs:
        if doc.get("kind") in ["Pod", "Deployment", "StatefulSet", "DaemonSet"]:
            if doc.get("kind") == "Pod":
                pod_spec = doc.get("spec", {})
            else:
                pod_spec = doc.get("spec", {}).get("template", {}).get("spec", {})

            pod_sc = pod_spec.get("securityContext", {})
            seccomp = pod_sc.get("seccompProfile", {})

            # Should have seccompProfile
            assert seccomp, \
                f"{doc['kind']}/{doc['metadata']['name']}: seccompProfile must be set"

            # Type should be RuntimeDefault or Localhost
            seccomp_type = seccomp.get("type")
            assert seccomp_type in ["RuntimeDefault", "Localhost"], \
                f"{doc['kind']}/{doc['metadata']['name']}: " \
                f"seccompProfile.type must be RuntimeDefault or Localhost, got {seccomp_type}"
```

### Scope Estimate

- Files: 8
- Lines: ~700 (MEDIUM)
- Tokens: ~5500

### Constraints

- DO enforce non-root user for all containers
- DO set allowPrivilegeEscalation=false
- DO use readOnlyRootFilesystem=true
- DO drop ALL capabilities or specific ones
- DO NOT allow privileged containers

---

## Execution Report

**Executed by:** ______
**Date:** ______
**Duration:** ______ minutes

### Goal Status
- [ ] AC1-AC6 â€” âœ…

**Goal Achieved:** ______
