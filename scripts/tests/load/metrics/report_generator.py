#!/usr/bin/env python3
"""
Report Generator for Load Testing
Part of WS-013-10: Metrics Collection & Regression Detection

Generates multi-layer reports from load test results.

Usage:
    python report_generator.py generate --results-dir /tmp/load-test-results --output /tmp/reports
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List


class ReportGenerator:
    """Generates multi-layer reports from load test results."""

    def __init__(self, results_dir: Path, output_dir: Path):
        """
        Initialize report generator.

        Args:
            results_dir: Directory containing result files
            output_dir: Directory for output reports
        """
        self.results_dir = Path(results_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def load_results(self) -> List[Dict[str, Any]]:
        """Load all results from directory."""
        all_results = []

        for results_file in self.results_dir.glob("**/*.jsonl"):
            with open(results_file) as f:
                for line in f:
                    try:
                        all_results.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue

        return all_results

    def generate_layer1_executive_summary(self, results: List[Dict[str, Any]]) -> str:
        """
        Generate Layer 1: Executive summary (Markdown).

        Args:
            results: List of result dictionaries

        Returns:
            Markdown content
        """
        total_tests = len(results)
        successful = sum(1 for r in results if r.get("exit_code", 0) == 0)
        failed = total_tests - successful

        # Calculate average duration
        durations = [r.get("duration_sec", 0) for r in results if r.get("duration_sec")]
        avg_duration = sum(durations) / len(durations) if durations else 0

        # Count regressions
        regressions = sum(1 for r in results if r.get("regression", False))

        md = f"""# Load Test Executive Summary

**Date:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}

## Overall Results

- **Total Tests:** {total_tests}
- **Successful:** {successful} ({successful/total_tests*100 if total_tests > 0 else 0:.1f}%)
- **Failed:** {failed}
- **Regressions:** {regressions}

## Performance

- **Average Duration:** {avg_duration:.2f}s
- **Total Duration:** {sum(durations):.2f}s

## Summary

{'All tests passed successfully!' if failed == 0 else f'{failed} test(s) failed.'}
{'No regressions detected.' if regressions == 0 else f'{regressions} regression(s) detected.'}

---

*Generated by Spark K8s Load Test Framework*
"""
        return md

    def generate_layer2_technical_deep_dive(self, results: List[Dict[str, Any]]) -> str:
        """
        Generate Layer 2: Technical deep-dive (HTML).

        Args:
            results: List of result dictionaries

        Returns:
            HTML content
        """
        # Group results by test name
        by_test = {}
        for r in results:
            test_name = r.get("test_name", "unknown")
            if test_name not in by_test:
                by_test[test_name] = []
            by_test[test_name].append(r)

        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Load Test Report - {datetime.utcnow().strftime('%Y-%m-%d')}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        h1 {{ color: #333; }}
        .summary {{ background: #f5f5f5; padding: 20px; border-radius: 5px; }}
        .test {{ margin: 20px 0; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
        .test.passed {{ border-left: 4px solid #4CAF50; }}
        .test.failed {{ border-left: 4px solid #f44336; }}
        .metrics {{ display: grid; grid-template-columns: repeat(3, 1fr); gap: 10px; }}
        .metric {{ background: #f9f9f9; padding: 10px; border-radius: 3px; }}
        .metric-label {{ font-size: 12px; color: #666; }}
        .metric-value {{ font-size: 18px; font-weight: bold; }}
    </style>
</head>
<body>
    <h1>Load Test Technical Report</h1>
    <p><strong>Generated:</strong> {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}</p>

    <div class="summary">
        <h2>Summary</h2>
        <p><strong>Total Tests:</strong> {len(results)}</p>
        <p><strong>Successful:</strong> {sum(1 for r in results if r.get('exit_code', 0) == 0)}</p>
        <p><strong>Failed:</strong> {sum(1 for r in results if r.get('exit_code', 0) != 0)}</p>
    </div>

    <h2>Test Results</h2>
"""

        # Add test details
        for test_name, test_results in sorted(by_test.items()):
            status = "passed" if all(r.get("exit_code", 0) == 0 for r in test_results) else "failed"

            html += f"""
    <div class="test {status}">
        <h3>{test_name}</h3>
        <div class="metrics">
"""

            # Add metrics for first result
            if test_results:
                r = test_results[0]
                duration = r.get("tier3_performance", {}).get("duration_sec", 0)
                throughput = r.get("tier3_performance", {}).get("throughput", 0)

                html += f"""
            <div class="metric">
                <div class="metric-label">Duration</div>
                <div class="metric-value">{duration:.2f}s</div>
            </div>
            <div class="metric">
                <div class="metric-label">Throughput</div>
                <div class="metric-value">{throughput:,.0f} rows/s</div>
            </div>
            <div class="metric">
                <div class="metric-label">Status</div>
                <div class="metric-value">{status.upper()}</div>
            </div>
"""

            html += """
        </div>
    </div>
"""

        html += """
</body>
</html>
"""
        return html

    def generate_layer3_detailed_report(self, results: List[Dict[str, Any]]) -> str:
        """
        Generate Layer 3: Detailed report (Markdown).

        Args:
            results: List of result dictionaries

        Returns:
            Markdown content
        """
        md = f"""# Detailed Load Test Report

**Generated:** {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}

## Test Details

"""

        for r in sorted(results, key=lambda x: x.get("test_name", "")):
            test_name = r.get("test_name", "unknown")
            md += f"\n### {test_name}\n\n"

            # Add metadata
            md += f"- **Spark Version:** {r.get('spark_version', 'N/A')}\n"
            md += f"- **Orchestrator:** {r.get('orchestrator', 'N/A')}\n"
            md += f"- **Mode:** {r.get('mode', 'N/A')}\n"
            md += f"- **Extensions:** {r.get('extensions', 'N/A')}\n"
            md += f"- **Operation:** {r.get('operation', 'N/A')}\n"
            md += f"- **Data Size:** {r.get('data_size', 'N/A')}\n"
            md += f"- **Exit Code:** {r.get('exit_code', 'N/A')}\n"
            md += f"- **Duration:** {r.get('duration_sec', 0):.2f}s\n"

            # Add tier 1 metrics
            tier1 = r.get("tier1_stability", {})
            if tier1:
                md += "\n**Stability Metrics:**\n"
                md += f"- Pod Restarts: {tier1.get('pod_restarts', 0)}\n"
                md += f"- OOM Kills: {tier1.get('oom_kills', 0)}\n"
                md += f"- Failed Tasks: {tier1.get('failed_tasks', 0)}\n"

            # Add tier 2 metrics
            tier2 = r.get("tier2_efficiency", {})
            if tier2:
                md += "\n**Efficiency Metrics:**\n"
                md += f"- CPU Usage: {tier2.get('cpu_usage_pct', 0):.1f}%\n"
                md += f"- Memory Usage: {tier2.get('memory_usage_pct', 0):.1f}%\n"

            # Add tier 3 metrics
            tier3 = r.get("tier3_performance", {})
            if tier3:
                md += "\n**Performance Metrics:**\n"
                md += f"- Duration: {tier3.get('duration_sec', 0):.2f}s\n"
                md += f"- Throughput: {tier3.get('throughput', 0):,.0f} rows/s\n"

            md += "\n---\n"

        return md

    def generate_layer4_raw_data(self, results: List[Dict[str, Any]]) -> Path:
        """
        Generate Layer 4: Raw data (JSONL).

        Args:
            results: List of result dictionaries

        Returns:
            Path to raw data file
        """
        output_file = self.output_dir / "raw-data.jsonl"

        with open(output_file, 'w') as f:
            for r in results:
                f.write(json.dumps(r) + '\n')

        return output_file

    def generate_all(self) -> Dict[str, Path]:
        """
        Generate all report layers.

        Returns:
            Dictionary mapping layer names to output paths
        """
        results = self.load_results()

        print(f"Loaded {len(results)} results from {self.results_dir}")

        # Layer 1: Executive summary
        layer1_content = self.generate_layer1_executive_summary(results)
        layer1_file = self.output_dir / "executive-summary.md"
        layer1_file.write_text(layer1_content)
        print(f"Generated: {layer1_file}")

        # Layer 2: Technical deep-dive
        layer2_content = self.generate_layer2_technical_deep_dive(results)
        layer2_file = self.output_dir / "technical-report.html"
        layer2_file.write_text(layer2_content)
        print(f"Generated: {layer2_file}")

        # Layer 3: Detailed report
        layer3_content = self.generate_layer3_detailed_report(results)
        layer3_file = self.output_dir / "detailed-report.md"
        layer3_file.write_text(layer3_content)
        print(f"Generated: {layer3_file}")

        # Layer 4: Raw data
        layer4_file = self.generate_layer4_raw_data(results)
        print(f"Generated: {layer4_file}")

        return {
            "layer1": layer1_file,
            "layer2": layer2_file,
            "layer3": layer3_file,
            "layer4": layer4_file,
        }


def main():
    parser = argparse.ArgumentParser(
        description="Generate load test reports"
    )
    parser.add_argument(
        '--results-dir', type=str, required=True,
        help='Directory containing result files'
    )
    parser.add_argument(
        '--output-dir', type=str,
        default='/tmp/load-test-reports',
        help='Output directory for reports'
    )
    parser.add_argument(
        '--layers', type=str,
        default='all',
        choices=['all', '1', '2', '3', '4'],
        help='Report layers to generate'
    )

    args = parser.parse_args()

    generator = ReportGenerator(
        Path(args.results_dir),
        Path(args.output_dir),
    )

    if args.layers == 'all':
        output_files = generator.generate_all()
        print("\nReport generation complete!")
        for layer, path in output_files.items():
            print(f"  {layer}: {path}")
        return 0
    else:
        # Generate specific layer
        results = generator.load_results()
        if args.layers == '1':
            content = generator.generate_layer1_executive_summary(results)
            output_file = Path(args.output_dir) / "executive-summary.md"
        elif args.layers == '2':
            content = generator.generate_layer2_technical_deep_dive(results)
            output_file = Path(args.output_dir) / "technical-report.html"
        elif args.layers == '3':
            content = generator.generate_layer3_detailed_report(results)
            output_file = Path(args.output_dir) / "detailed-report.md"
        elif args.layers == '4':
            output_file = generator.generate_layer4_raw_data(results)
            content = None

        if content:
            output_file.parent.mkdir(parents=True, exist_ok=True)
            output_file.write_text(content)

        print(f"Generated: {output_file}")
        return 0


if __name__ == '__main__':
    sys.exit(main())
