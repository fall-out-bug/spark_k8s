{"id":"spark_k8s-05t","title":"WS-014-04: RBAC tests (6 scenarios)","description":"6 RBAC test scenarios with least privilege validation.\n\n- ServiceAccount permissions\n- Role/ClusterRole least privilege\n- No wildcard permissions\n- Resource-specific rules only\n\nScope: MEDIUM (~500 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:29.356456072+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:29.356456072+03:00","dependencies":[{"issue_id":"spark_k8s-05t","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:36.535520031+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-096","title":"WS-013-02: GPU load (4 scenarios)","description":"4 GPU load test scenarios (Spark 4.1.0, 4.1.1 × Airflow × GPU) with RAPIDS acceleration validation.\n\n- 30-minute sustained load at 0.5-1 query/second\n- GPU utilization \u003e 60% sustained\n- Speedup vs CPU \u003e= 2x for heavy queries\n- GPU memory stable (no leaks)\n- Error rate \u003c 1%\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:18:00.930404198+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:18:00.930404198+03:00","dependencies":[{"issue_id":"spark_k8s-096","depends_on_id":"spark_k8s-47g","type":"blocks","created_at":"2026-02-04T01:18:21.790238039+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-0su","title":"WS-016-01: Metrics collection (Prometheus)","description":"Prometheus Helm chart with JMX exporter for Spark.\n\n- Prometheus + JMX exporter integration\n- 15s scrape interval\n- Spark metrics (executor, driver, shuffle)\n- K8s metrics (kube-state-metrics, node_exporter)\n- Data retention 15d\n- ServiceMonitor configured\n\nScope: MEDIUM (~700 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:46.044979611+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:46.044979611+03:00","dependencies":[{"issue_id":"spark_k8s-0su","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:02.869735525+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p","title":"F25: Community Infrastructure","description":"GitHub issue/PR templates (bug_report.yml, feature_request.yml, documentation.yml, good_first_issue.yml). CONTRIBUTING.md with quick ways to contribute. CODE_OF_CONDUCT.md (Contributor Covenant). Labels: good first issue, help wanted, documentation, bug, enhancement, discussion, spark-3.5, spark-4.1, kubernetes, openshift.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 2 Foundation","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:04.173880679+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:04.173880679+03:00"}
{"id":"spark_k8s-13p.1","title":"WS-025-01: Issue templates creation","description":"Create .github/ISSUE_TEMPLATE/ directory with templates: bug_report.yml, feature_request.yml, documentation.yml, good_first_issue.yml. Each template has structured fields, triage questions, labels assignment. Test template rendering in GitHub UI.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:26:17.727441564+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:17.727441564+03:00","dependencies":[{"issue_id":"spark_k8s-13p.1","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:17.728600557+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p.2","title":"WS-025-02: Pull request template","description":"Create .github/PULL_REQUEST_TEMPLATE.md. Sections: description, changes, testing, checklist (tests pass, coverage OK, docs updated), related issues. Auto-populated when PR created.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":30,"created_at":"2026-02-04T15:26:17.967995578+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:17.967995578+03:00","dependencies":[{"issue_id":"spark_k8s-13p.2","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:17.969276009+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-13p.2","depends_on_id":"spark_k8s-13p.1","type":"blocks","created_at":"2026-02-04T15:37:36.200096643+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p.3","title":"WS-025-03: CONTRIBUTING.md guide","description":"Write CONTRIBUTING.md with: quick ways to contribute (docs, bug reports, code), development environment setup, testing workflow, PR guidelines, code style reference. Link to existing PROJECT_CONVENTIONS.md. Keep under 500 lines.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:18.195345186+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:18.195345186+03:00","dependencies":[{"issue_id":"spark_k8s-13p.3","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:18.196481336+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-13p.3","depends_on_id":"spark_k8s-ds8.5","type":"blocks","created_at":"2026-02-04T15:37:55.699992296+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p.4","title":"WS-025-04: CODE_OF_CONDUCT.md","description":"Adapt Contributor Covenant for spark_k8s. Enforce inclusive language, zero tolerance for harassment. Reporting procedure with email/template. Contact information for moderators. Translate to RU (bilingual).","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":45,"created_at":"2026-02-04T15:26:18.411151745+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:18.411151745+03:00","dependencies":[{"issue_id":"spark_k8s-13p.4","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:18.412249942+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-13p.4","depends_on_id":"spark_k8s-13p.3","type":"blocks","created_at":"2026-02-04T15:37:36.639246602+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p.5","title":"WS-025-05: GitHub labels configuration","description":"Create standard labels with colors and descriptions: good first issue (green), help wanted (blue), documentation (purple), bug (red), enhancement (yellow), discussion (gray), spark-3.5 (orange), spark-4.1 (dark orange), kubernetes (blue), openshift (red). Use labels.yml or script.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":30,"created_at":"2026-02-04T15:26:18.631001044+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:18.631001044+03:00","dependencies":[{"issue_id":"spark_k8s-13p.5","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:18.632115023+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-13p.5","depends_on_id":"spark_k8s-13p.1","type":"blocks","created_at":"2026-02-04T15:37:36.894476513+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-13p.6","title":"WS-025-06: Contributors documentation","description":"Create docs/community/contributors.md. Contribution ladder: lurker → participant → contributor → expert → maintainer. First-time contributor flow. Getting started guide. Mentorship program. Recognition systems.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:26:18.85068+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:18.85068+03:00","dependencies":[{"issue_id":"spark_k8s-13p.6","depends_on_id":"spark_k8s-13p","type":"parent-child","created_at":"2026-02-04T15:26:18.851732744+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-13p.6","depends_on_id":"spark_k8s-13p.2","type":"blocks","created_at":"2026-02-04T15:38:39.321519464+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-17o","title":"WS-012-05: Standalone E2E (8 scenarios)","description":"Create 8 standalone cluster E2E test scenarios.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:08.30168605+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:08.30168605+03:00","dependencies":[{"issue_id":"spark_k8s-17o","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:34.850551244+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1cb","title":"WS-017-01: Spark Connect Go client library","description":"gRPC-based Spark Connect client library for Go.\n\n- Client: NewClient, Close, connection management\n- Session: CreateSession, Close, session ID\n- DataFrame: SQL, Collect, Show, Count operations\n- Row: GetInt, GetString, GetFloat methods\n- Error handling and context management\n- TLS support for production\n\nBased on official Apache Spark Connect gRPC protocol.\n\nScope: MEDIUM (~800 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T13:03:32.727704589+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:03:32.727704589+03:00","dependencies":[{"issue_id":"spark_k8s-1cb","depends_on_id":"spark_k8s-cqy","type":"blocks","created_at":"2026-02-04T13:03:39.890553408+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1fm","title":"WS-012-02: GPU E2E (16 scenarios)","description":"Create 16 GPU E2E test scenarios for Spark 4.1 with RAPIDS acceleration validation.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:07.644044237+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:07.644044237+03:00","dependencies":[{"issue_id":"spark_k8s-1fm","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:34.172319986+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1hs","title":"Phase 2: Complete Smoke Tests","description":"Cover all combinations of Spark versions, components, modes, and features with smoke tests to ensure quality for every build. Target: 139 scenarios total. Current: 15 implemented (11%).","status":"tombstone","priority":0,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:27:42.930234146+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:29:24.831154985+03:00","deleted_at":"2026-02-04T00:29:24.831154985+03:00","deleted_by":"daemon","delete_reason":"delete","original_type":"feature"}
{"id":"spark_k8s-1ig","title":"WS-013-05: Security stability (4 scenarios)","description":"4 security stability scenarios (PSS, SCC, OpenShift) under sustained load.\n\n- PSS restricted mode stable under load\n- SCC policies stable under load\n- OpenShift presets stable under load\n- Performance within 10% of non-secure baseline\n- No policy violations under load\n- 30-minute sustained load\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:18:12.388149674+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:18:12.388149674+03:00","dependencies":[{"issue_id":"spark_k8s-1ig","depends_on_id":"spark_k8s-47g","type":"blocks","created_at":"2026-02-04T01:18:22.463485278+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1wf","title":"F21: Project Origins Documentation","description":"Write 'Why spark_k8s' story (500+ words). Problem: DevOps don't understand Spark, Data doesn't understand K8s. Solution: Lego-constructor approach. Vision: Production-ready, not production-hostile.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 1","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:23:56.667423768+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:23:56.667423768+03:00"}
{"id":"spark_k8s-1wf.1","title":"WS-021-01: Write origin story","description":"Write 500+ word 'Why spark_k8s' document. Problem statement: DevOps don't understand Spark, Data doesn't understand K8s, communication gap causes failed deployments. Solution: Lego-constructor approach with preset-based deployment. Vision: Production-ready, not production-hostile. Save to docs/about/origin-story.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:24.812506229+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:24.812506229+03:00","dependencies":[{"issue_id":"spark_k8s-1wf.1","depends_on_id":"spark_k8s-1wf","type":"parent-child","created_at":"2026-02-04T15:25:24.813717447+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1wf.2","title":"WS-021-02: Problem deep dive","description":"Expand on the communication gap problem. Real-world examples of failed Spark deployments due to DevOps/Data disconnect. Quantify the cost (time, money, frustration). Interview format or case study style.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":45,"created_at":"2026-02-04T15:25:25.044759745+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:25.044759745+03:00","dependencies":[{"issue_id":"spark_k8s-1wf.2","depends_on_id":"spark_k8s-1wf","type":"parent-child","created_at":"2026-02-04T15:25:25.045917353+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-1wf.2","depends_on_id":"spark_k8s-1wf.1","type":"blocks","created_at":"2026-02-04T15:37:29.876394504+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1wf.3","title":"WS-021-03: Solution philosophy","description":"Document the Lego-constructor philosophy. Why presets matter. How modularity enables self-service without chaos. The balance between flexibility and guardrails. Connection to platform engineering principles.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:25.277984939+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:25.277984939+03:00","dependencies":[{"issue_id":"spark_k8s-1wf.3","depends_on_id":"spark_k8s-1wf","type":"parent-child","created_at":"2026-02-04T15:25:25.279225256+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-1wf.3","depends_on_id":"spark_k8s-1wf.1","type":"blocks","created_at":"2026-02-04T15:37:30.105623047+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1wf.4","title":"WS-021-04: Vision and future roadmap","description":"Articulate long-term vision for spark_k8s. Beyond Helm charts: what's the north star? Evolution toward complete data platform. Community-driven development model. Sustainability story.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":45,"created_at":"2026-02-04T15:25:25.504801066+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:25.504801066+03:00","dependencies":[{"issue_id":"spark_k8s-1wf.4","depends_on_id":"spark_k8s-1wf","type":"parent-child","created_at":"2026-02-04T15:25:25.505821344+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-1wf.4","depends_on_id":"spark_k8s-1wf.3","type":"blocks","created_at":"2026-02-04T15:38:37.361034928+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-1wf.5","title":"WS-021-05: Bilingual version (RU)","description":"Translate origin story to Russian. Maintain tone and voice. Cultural adaptations where needed. Publish both EN and RU versions side by side.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":30,"created_at":"2026-02-04T15:25:25.726409365+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:25.726409365+03:00","dependencies":[{"issue_id":"spark_k8s-1wf.5","depends_on_id":"spark_k8s-1wf","type":"parent-child","created_at":"2026-02-04T15:25:25.727548103+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-1wf.5","depends_on_id":"spark_k8s-1wf.4","type":"blocks","created_at":"2026-02-04T15:38:37.610408805+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-2dg","title":"WS-011-03: Jupyter images (12) + tests","description":"Create Jupyter runtime images combining Spark 3.5/4.1 with GPU/Iceberg variants and integration tests.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:57:04.617570912+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:57:04.617570912+03:00","dependencies":[{"issue_id":"spark_k8s-2dg","depends_on_id":"spark_k8s-3hr","type":"blocks","created_at":"2026-02-04T00:57:17.07839354+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-2dg","depends_on_id":"spark_k8s-hbc","type":"blocks","created_at":"2026-02-04T00:59:34.703375552+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-2dg","depends_on_id":"spark_k8s-ehu","type":"blocks","created_at":"2026-02-04T00:59:34.919031168+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3hr","title":"F11: Phase 5 - Docker Runtime Images","description":"Create production-ready Spark runtime images combining base, intermediate layers with Spark, Jupyter, Airflow, MLflow components.","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:56:35.71121354+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:56:35.71121354+03:00"}
{"id":"spark_k8s-3hr.1","title":"WS-011-10: GHCR Integration","description":"Integrate GitHub Container Registry into F11 build workflow. Update existing image builds to push to GHCR. Migration from Docker Hub (if used). Documentation updates for new image locations. Retag existing images.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:27:13.598107338+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:13.598107338+03:00","dependencies":[{"issue_id":"spark_k8s-3hr.1","depends_on_id":"spark_k8s-3hr","type":"parent-child","created_at":"2026-02-04T15:27:13.606281321+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-3hr.1","depends_on_id":"spark_k8s-ds8.1","type":"blocks","created_at":"2026-02-04T15:37:50.928684247+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3hr.2","title":"WS-011-11: Image Caching Strategy","description":"Implement layer caching strategy for faster builds. BuildKit cache integration. CI cache for GitHub Actions. Pull-through caching for common base layers. Documentation for cache debugging.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:27:13.834816171+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:13.834816171+03:00","dependencies":[{"issue_id":"spark_k8s-3hr.2","depends_on_id":"spark_k8s-3hr","type":"parent-child","created_at":"2026-02-04T15:27:13.836130068+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-3hr.2","depends_on_id":"spark_k8s-3hr.1","type":"blocks","created_at":"2026-02-04T15:37:51.194671855+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3hr.3","title":"WS-011-12: Image Security Scanning","description":"Add security scanning to image build pipeline. Trivy integration in GitHub Actions. Fail build on HIGH/CRITICAL vulnerabilities. Vulnerability report generation. SBOM generation and attestation.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:27:14.055787002+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:14.055787002+03:00","dependencies":[{"issue_id":"spark_k8s-3hr.3","depends_on_id":"spark_k8s-3hr","type":"parent-child","created_at":"2026-02-04T15:27:14.056891518+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-3hr.3","depends_on_id":"spark_k8s-3hr.1","type":"blocks","created_at":"2026-02-04T15:37:51.460639831+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3hr.4","title":"WS-011-13: Image Variant Testing","description":"Test all image variants before release. Spark 3.5.7, 4.1.0. Jupyter variants. Python version compatibility. Runtime testing on Minikube/OpenShift. Validation checklist per variant.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:27:14.288303028+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:14.288303028+03:00","dependencies":[{"issue_id":"spark_k8s-3hr.4","depends_on_id":"spark_k8s-3hr","type":"parent-child","created_at":"2026-02-04T15:27:14.289610605+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-3hr.4","depends_on_id":"spark_k8s-3hr.2","type":"blocks","created_at":"2026-02-04T15:38:45.31170676+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3i5","title":"WS-008-02: Standalone chart baseline scenarios (24)","description":"Create smoke test scenarios for Spark Standalone chart across different modes and versions","status":"closed","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:04.318446739+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:40:01.968411088+03:00","closed_at":"2026-02-04T20:40:01.968411088+03:00","close_reason":"All 22 standalone scenarios created. Unblock WS-008-07.","dependencies":[{"issue_id":"spark_k8s-3i5","depends_on_id":"spark_k8s-ikw","type":"blocks","created_at":"2026-02-04T00:31:24.277767364+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3vr","title":"WS-010-01: Spark core layers (4) + tests","description":"Create Spark core intermediate layers for 3.5.7, 3.5.8, 4.1.0, 4.1.1 with unit tests.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:46:50.810152378+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:46:50.810152378+03:00","dependencies":[{"issue_id":"spark_k8s-3vr","depends_on_id":"spark_k8s-dc0","type":"blocks","created_at":"2026-02-04T00:47:27.29204018+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-3yd","title":"WS-017-04: Go load tests","description":"8 load test scenarios for Go client.\n\n- Sustained load: 30 min at 1 query/sec\n- Concurrent connections: 2+ parallel clients\n- Heavy aggregation load tests\n- Memory/CPU profiling with pprof\n- Go benchmarks (go test -bench)\n- Performance comparison with Python client\n\nScope: MEDIUM (~700 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T13:03:33.422832548+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:03:33.422832548+03:00","dependencies":[{"issue_id":"spark_k8s-3yd","depends_on_id":"spark_k8s-cqy","type":"blocks","created_at":"2026-02-04T13:03:40.611504497+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-3yd","depends_on_id":"spark_k8s-1cb","type":"blocks","created_at":"2026-02-04T13:03:41.277127483+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-47g","title":"F13: Phase 7 - Load Tests","description":"20 load scenarios for performance and stability testing under sustained load (30 min).\n\n- WS-013-01: Baseline load (4 scenarios)\n- WS-013-02: GPU load (4 scenarios)\n- WS-013-03: Iceberg load (4 scenarios)\n- WS-013-04: Comparison load (4 scenarios)\n- WS-013-05: Security stability (4 scenarios)\n\nTotal: 20 scenarios across 5 workstreams\nEstimated LOC: ~3000","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:17:45.644487327+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:17:45.644487327+03:00"}
{"id":"spark_k8s-4jm","title":"Fix podSecurityStandards comment inconsistency in values.yaml","description":"\nComment says podSecurityStandards: false but value is true\nNeed to sync documentation with actual default\n","status":"closed","priority":2,"issue_type":"bug","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T17:46:05.085982547+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T17:49:03.282404093+03:00","closed_at":"2026-02-04T17:49:03.282404093+03:00","close_reason":"Added comment explaining podSecurityStandards default change to true for OpenShift compatibility"}
{"id":"spark_k8s-4ku","title":"Phase 2: Complete Smoke Tests","status":"tombstone","priority":0,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:21:04.498138715+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:23:14.330785487+03:00","deleted_at":"2026-02-04T00:23:14.330785487+03:00","deleted_by":"daemon","delete_reason":"delete","original_type":"feature"}
{"id":"spark_k8s-4ll","title":"WS-009-03: CUDA 12.1 base layer + test","description":"Create CUDA 12.1 base Docker image with NVIDIA runtime, unit tests, and GPU support validation.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:42:06.495714562+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:42:06.495714562+03:00","dependencies":[{"issue_id":"spark_k8s-4ll","depends_on_id":"spark_k8s-nxo","type":"blocks","created_at":"2026-02-04T00:42:38.732444785+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-4ll","depends_on_id":"spark_k8s-fl6","type":"blocks","created_at":"2026-02-04T00:44:55.983911591+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-55o","title":"WS-008-01: Jupyter GPU/Iceberg scenarios (12)","description":"Create smoke test scenarios for Jupyter with GPU and Iceberg features across Spark versions 3.5.7, 3.5.8, 4.1.0, 4.1.1","status":"closed","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:01.88871078+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:02:22.32050947+03:00","closed_at":"2026-02-04T20:02:22.32050947+03:00","close_reason":"WS completed: 12 Jupyter GPU/Iceberg scenarios created"}
{"id":"spark_k8s-648","title":"WS-015-01: Parallel execution framework","description":"Parallel execution framework for concurrent test execution.\n\n- GNU parallel with xargs fallback\n- 4+ concurrent tests (configurable via MAX_PARALLEL)\n- Unique namespace/release per test (isolation)\n- Automatic cleanup on completion/failure\n- Retry mechanism for namespace conflicts\n\nScripts:\n- scripts/parallel/run_parallel.sh (main orchestrator)\n- scripts/parallel/run_scenario.sh (single scenario)\n- scripts/parallel/cleanup.sh (namespace cleanup)\n\nScope: MEDIUM (~800 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:58:37.448204402+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:58:37.448204402+03:00","dependencies":[{"issue_id":"spark_k8s-648","depends_on_id":"spark_k8s-dyz","type":"blocks","created_at":"2026-02-04T10:58:45.534529878+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-659","title":"Remove S3 config duplication in spark-connect-configmap.yaml","description":"\nS3 configuration appears twice (lines 65-71 and 89-93)\nNeed to consolidate to avoid duplication and inconsistency\n","status":"closed","priority":2,"issue_type":"bug","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T17:46:04.852628612+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T17:50:13.385452607+03:00","closed_at":"2026-02-04T17:50:13.385452607+03:00","close_reason":"Removed duplicate S3 config block (lines 89-93) from spark-connect-configmap.yaml - kept the conditional version (lines 65-71)"}
{"id":"spark_k8s-6ad","title":"WS-012-01: Core E2E (24 scenarios)","description":"Create 24 core E2E test scenarios for Spark 3.5 with Jupyter, Airflow, k8s-submit and connect-k8s modes using full NYC Taxi dataset.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:07.421599968+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:07.421599968+03:00","dependencies":[{"issue_id":"spark_k8s-6ad","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:33.958018368+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1","title":"F27: Preset Expansion","description":"Expand preset library from 11 to 15+ production scenarios. New presets: Streaming with Kafka, Real-time Analytics, Batch ETL Large Scale, Machine Learning Pipeline with MLflow, Cost-Optimized Spot Instances, GPU-Accelerated Training, Hybrid Cloud (on-prem + cloud).","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 3 Growth","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:13.268689693+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:13.268689693+03:00"}
{"id":"spark_k8s-6g1.1","title":"WS-027-01: Streaming preset design","description":"Design preset for streaming workloads with Kafka. Components: Spark Connect, Kafka consumer/producer, checkpointing. Configuration: exactly-once semantics, backpressure handling. values-scenario-streaming-kafka.yaml. Documentation guide.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:23.639374965+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:23.639374965+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.1","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:23.640526078+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.2","title":"WS-027-02: Real-time Analytics preset","description":"Design preset for real-time analytics. Structured streaming with aggregations. Windowing operations (tumble, slide, session). Output to multiple sinks (console, file, database). Monitoring focus.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:23.848518607+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:23.848518607+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.2","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:23.849704201+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.2","depends_on_id":"spark_k8s-6g1.1","type":"blocks","created_at":"2026-02-04T15:37:42.371991566+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.3","title":"WS-027-03: Large Scale Batch preset","description":"Design preset for large-scale batch ETL (TB+ data). Configuration: dynamic allocation aggressive, shuffle service (Celeborn), speculation enabled. Resource planning templates. Cost optimization notes.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:24.098642625+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:24.098642625+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.3","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:24.09984551+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.3","depends_on_id":"spark_k8s-6g1.1","type":"blocks","created_at":"2026-02-04T15:37:42.582162641+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.4","title":"WS-027-04: ML Pipeline preset","description":"Design preset for machine learning workflows. Components: Jupyter with MLflow, feature store integration, model serving. GPU support optional. Hyperparameter tuning patterns. values-scenario-ml-pipeline.yaml","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:24.325107203+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:24.325107203+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.4","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:24.342671861+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.4","depends_on_id":"spark_k8s-6g1.1","type":"blocks","created_at":"2026-02-04T15:37:42.810818967+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.5","title":"WS-027-05: Cost-Optimized Spot preset","description":"Design preset for cost-optimized workloads. Spot instances with fallback to on-demand. Preemption handling. Checkpointing for recovery. Scale-to-zero idle timeout. Target: 70%+ cost savings with acceptable failure rate.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:24.564496897+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:24.564496897+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.5","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:24.565698912+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.5","depends_on_id":"spark_k8s-6g1.1","type":"blocks","created_at":"2026-02-04T15:37:43.024855482+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.6","title":"WS-027-06: GPU Training preset","description":"Design preset for GPU-accelerated training. RAPIDS integration (cuDF, cuML). GPU scheduling configuration. Memory management for GPU workloads. Benchmark comparison: GPU vs CPU. values-scenario-gpu-training.yaml","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:24.797053211+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:24.797053211+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.6","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:24.798164035+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.6","depends_on_id":"spark_k8s-6g1.4","type":"blocks","created_at":"2026-02-04T15:37:43.329683023+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.6","depends_on_id":"spark_k8s-6g1.1","type":"blocks","created_at":"2026-02-04T15:38:40.479970285+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.7","title":"WS-027-07: Hybrid Cloud preset","description":"Design preset for hybrid cloud deployments. On-prem K8s + cloud burst. Data locality awareness. VPN/network configuration. Disaster recovery patterns. Multi-cluster management.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:25.016271235+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:25.016271235+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.7","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:25.017308696+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.7","depends_on_id":"spark_k8s-6g1.3","type":"blocks","created_at":"2026-02-04T15:38:40.059116146+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.7","depends_on_id":"spark_k8s-6g1.5","type":"blocks","created_at":"2026-02-04T15:38:40.291713664+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6g1.8","title":"WS-027-08: Preset validation testing","description":"Create test suite for all new presets. Smoke test: deploy and verify. Integration test: run sample workload. Documentation test: follow guide end-to-end. Update preset catalog with new entries.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:26:25.244106153+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:25.244106153+03:00","dependencies":[{"issue_id":"spark_k8s-6g1.8","depends_on_id":"spark_k8s-6g1","type":"parent-child","created_at":"2026-02-04T15:26:25.245390114+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-6g1.8","depends_on_id":"spark_k8s-6g1.7","type":"blocks","created_at":"2026-02-04T15:38:40.740242694+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6lf","title":"WS-008-03: Spark Operator scenarios (32)","description":"Create smoke test scenarios for Spark Operator mode across components and versions","status":"closed","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:07.548200393+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:42:30.809052918+03:00","closed_at":"2026-02-04T20:42:30.809052918+03:00","close_reason":"All 12 Spark Operator scenarios created: jupyter, airflow, mlflow across 3.5.7, 3.5.8, 4.1.0, 4.1.1"}
{"id":"spark_k8s-6z1","title":"WS-014-01: PSS tests (8 scenarios)","description":"8 PSS (Pod Security Standards) test scenarios with kubeconform validation.\n\n- PSS restricted profile for Spark 3.5/4.1\n- PSS baseline profile for Spark 3.5/4.1\n- Validation via helm template + kubeconform\n- All presets pass PSS validation\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:28.600007591+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:28.600007591+03:00","dependencies":[{"issue_id":"spark_k8s-6z1","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:35.878147522+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-6z6","title":"Add Kafka support to Spark 3.5.7 image","description":"Add spark-sql-kafka-0-10_2.12 jar to Spark 3.5.7 image and rebuild","status":"closed","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:24:09.843570639+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:34:20.22527054+03:00","closed_at":"2026-02-04T13:34:20.22527054+03:00","close_reason":"Spark 3.5.7 собран из исходников с Hadoop 3.4.2 и Kafka support. Все компоненты проверены: Spark 3.5.7 ✅, Hadoop 3.4.2 ✅ (BulkDeleteOperation найден), Kafka ✅, AWS SDK v2 ✅. Образ spark-k8s:3.5.7-hadoop3.4.2 загружен в minikube и протестирован."}
{"id":"spark_k8s-703","title":"F22: Progress Automation","description":"Set up automated progress bot via GitHub Actions. Comment on closed workstreams with summary, update roadmap status automatically, generate weekly progress digest to Telegram channel.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 1","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:23:58.241746977+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:23:58.241746977+03:00"}
{"id":"spark_k8s-703.1","title":"WS-022-01: Workstream completion bot","description":"GitHub Action that triggers on workstream close. Comments with summary: what was done, time taken, test coverage, files changed. Tags relevant maintainers. Format: '✅ WS-XXX-YY completed: [title] - [summary]'","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:27.272648508+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:27.272648508+03:00","dependencies":[{"issue_id":"spark_k8s-703.1","depends_on_id":"spark_k8s-703","type":"parent-child","created_at":"2026-02-04T15:25:27.273922255+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-703.2","title":"WS-022-02: ROADMAP auto-update","description":"GitHub Action to update ROADMAP.md on workstream status changes. Reads beads status, updates progress bars, refreshes timeline. Runs on schedule (hourly) and on demand (workflow_dispatch).","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:25:27.499040882+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:27.499040882+03:00","dependencies":[{"issue_id":"spark_k8s-703.2","depends_on_id":"spark_k8s-703","type":"parent-child","created_at":"2026-02-04T15:25:27.500420425+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.2","depends_on_id":"spark_k8s-703.1","type":"blocks","created_at":"2026-02-04T15:37:30.813788363+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.2","depends_on_id":"spark_k8s-bof.1","type":"blocks","created_at":"2026-02-04T15:37:54.732481909+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-703.3","title":"WS-022-03: Weekly digest generator","description":"Script to generate weekly progress digest. Inputs: closed workstreams, opened issues, test coverage changes, community activity. Output: Markdown formatted for Telegram channel. Auto-post via Telegram bot API.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:27.724445899+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:27.724445899+03:00","dependencies":[{"issue_id":"spark_k8s-703.3","depends_on_id":"spark_k8s-703","type":"parent-child","created_at":"2026-02-04T15:25:27.725917996+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.3","depends_on_id":"spark_k8s-703.1","type":"blocks","created_at":"2026-02-04T15:37:31.049709423+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.3","depends_on_id":"spark_k8s-bof.1","type":"blocks","created_at":"2026-02-04T15:37:55.038038995+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-703.4","title":"WS-022-04: Metrics dashboard","description":"Create metrics dashboard for progress tracking. Visual indicators: velocity, open/closed ratio, community contributions, test coverage trend. Deploy to GitHub Pages or embed in README.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:25:27.952335185+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:27.952335185+03:00","dependencies":[{"issue_id":"spark_k8s-703.4","depends_on_id":"spark_k8s-703","type":"parent-child","created_at":"2026-02-04T15:25:27.953513543+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.4","depends_on_id":"spark_k8s-bof.4","type":"blocks","created_at":"2026-02-04T15:37:55.259178126+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.4","depends_on_id":"spark_k8s-703.3","type":"blocks","created_at":"2026-02-04T15:38:37.862997014+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-703.4","depends_on_id":"spark_k8s-bof.1","type":"blocks","created_at":"2026-02-04T15:38:47.704565506+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w","title":"F19: Documentation Enhancement","description":"Persona-based documentation: getting started guides, tutorials, centralized troubleshooting, migration guides, reference docs. 10 workstreams, ~74 hours. Reduces onboarding from days to hours. Self-service troubleshooting. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T14:41:39.416307511+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:41:39.416307511+03:00"}
{"id":"spark_k8s-71w.1","title":"WS-050-01: Getting Started Guides","description":"P0: Local dev (Minikube/Kind), cloud setup (EKS/GKE/AKS/OpenShift), backend decision guide, first Spark job. 6h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:43:10.509828029+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.10","title":"WS-052-03: Product Team Persona","description":"P2: Self-service analytics for non-technical users. Jupyter quickstart, SQL examples, ad-hoc queries, visualization. 6h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:43:12.650425944+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.11","title":"WS-019-01: Getting Started Guides","description":"P0: Local dev (Minikube/Kind), cloud setup (EKS/GKE/AKS/OpenShift), backend decision guide, first Spark job. 6h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"closed","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:47:03.886924936+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:51:07.159299786+03:00","closed_at":"2026-02-04T15:51:07.159299786+03:00","close_reason":"WS-050-01 completed: Created getting started guides with local/cloud setup, backend selection, first job examples, and helper scripts.","dependencies":[{"issue_id":"spark_k8s-71w.11","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:03.888506112+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.12","title":"WS-019-02: Persona Landing Pages","description":"P0: Data Engineer, DataOps, SRE, Platform Engineer, Product Team landing pages with learning paths. 8h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"closed","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:47:04.176026042+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:56:24.908524567+03:00","closed_at":"2026-02-04T15:56:24.908524567+03:00","close_reason":"WS completed: Created 6 persona landing pages (Data Engineer, DevOps/SRE, Platform Engineer, Data Scientist, Product Team) with complete learning paths, common tasks, and resources","dependencies":[{"issue_id":"spark_k8s-71w.12","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:04.177750409+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.13","title":"WS-019-03: Centralized Troubleshooting","description":"P0: Decision trees for job-not-starting, performance, storage, memory, network issues. 10h, 1-2 days. See docs/drafts/feature-documentation-enhancement.md","status":"closed","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:04.433433368+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:58:41.590720658+03:00","closed_at":"2026-02-04T15:58:41.590720658+03:00","close_reason":"WS completed: Created centralized troubleshooting guide with decision trees for 5 issue categories (Job Won't Start, Performance, Memory, Storage, Network), quick reference commands, health check script, and 2 operational runbooks (Job Failures, Performance Tuning)","dependencies":[{"issue_id":"spark_k8s-71w.13","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:04.434584766+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.14","title":"WS-019-04: Workflow Tutorials","description":"P1: ETL pipeline, ML workflow, streaming, cost optimization, data quality, performance tuning. 16h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:04.667508325+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:04.667508325+03:00","dependencies":[{"issue_id":"spark_k8s-71w.14","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:04.668690643+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.15","title":"WS-019-05: Performance \u0026 Monitoring Guides","description":"P1: Performance tuning, executor sizing, memory config, shuffle optimization, monitoring setup. 12h, 2 days. Depends on F16. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:04.947390743+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:04.947390743+03:00","dependencies":[{"issue_id":"spark_k8s-71w.15","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:04.94856318+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.16","title":"WS-019-06: Migration Guides","description":"P1: Migration from standalone/EMR/Dataproc/Databricks/YARN, version upgrade, compatibility matrix. 10h, 1-2 days. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:05.173490402+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:05.173490402+03:00","dependencies":[{"issue_id":"spark_k8s-71w.16","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:05.17460562+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.17","title":"WS-019-07: DataOps Persona Path","description":"P1: Complete DataOps documentation path: deployment, CI/CD, monitoring, data quality, backup/DR. 8h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:47:05.459979597+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:05.459979597+03:00","dependencies":[{"issue_id":"spark_k8s-71w.17","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:05.461019025+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.18","title":"WS-019-08: Advanced Workflows","description":"P2: Streaming patterns, exactly-once, backpressure, state management, joins, advanced SQL, UDFs, connectors. 12h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:05.728742718+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:05.728742718+03:00","dependencies":[{"issue_id":"spark_k8s-71w.18","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:05.729932345+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.19","title":"WS-019-09: Reference Documentation","description":"P2: Complete values reference, Helm parameters, CLI reference, config reference, metrics reference. Auto-generated. 14h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:47:05.963011543+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:05.963011543+03:00","dependencies":[{"issue_id":"spark_k8s-71w.19","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:05.981302393+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.2","title":"WS-050-02: Persona Landing Pages","description":"P0: Data Engineer, DataOps, SRE, Platform Engineer, Product Team landing pages with learning paths. 8h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:43:10.7758585+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.20","title":"WS-019-10: Product Team Persona","description":"P2: Self-service analytics for non-technical users. Jupyter quickstart, SQL examples, ad-hoc queries, visualization. 6h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:47:06.220327008+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:06.220327008+03:00","dependencies":[{"issue_id":"spark_k8s-71w.20","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T14:47:06.221669295+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.21","title":"WS-019-11: Video Content Creation","description":"Create video tutorials for key workflows. Videos: '5-minute quick start', 'Troubleshooting failed jobs', 'Deploying first pipeline'. Screen recordings with voiceover. Host on YouTube, embed in docs. Transcripts for accessibility.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":300,"created_at":"2026-02-04T15:27:10.794937023+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:10.794937023+03:00","dependencies":[{"issue_id":"spark_k8s-71w.21","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T15:27:10.796060194+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.22","title":"WS-019-12: Interactive Tutorial Platform","description":"Build interactive tutorial platform. Step-by-step guided exercises. In-browser code execution (optional). Progress tracking and completion certificates. Feedback collection. Gamification: badges for completing tutorials.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":400,"created_at":"2026-02-04T15:27:11.025501331+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:11.025501331+03:00","dependencies":[{"issue_id":"spark_k8s-71w.22","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T15:27:11.026759723+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-71w.22","depends_on_id":"spark_k8s-71w.11","type":"blocks","created_at":"2026-02-04T15:38:44.284608314+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-71w.22","depends_on_id":"spark_k8s-71w.23","type":"blocks","created_at":"2026-02-04T15:38:44.545232957+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.23","title":"WS-019-13: API Documentation","description":"Generate API documentation from Helm charts. Document all values.yaml options with examples. Default values, constraints, interactions between values. Auto-generate from chart schema. Versioned docs per chart version.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:27:11.249175038+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:11.249175038+03:00","dependencies":[{"issue_id":"spark_k8s-71w.23","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T15:27:11.25041634+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-71w.23","depends_on_id":"spark_k8s-71w.16","type":"blocks","created_at":"2026-02-04T15:38:45.050347159+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.24","title":"WS-019-14: Video Documentation Site","description":"Create video documentation site. Host tutorial videos. Categories: getting started, operations, advanced. SEO-optimized pages. Transcript search. Video embedding in other docs.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":200,"created_at":"2026-02-04T15:27:11.501527237+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:11.501527237+03:00","dependencies":[{"issue_id":"spark_k8s-71w.24","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T15:27:11.502624893+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-71w.24","depends_on_id":"spark_k8s-71w.21","type":"blocks","created_at":"2026-02-04T15:37:50.420459109+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.25","title":"WS-019-15: Community Contributed Docs","description":"Enable community documentation contributions. Template for community guides. Review and merge process. Attribution for contributors. Featured community docs. Doc sprint events for bulk contribution.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":150,"created_at":"2026-02-04T15:27:11.748679048+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:11.748679048+03:00","dependencies":[{"issue_id":"spark_k8s-71w.25","depends_on_id":"spark_k8s-71w","type":"parent-child","created_at":"2026-02-04T15:27:11.751310027+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-71w.25","depends_on_id":"spark_k8s-13p.3","type":"blocks","created_at":"2026-02-04T15:38:44.792926107+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-71w.3","title":"WS-050-03: Centralized Troubleshooting","description":"P0: Decision trees for job-not-starting, performance, storage, memory, network issues. 10h, 1-2 days. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:11.013184372+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.4","title":"WS-051-01: Workflow Tutorials","description":"P1: ETL pipeline, ML workflow, streaming, cost optimization, data quality, performance tuning. 16h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:11.263538081+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.5","title":"WS-051-02: Performance \u0026 Monitoring Guides","description":"P1: Performance tuning, executor sizing, memory config, shuffle optimization, monitoring setup. 12h, 2 days. Depends on F16. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:11.48613356+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.6","title":"WS-051-03: Migration Guides","description":"P1: Migration from standalone/EMR/Dataproc/Databricks/YARN, version upgrade, compatibility matrix. 10h, 1-2 days. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:11.732204145+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.7","title":"WS-051-04: DataOps Persona Path","description":"P1: Complete DataOps documentation path: deployment, CI/CD, monitoring, data quality, backup/DR. 8h, 1 day. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T14:43:11.976679864+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.8","title":"WS-052-01: Advanced Workflows","description":"P2: Streaming patterns, exactly-once, backpressure, state management, joins, advanced SQL, UDFs, connectors. 12h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:12.225342643+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-71w.9","title":"WS-052-02: Reference Documentation","description":"P2: Complete values reference, Helm parameters, CLI reference, config reference, metrics reference. Auto-generated. 14h, 2 days. See docs/drafts/feature-documentation-enhancement.md","status":"tombstone","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T14:43:12.448135529+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:47:32.887300966+03:00","deleted_at":"2026-02-04T14:47:32.887300966+03:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"spark_k8s-74z","title":"F16: Phase 10 - Observability (Monitoring \u0026 Tracing)","description":"Full observability stack for Spark K8s: metrics (Prometheus), logs (Loki), traces (Jaeger/OTel), dashboards (Grafana), alerting, Spark UI integration.\n\n- WS-016-01: Metrics collection (Prometheus + JMX exporter)\n- WS-016-02: Logging aggregation (Loki + Promtail)\n- WS-016-03: Distributed tracing (Jaeger + OpenTelemetry)\n- WS-016-04: Dashboards (Grafana with 5+ dashboards)\n- WS-016-05: Alerting rules (AlertManager + Slack)\n- WS-016-06: Spark UI integration (unified view)\n\nFeatures:\n- Prometheus metrics (15s scrape, JMX exporter)\n- Loki log aggregation (JSON structured, trace ID correlation)\n- Jaeger distributed tracing (OpenTelemetry, SQL/shuffle tracing)\n- Grafana dashboards (cluster, apps, executors, SQL, resources)\n- AlertManager (critical/warning/info, Slack notifications)\n- Spark UI integration (metrics, traces, logs embedded)\n\nEstimated LOC: ~3600","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:05.277365713+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:05.277365713+03:00"}
{"id":"spark_k8s-750","title":"WS-012-03: Iceberg E2E (16 scenarios)","description":"Create 16 Iceberg E2E test scenarios for table operations validation.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:07.873450687+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:07.873450687+03:00","dependencies":[{"issue_id":"spark_k8s-750","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:34.401632864+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-772","title":"WS-017-03: Go E2E tests","description":"16 E2E test scenarios for Go client.\n\n- NYC Taxi dataset queries (11GB)\n- COUNT, GROUP BY, JOIN operations\n- Window functions, CTE, subqueries\n- Complex multi-step queries\n- Performance comparison with Python client\n- Same queries as Phase 6 E2E tests\n\nScope: MEDIUM (~700 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T13:03:33.197171869+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:03:33.197171869+03:00","dependencies":[{"issue_id":"spark_k8s-772","depends_on_id":"spark_k8s-cqy","type":"blocks","created_at":"2026-02-04T13:03:40.348978679+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-772","depends_on_id":"spark_k8s-1cb","type":"blocks","created_at":"2026-02-04T13:03:41.052820699+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-7cv","title":"WS-010-04: JARs layers (RAPIDS, Iceberg) + tests","description":"Create JARs layers for RAPIDS and Iceberg with download and caching.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:46:51.503230195+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:46:51.503230195+03:00","dependencies":[{"issue_id":"spark_k8s-7cv","depends_on_id":"spark_k8s-dc0","type":"blocks","created_at":"2026-02-04T00:47:27.952548441+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-7yj","title":"WS-008-07: Parallel execution improvements","description":"Improve parallel execution: skip logic, intelligent scheduling, aggregated logging, retry mechanism","status":"closed","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:20.367118944+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:40:02.213729346+03:00","closed_at":"2026-02-04T20:40:02.213729346+03:00","close_reason":"Parallel execution improvements complete","dependencies":[{"issue_id":"spark_k8s-7yj","depends_on_id":"spark_k8s-3i5","type":"blocks","created_at":"2026-02-04T00:31:31.195663675+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-89o","title":"WS-010-02: Python dependencies layer + test","description":"Create Python dependencies intermediate layer with requirements.txt management.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:46:51.036507117+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:46:51.036507117+03:00","dependencies":[{"issue_id":"spark_k8s-89o","depends_on_id":"spark_k8s-dc0","type":"blocks","created_at":"2026-02-04T00:47:27.505679217+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-97a","title":"F12: Phase 6 - E2E Tests","description":"Create 80 E2E scenarios with full dataset (NYC Taxi 11GB) to validate all Spark version, component, mode, and feature combinations.","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:01:56.091200453+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:01:56.091200453+03:00"}
{"id":"spark_k8s-9io","title":"WS-014-03: Network policies (6 scenarios)","description":"6 network policy test scenarios with default-deny + explicit allow.\n\n- Default-deny ingress/egress policies\n- Explicit allow for Spark components\n- MinIO/PostgreSQL access rules\n- No overly permissive policies\n\nScope: MEDIUM (~500 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:29.109159284+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:29.109159284+03:00","dependencies":[{"issue_id":"spark_k8s-9io","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:36.3200557+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-9qv","title":"Fix Scala version inconsistency in Dockerfile.4.1.0","notes":"\nENV SCALA_VERSION=2.13 but downloads scala-2.12.19.tgz\nNeed to download scala-2.13.x for Spark 4.1.0\nFile: docker/spark-custom/Dockerfile.4.1.0\n","status":"closed","priority":2,"issue_type":"bug","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T17:45:54.48700606+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T17:47:32.020996443+03:00","closed_at":"2026-02-04T17:47:32.020996443+03:00","close_reason":"Fixed: Scala 2.13.14 downloaded for Spark 4.1.0 (was 2.12.19)"}
{"id":"spark_k8s-a7c","title":"WS-012-06: Library compatibility (8 scenarios)","description":"Create 8 library compatibility E2E test scenarios.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:08.524801828+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:08.524801828+03:00","dependencies":[{"issue_id":"spark_k8s-a7c","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:35.077552303+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-aus","title":"WS-013-01: Baseline load (4 scenarios)","description":"4 baseline load test scenarios (Spark 3.5.8, 4.1.1 × Airflow) with 30-minute sustained load.\n\n- Each test runs for 30 minutes at 1 query/second\n- Throughput metrics collected (queries/sec)\n- Latency percentiles captured (p50, p95, p99)\n- Error rate \u003c 1% for all scenarios\n- Fixed resources (no dynamic allocation)\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:17:57.074751524+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:17:57.074751524+03:00","dependencies":[{"issue_id":"spark_k8s-aus","depends_on_id":"spark_k8s-47g","type":"blocks","created_at":"2026-02-04T01:18:21.566576824+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-b1r","title":"WS-012-04: GPU+Iceberg E2E (8 scenarios)","description":"Create 8 GPU+Iceberg combined E2E test scenarios.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:02:08.081865567+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:02:08.081865567+03:00","dependencies":[{"issue_id":"spark_k8s-b1r","depends_on_id":"spark_k8s-97a","type":"blocks","created_at":"2026-02-04T01:02:34.63474191+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-bof","title":"F20: Public ROADMAP","description":"Create public ROADMAP.md from beads backlog. Visual timeline showing F01-F19 with current status indicators, live progress updates, and clear milestones. Transparency and accountability for community trust.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 1","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:23:52.507370524+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:23:52.507370524+03:00"}
{"id":"spark_k8s-bof.1","title":"WS-020-01: Create ROADMAP.md structure","description":"Design and create public ROADMAP.md file. Visual timeline showing F01-F29 with current status indicators (planned, in-progress, completed, blocked). Milestone markers with target dates. Progress bars for each feature. Link to live status from beads.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:21.176515532+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:21.176515532+03:00","dependencies":[{"issue_id":"spark_k8s-bof.1","depends_on_id":"spark_k8s-bof","type":"parent-child","created_at":"2026-02-04T15:25:21.17784928+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-bof.2","title":"WS-020-02: Automated status sync","description":"GitHub Action or script to sync beads status to ROADMAP.md. Runs on push to main, on workstream close, on feature status change. Updates progress bars and status indicators automatically.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:21.408808853+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:21.408808853+03:00","dependencies":[{"issue_id":"spark_k8s-bof.2","depends_on_id":"spark_k8s-bof","type":"parent-child","created_at":"2026-02-04T15:25:21.410036501+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-bof.2","depends_on_id":"spark_k8s-bof.1","type":"blocks","created_at":"2026-02-04T15:37:29.057972422+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-bof.3","title":"WS-020-03: Visual timeline rendering","description":"Add visual timeline component to ROADMAP.md. Mermaid diagram or custom SVG showing feature phases. Dependency visualization between features. Current date marker with progress indicators.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:25:21.642833062+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:21.642833062+03:00","dependencies":[{"issue_id":"spark_k8s-bof.3","depends_on_id":"spark_k8s-bof","type":"parent-child","created_at":"2026-02-04T15:25:21.643890301+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-bof.3","depends_on_id":"spark_k8s-bof.1","type":"blocks","created_at":"2026-02-04T15:37:29.328275476+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-bof.4","title":"WS-020-04: Milestone tracking dashboard","description":"Create milestone tracking section in ROADMAP.md. Quarterly goals with progress. Key deliverables checklist. Upcoming milestones preview. Historical milestones archive.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:21.857992788+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:21.857992788+03:00","dependencies":[{"issue_id":"spark_k8s-bof.4","depends_on_id":"spark_k8s-bof","type":"parent-child","created_at":"2026-02-04T15:25:21.859251117+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-bof.4","depends_on_id":"spark_k8s-bof.2","type":"blocks","created_at":"2026-02-04T15:38:37.117168276+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-c9e","title":"WS-014-05: Secret management (6 scenarios)","description":"6 secret management test scenarios for K8s native secrets.\n\n- Secret creation/mounting\n- Environment variable injection\n- Volume mount secrets\n- No secrets in plain text\n\nScope: MEDIUM (~500 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:29.599320385+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:29.599320385+03:00","dependencies":[{"issue_id":"spark_k8s-c9e","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:36.751008114+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-cef","title":"Fix UID mismatch between Dockerfile and OpenShift presets","description":"\nDockerfile creates spark user with UID 185\nOpenShift preset uses UID 1000000000\nThis causes permission issues on OpenShift\nNeed to make UID configurable or document the mismatch\n","status":"closed","priority":2,"issue_type":"bug","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T17:46:04.617463869+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T17:53:15.27253745+03:00","closed_at":"2026-02-04T17:53:15.27253745+03:00","close_reason":"Fixed: Made UID configurable via ARG (SPARK_UID/SPARK_GID), updated OpenShift presets to use UID 185, added README with OpenShift build instructions"}
{"id":"spark_k8s-ch5","title":"WS-010-03: JDBC drivers layer + test","description":"Create JDBC drivers layer (PostgreSQL, MySQL, Oracle, MSSQL, Vertica) with tests.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:46:51.279092599+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:55:31.594836568+03:00","dependencies":[{"issue_id":"spark_k8s-ch5","depends_on_id":"spark_k8s-dc0","type":"blocks","created_at":"2026-02-04T00:47:27.732303049+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-cqy","title":"F17: Phase 11 - Spark Connect Go Client","description":"Spark Connect Go client library and testing framework.\n\n- WS-017-01: Spark Connect Go client library\n- WS-017-02: Go smoke tests (12 scenarios)\n- WS-017-03: Go E2E tests (16 scenarios)\n- WS-017-04: Go load tests (8 scenarios)\n\nFeatures:\n- gRPC-based Spark Connect client for Go\n- SQL execution and DataFrame operations\n- Session management and connection lifecycle\n- Smoke tests: connection, SQL, DataFrame, error handling\n- E2E tests: NYC Taxi dataset, complex queries, performance\n- Load tests: sustained load, concurrent connections, benchmarks\n- Performance comparison with Python client\n\nBased on official Apache Spark Connect Go client.\nEstimated LOC: ~2800","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T13:03:20.896245277+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:03:20.896245277+03:00"}
{"id":"spark_k8s-cuv","title":"WS-008-06: Dataset generation utilities","description":"Create utilities for generating test datasets (NYC Taxi sample ~100MB)","status":"closed","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:14.907392891+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:04:34.034210193+03:00","closed_at":"2026-02-04T20:04:34.034210193+03:00","close_reason":"WS completed: Dataset generation utility created with README and .gitignore","dependencies":[{"issue_id":"spark_k8s-cuv","depends_on_id":"spark_k8s-55o","type":"blocks","created_at":"2026-02-04T00:31:28.553678995+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-cy5","title":"F14: Phase 8 - Advanced Security","description":"48 security scenarios for PSS, SCC, Network Policies, RBAC, Secret Management, Container Security, S3 Security.\n\n- WS-014-01: PSS tests (8 scenarios)\n- WS-014-02: SCC tests (12 scenarios)\n- WS-014-03: Network policies (6 scenarios)\n- WS-014-04: RBAC tests (6 scenarios)\n- WS-014-05: Secret management (6 scenarios)\n- WS-014-06: Container security (8 scenarios)\n- WS-014-07: S3 security (6 scenarios)\n\nTotal: 48 security scenarios\nEstimated LOC: ~4200","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:15.651413326+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:15.651413326+03:00"}
{"id":"spark_k8s-d5e","title":"F18: Production Operations Suite","description":"Complete operational excellence capabilities: runbooks, incident response, backup/DR automation, job CI/CD, SLI/SLO monitoring, cost attribution. 12 workstreams, ~6,400 LOC. Critical for production readiness. Reduces MTTR from hours to \u003c30 minutes. See docs/drafts/feature-production-operations.md","status":"open","priority":0,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T14:41:37.208400408+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:41:37.208400408+03:00"}
{"id":"spark_k8s-d5e.1","title":"WS-018-01: Incident Response Framework","description":"P0: Structured incident response with severity levels (P0-P3), on-call rotation, escalation paths, communication templates, PIRA framework. 600 LOC, 3 days. See docs/drafts/feature-production-operations.md","status":"closed","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":360,"created_at":"2026-02-04T14:42:22.3138732+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T16:01:42.854515412+03:00","closed_at":"2026-02-04T16:01:42.854515412+03:00","close_reason":"WS completed: Created Incident Response Framework with severity levels (P0-P3), 4-phase PIRA workflow (Preparation, Identification, Response, Aftermath), communication templates, escalation policy configuration, incident creation script, and post-incident review template","dependencies":[{"issue_id":"spark_k8s-d5e.1","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:22.320265934+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.10","title":"WS-018-10: Cost Attribution Dashboard","description":"P2: Per-job/team cost tracking, breakdown by component, spot vs on-demand, trends, forecasting. 600 LOC, 3 days. Depends on F16. See docs/drafts/feature-production-operations.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":360,"created_at":"2026-02-04T14:42:46.762988326+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:46.762988326+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.10","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:46.768030095+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.11","title":"WS-018-11: Budget Alerts \u0026 Optimization","description":"P2: Budget definition, alerts (50/80/100%), anomaly detection, rightsizing, idle resources. 500 LOC, 2 days. See docs/drafts/feature-production-operations.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":240,"created_at":"2026-02-04T14:42:47.01094215+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:47.01094215+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.11","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:47.016565668+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.11","depends_on_id":"spark_k8s-d5e.10","type":"blocks","created_at":"2026-02-04T14:42:47.020034698+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.12","title":"WS-018-12: Runbook Testing \u0026 Validation","description":"P2: Automated runbook tests, monthly drills, accuracy metrics (\u003e90%), maintenance checklist. 500 LOC, 2 days. See docs/drafts/feature-production-operations.md","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":240,"created_at":"2026-02-04T14:42:47.261565507+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:47.261565507+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.12","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:47.265475388+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.13","title":"WS-018-13: Runbook Execution Automation","description":"Automate runbook execution for validation. Script that runs each runbook in test environment. Validates fix steps work as documented. Generates report of runbook health. Auto-update runbooks if detected changes in Spark/K8s.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:27:07.975679075+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:07.975679075+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.13","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T15:27:07.976989397+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.13","depends_on_id":"spark_k8s-d5e.7","type":"blocks","created_at":"2026-02-04T15:37:47.755580874+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.13","depends_on_id":"spark_k8s-d5e.2","type":"blocks","created_at":"2026-02-04T15:37:48.080425906+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.14","title":"WS-018-14: Incident Response Training","description":"Create incident response training materials. Simulation scenarios for team practice. Fire drill procedures. Post-simulation review templates. Training video: 'MTTR in 30 minutes'. Checklist for on-call readiness.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:27:08.204617301+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:08.204617301+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.14","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T15:27:08.205660004+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.14","depends_on_id":"spark_k8s-d5e.1","type":"blocks","created_at":"2026-02-04T15:37:48.422192101+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.15","title":"WS-018-15: SLO-based Alerting Extensions","description":"Extend SLO-based alerting beyond basics. Burn rate alerts (error budget consumption). Multi-window alerts (5min, 1h, 24h). SLO miss root cause analysis templates. Alert tuning guide. Integration with AlertManager.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":150,"created_at":"2026-02-04T15:27:08.423974714+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:08.423974714+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.15","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T15:27:08.425080486+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.15","depends_on_id":"spark_k8s-d5e.4","type":"blocks","created_at":"2026-02-04T15:37:48.769224184+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.16","title":"WS-018-16: Chaos Testing Integration","description":"Integrate chaos engineering into operations. Chaos scenarios: pod kills, network partition, S3 outage. Automated chaos tests with validation. Recovery time tracking. Chaos metrics dashboard. Integration with Chaos Mesh/Litmus.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":200,"created_at":"2026-02-04T15:27:08.655623403+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:08.655623403+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.16","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T15:27:08.656791295+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.16","depends_on_id":"spark_k8s-d5e.6","type":"blocks","created_at":"2026-02-04T15:37:49.291020505+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.16","depends_on_id":"spark_k8s-d5e.2","type":"blocks","created_at":"2026-02-04T15:38:43.569267835+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.16","depends_on_id":"spark_k8s-d5e.3","type":"blocks","created_at":"2026-02-04T15:38:44.060339904+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.17","title":"WS-018-17: Operations Playbook Portal","description":"Create centralized operations portal. Web interface for all runbooks. Search by symptom, error, component. Runbook execution tracking. Favorite runbooks. Feedback loop for runbook improvement.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":240,"created_at":"2026-02-04T15:27:08.882725125+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:08.882725125+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.17","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T15:27:08.883954447+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.17","depends_on_id":"spark_k8s-d5e.3","type":"blocks","created_at":"2026-02-04T15:38:43.797061912+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.2","title":"WS-018-02: Spark Application Failure Runbooks","description":"P0: Runbooks for driver crashes, executor failures, OOM kills, task failures, shuffle issues, Connect problems. 800 LOC, 4 days. See docs/drafts/feature-production-operations.md","status":"open","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":480,"created_at":"2026-02-04T14:42:22.594924782+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:22.594924782+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.2","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:22.601602645+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.2","depends_on_id":"spark_k8s-d5e","type":"blocks","created_at":"2026-02-04T14:42:22.607320167+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.3","title":"WS-018-03: Data Layer Recovery Runbooks","description":"P0: Automated recovery for Hive Metastore, S3/MinIO, data integrity verification. 900 LOC, 4 days. RTO \u003c30min. See docs/drafts/feature-production-operations.md","status":"open","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":480,"created_at":"2026-02-04T14:42:22.827947302+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:22.827947302+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.3","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:22.835440663+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.3","depends_on_id":"spark_k8s-d5e","type":"blocks","created_at":"2026-02-04T14:42:22.840714019+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.4","title":"WS-018-04: SLI/SLO Definitions \u0026 Monitoring","description":"P0: SLI definitions, SLO targets (99.9%), error budgets, burn rate alerts, dashboards. 600 LOC, 3 days. Depends on F16. See docs/drafts/feature-production-operations.md","status":"closed","priority":0,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":360,"created_at":"2026-02-04T14:42:23.033545367+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T16:04:46.539527293+03:00","closed_at":"2026-02-04T16:04:46.539527293+03:00","close_reason":"WS completed: Created comprehensive SLI/SLO documentation with 5 SLIs (Availability, Job Success Rate, Latency, Throughput, Error Rate), 3 tiers of alerting rules (Critical/Warning/Info), Prometheus rules configuration, Grafana dashboard JSON, and SLO report generation script","dependencies":[{"issue_id":"spark_k8s-d5e.4","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:23.038663825+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.5","title":"WS-018-05: Scaling \u0026 Capacity Planning","description":"P1: HPA/VPA, KEDA, cluster autoscaler, capacity calculator, rightsizing, cost optimization. 800 LOC, 3 days. See docs/drafts/feature-production-operations.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":360,"created_at":"2026-02-04T14:42:45.465893526+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:45.465893526+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.5","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:45.470638995+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.6","title":"WS-018-06: Post-Incident Review Process","description":"P1: PIRA template, root cause analysis, action tracking, learning dissemination. 400 LOC, 2 days. See docs/drafts/feature-production-operations.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":240,"created_at":"2026-02-04T14:42:45.768184403+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:45.768184403+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.6","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:45.773431921+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.6","depends_on_id":"spark_k8s-d5e.1","type":"blocks","created_at":"2026-02-04T14:42:45.77869177+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.7","title":"WS-018-07: Backup/DR Automation","description":"P1: CronJob backups, verification, restore testing, retention policies. 900 LOC, 4 days. 99.9%+ success. See docs/drafts/feature-production-operations.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":480,"created_at":"2026-02-04T14:42:46.01179333+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:46.01179333+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.7","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:46.016672758+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.7","depends_on_id":"spark_k8s-d5e.3","type":"blocks","created_at":"2026-02-04T14:42:46.021409327+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.8","title":"WS-018-08: Job CI/CD Framework","description":"P1: GitHub Actions for Spark jobs, dry-run, validation, promotion, rollback, A/B testing. 1000 LOC, 5 days. Depends on F08/F12/F15. See docs/drafts/feature-production-operations.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":600,"created_at":"2026-02-04T14:42:46.26609123+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:46.26609123+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.8","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:46.270801198+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-d5e.9","title":"WS-018-09: SQL \u0026 Code Validation","description":"P1: Spark SQL validation, Python/Scala linting, security scanning, performance regression. 700 LOC, 3 days. See docs/drafts/feature-production-operations.md","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":360,"created_at":"2026-02-04T14:42:46.512579297+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T14:42:46.512579297+03:00","dependencies":[{"issue_id":"spark_k8s-d5e.9","depends_on_id":"spark_k8s-d5e","type":"parent-child","created_at":"2026-02-04T14:42:46.516096239+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-d5e.9","depends_on_id":"spark_k8s-d5e.8","type":"blocks","created_at":"2026-02-04T14:42:46.520731168+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dc0","title":"F10: Phase 4 - Docker Intermediate Layers","description":"Create intermediate Docker layers (Spark core, Python deps, JDBC drivers, JARs) with unit tests for optimized Spark images.","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:46:39.12629441+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:46:39.12629441+03:00"}
{"id":"spark_k8s-dfv","title":"WS-016-03: Distributed tracing (Jaeger)","description":"Jaeger + OpenTelemetry for distributed tracing.\n\n- Jaeger all-in-one deployment\n- OpenTelemetry integration with Spark\n- Trace context propagation\n- SQL query tracing\n- Shuffle operation tracing\n- 10% probabilistic sampling\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:46.583614656+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:46.583614656+03:00","dependencies":[{"issue_id":"spark_k8s-dfv","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:03.477211574+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8","title":"F24: Pre-built Docker Images","description":"Push spark-custom:4.1.0 and jupyter-spark:4.1.0 to GitHub Container Registry (GHCR). Eliminate image build friction for users. GitHub Actions for automated builds on tag/release. Multi-arch support (amd64, arm64).","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Product-Led Growth. Can extend F11 (Docker Runtime Images).","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:02.514089961+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:02.514089961+03:00"}
{"id":"spark_k8s-ds8.1","title":"WS-024-01: GHCR registry setup","description":"Set up GitHub Container Registry for spark_k8s images. Configure repository permissions. Document pull instructions. Update README with ghcr.io references. Token-based authentication for CI/CD.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:32.241383843+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:32.241383843+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.1","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:32.242453+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8.2","title":"WS-024-02: Build automation for spark-custom","description":"GitHub Action workflow to build spark-custom:4.1.0 image. Trigger: on tag, on push to main, on schedule (weekly). Multi-stage build for size optimization. Security scan with Trivy. Push to ghcr.io/fall-out-bug/spark-k8s.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:32.466453477+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:32.466453477+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.2","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:32.467532355+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ds8.2","depends_on_id":"spark_k8s-ds8.1","type":"blocks","created_at":"2026-02-04T15:37:35.103910692+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8.3","title":"WS-024-03: Build automation for jupyter-spark","description":"GitHub Action workflow to build jupyter-spark:4.1.0 image. Include Spark Connect client, Python dependencies, sample notebooks. Trigger: on tag, on push to main. Security scan. Push to GHCR.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:32.689576601+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:32.689576601+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.3","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:32.690705998+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ds8.3","depends_on_id":"spark_k8s-ds8.1","type":"blocks","created_at":"2026-02-04T15:37:35.333023471+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8.4","title":"WS-024-04: Multi-arch support","description":"Enable multi-architecture builds (amd64, arm64). Use docker buildx or GitHub Actions matrix. Test on both architectures. Document architecture-specific considerations. Update quick-start.sh to detect architecture.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:25:32.913297093+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:32.913297093+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.4","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:32.91461144+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ds8.4","depends_on_id":"spark_k8s-ds8.3","type":"blocks","created_at":"2026-02-04T15:38:38.533967086+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8.5","title":"WS-024-05: Version tagging strategy","description":"Define image versioning strategy. Sync with Spark versions (3.5.7, 4.1.0). Semantic versioning for patches. Latest tag handling. Deprecation policy for old versions. Documentation in README.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:33.133793282+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:33.133793282+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.5","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:33.13496183+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ds8.6","title":"WS-024-06: Update charts for GHCR images","description":"Update all Helm chart values.yaml to use ghcr.io images by default. Document how to override for custom builds. Test pull and deployment. Update all examples and tutorials.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:25:33.368542585+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:33.368542585+03:00","dependencies":[{"issue_id":"spark_k8s-ds8.6","depends_on_id":"spark_k8s-ds8","type":"parent-child","created_at":"2026-02-04T15:25:33.369830362+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ds8.6","depends_on_id":"spark_k8s-ds8.5","type":"blocks","created_at":"2026-02-04T15:38:38.751827321+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ds8.6","depends_on_id":"spark_k8s-ds8.4","type":"blocks","created_at":"2026-02-04T15:38:39.024070331+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dyz","title":"F15: Phase 9 - Parallel Execution \u0026 CI/CD","description":"Parallel execution framework and CI/CD integration for automated testing.\n\n- WS-015-01: Parallel execution framework\n- WS-015-02: Result aggregation\n- WS-015-03: CI/CD integration\n\nFeatures:\n- GNU parallel/xargs for concurrent test execution\n- Namespace/release isolation for parallel tests\n- JSON + JUnit XML + HTML result aggregation\n- GitHub Actions workflows for smoke, E2E, load tests\n- Scheduled runs for full test suite\n\nEstimated LOC: ~2100","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:58:22.205523082+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:58:22.205523082+03:00"}
{"id":"spark_k8s-dyz.1","title":"WS-015-05: Job-Level CI/CD Pipelines","description":"Extend F15 with job-level CI/CD capabilities. Template for Spark job pipelines. Dry-run validation workflow. SQL testing in CI. Data quality gates. A/B testing framework for job changes. Blue-green deployment patterns.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":200,"created_at":"2026-02-04T15:27:15.943567583+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:15.943567583+03:00","dependencies":[{"issue_id":"spark_k8s-dyz.1","depends_on_id":"spark_k8s-dyz","type":"parent-child","created_at":"2026-02-04T15:27:15.944698816+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-dyz.1","depends_on_id":"spark_k8s-dyz.2","type":"blocks","created_at":"2026-02-04T15:37:51.870881295+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dyz.2","title":"WS-015-06: Dry-Run Validation Framework","description":"Build dry-run validation system for Spark jobs. Validate job configuration without execution. Check: resource limits, permissions, dependencies, SQL syntax. Pre-commit hook for job definitions.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":150,"created_at":"2026-02-04T15:27:16.198217963+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:16.198217963+03:00","dependencies":[{"issue_id":"spark_k8s-dyz.2","depends_on_id":"spark_k8s-dyz","type":"parent-child","created_at":"2026-02-04T15:27:16.199432515+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-dyz.2","depends_on_id":"spark_k8s-71w.23","type":"blocks","created_at":"2026-02-04T15:37:52.117480703+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dyz.3","title":"WS-015-07: Job Promotion Automation","description":"Automate job promotion through environments. dev → staging → production. Gate checks between stages. Automatic rollback on failure. Promotion request workflow. Audit trail for all promotions.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:27:16.435530512+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:16.435530512+03:00","dependencies":[{"issue_id":"spark_k8s-dyz.3","depends_on_id":"spark_k8s-dyz","type":"parent-child","created_at":"2026-02-04T15:27:16.436587316+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-dyz.3","depends_on_id":"spark_k8s-dyz.2","type":"blocks","created_at":"2026-02-04T15:37:52.322470958+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dyz.4","title":"WS-015-08: Job Versioning Strategy","description":"Define job versioning strategy. Semantic versioning for job definitions. Migration paths between versions. Rollback capabilities. Version compatibility matrix with Spark versions.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:27:16.664635514+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:16.664635514+03:00","dependencies":[{"issue_id":"spark_k8s-dyz.4","depends_on_id":"spark_k8s-dyz","type":"parent-child","created_at":"2026-02-04T15:27:16.665708278+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-dyz.5","title":"WS-015-09: Job Testing Templates","description":"Create testing templates for Spark jobs. Unit test template for SQL/Python. Integration test template with sample data. Performance regression test. Data quality test template. CI/CD integration examples.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":150,"created_at":"2026-02-04T15:27:16.887954332+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:27:16.887954332+03:00","dependencies":[{"issue_id":"spark_k8s-dyz.5","depends_on_id":"spark_k8s-dyz","type":"parent-child","created_at":"2026-02-04T15:27:16.889254374+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-dyz.5","depends_on_id":"spark_k8s-dyz.1","type":"blocks","created_at":"2026-02-04T15:37:52.540892963+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-dyz.5","depends_on_id":"spark_k8s-dyz.2","type":"blocks","created_at":"2026-02-04T15:38:45.763174936+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-e7p","title":"WS-016-04: Dashboards (Grafana)","description":"Grafana dashboards for observability.\n\n- Grafana Helm chart\n- Prometheus/Loki/Jaeger datasources\n- 5+ dashboards: cluster, apps, executors, SQL, resources\n- Auto-provision from ConfigMaps\n- Dashboard JSON configs\n\nScope: MEDIUM (~500 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:46.828936012+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:46.828936012+03:00","dependencies":[{"issue_id":"spark_k8s-e7p","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:03.742367605+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-e7p","depends_on_id":"spark_k8s-0su","type":"blocks","created_at":"2026-02-04T12:31:04.604602815+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-e7p","depends_on_id":"spark_k8s-wge","type":"blocks","created_at":"2026-02-04T12:31:04.90055627+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ehu","title":"WS-011-02: Spark 4.1 images (8) + tests","description":"Create Spark 4.1.0/4.1.1 runtime images: baseline, GPU, Iceberg, GPU+Iceberg variants with integration tests.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:57:04.401868126+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:57:04.401868126+03:00","dependencies":[{"issue_id":"spark_k8s-ehu","depends_on_id":"spark_k8s-3hr","type":"blocks","created_at":"2026-02-04T00:57:16.859513788+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-f0t","title":"F23: Quick Start Experience","description":"Create magic ./quick-start.sh script that deploys Spark with working Jupyter in \u003c2 minutes. Auto-start Minikube, pull pre-built images, deploy with defaults, port-forward, open browser. ASCII celebration on success.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Product-Led Growth. Reduces time-to-value from 15min to \u003c2min = 3-5x activation increase.","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:00.307726345+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:00.307726345+03:00"}
{"id":"spark_k8s-f0t.1","title":"WS-023-01: Design quick-start flow","description":"Design the \u003c2-minute quick-start experience. User journey: clone repo → run script → see working Spark. Dependencies check (kubectl, helm, docker/k8s). Fallback options for different environments. Error handling with helpful messages.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:29.643157109+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:29.643157109+03:00","dependencies":[{"issue_id":"spark_k8s-f0t.1","depends_on_id":"spark_k8s-f0t","type":"parent-child","created_at":"2026-02-04T15:25:29.644500826+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-f0t.2","title":"WS-023-02: Implement quick-start.sh script","description":"Write bash script ./quick-start.sh. Auto-detect environment (Minikube, Docker Desktop, OpenShift). Start/verify cluster. Pull pre-built images. Deploy with sensible defaults. Port-forward Jupyter. Open browser. Pre-load sample notebook.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:25:29.888692235+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:29.888692235+03:00","dependencies":[{"issue_id":"spark_k8s-f0t.2","depends_on_id":"spark_k8s-f0t","type":"parent-child","created_at":"2026-02-04T15:25:29.889826262+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.2","depends_on_id":"spark_k8s-f0t.1","type":"blocks","created_at":"2026-02-04T15:37:31.545070313+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.2","depends_on_id":"spark_k8s-ds8.3","type":"blocks","created_at":"2026-02-04T15:38:47.939752192+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.2","depends_on_id":"spark_k8s-ds8.2","type":"blocks","created_at":"2026-02-04T15:38:48.176598715+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-f0t.3","title":"WS-023-03: Success celebration UI","description":"Design and implement success message. ASCII art celebration. Deployment time statistics. Configuration summary. Next steps links. Shareable deployment URL (if tracking enabled). Feedback prompt.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":45,"created_at":"2026-02-04T15:25:30.113314616+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:30.113314616+03:00","dependencies":[{"issue_id":"spark_k8s-f0t.3","depends_on_id":"spark_k8s-f0t","type":"parent-child","created_at":"2026-02-04T15:25:30.114457843+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.3","depends_on_id":"spark_k8s-f0t.1","type":"blocks","created_at":"2026-02-04T15:37:31.77710974+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.3","depends_on_id":"spark_k8s-f0t.2","type":"blocks","created_at":"2026-02-04T15:38:38.076891488+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-f0t.4","title":"WS-023-04: Sample notebook creation","description":"Create pre-loaded sample Jupyter notebook. Demonstrates Spark Connect working. Simple DataFrame operation. README cell with next steps. Export to PDF guide. Save to examples/quick-start/","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:25:30.332430051+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:30.332430051+03:00","dependencies":[{"issue_id":"spark_k8s-f0t.4","depends_on_id":"spark_k8s-f0t","type":"parent-child","created_at":"2026-02-04T15:25:30.333530098+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.4","depends_on_id":"spark_k8s-f0t.2","type":"blocks","created_at":"2026-02-04T15:37:32.016271977+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-f0t.5","title":"WS-023-05: Cross-platform testing","description":"Test quick-start.sh on Linux, macOS, WSL2. Verify Minikube, Docker Desktop, Kind clusters. Test with and without existing cluster. Document known issues and workarounds.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:25:30.555158476+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:25:30.555158476+03:00","dependencies":[{"issue_id":"spark_k8s-f0t.5","depends_on_id":"spark_k8s-f0t","type":"parent-child","created_at":"2026-02-04T15:25:30.556308794+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-f0t.5","depends_on_id":"spark_k8s-f0t.3","type":"blocks","created_at":"2026-02-04T15:38:38.268219097+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-fl6","title":"WS-009-01: JDK 17 base layer + test","description":"Create JDK 17 base Docker image with Eclipse Temurin, unit tests, and \u003c200MB target size.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:42:00.159848533+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:42:00.159848533+03:00","dependencies":[{"issue_id":"spark_k8s-fl6","depends_on_id":"spark_k8s-nxo","type":"blocks","created_at":"2026-02-04T00:42:38.288120509+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-gz2","title":"WS-013-03: Iceberg load (4 scenarios)","description":"4 Iceberg load test scenarios (Spark 3.5.8, 4.1.1 × Airflow × Iceberg) with INSERT/MERGE operations.\n\n- INSERT rate \u003e= 10 inserts/second\n- MERGE rate \u003e= 5 merges/second\n- File pruning working (\u003e 50% files skipped)\n- No snapshot explosion\n- 30-minute sustained load\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:18:04.590891095+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:18:04.590891095+03:00","dependencies":[{"issue_id":"spark_k8s-gz2","depends_on_id":"spark_k8s-47g","type":"blocks","created_at":"2026-02-04T01:18:22.006393429+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-hbc","title":"WS-011-01: Spark 3.5 images (8) + tests","description":"Create Spark 3.5.7/3.5.8 runtime images: baseline, GPU, Iceberg, GPU+Iceberg variants with integration tests.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:57:04.187867472+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:57:04.187867472+03:00","dependencies":[{"issue_id":"spark_k8s-hbc","depends_on_id":"spark_k8s-3hr","type":"blocks","created_at":"2026-02-04T00:57:16.643319162+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-hym","title":"WS-008-05: MLflow scenarios (24)","description":"Create smoke test scenarios for MLflow integration with Spark","status":"closed","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:12.302927531+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:39:54.49713975+03:00","closed_at":"2026-02-04T20:39:54.49713975+03:00","close_reason":"All 24 MLflow scenarios created: k8s, connect-k8s, connect-standalone, iceberg, gpu variants"}
{"id":"spark_k8s-ikw","title":"F08: Phase 2 - Complete Smoke Tests","description":"Cover all combinations of Spark versions, components, modes, and features with smoke tests. Target: 139 scenarios. Current: 15 implemented.","notes":"Progress: 139 smoke test scenarios created ✓\n\nTarget achieved: 139/139 (100%)\n\nCompleted workstreams:\n- WS-008-02: 22 standalone scenarios ✓\n- WS-008-04: 12 History Server scenarios ✓  \n- WS-008-05: 24 MLflow scenarios ✓\n- WS-008-07: Parallel execution library ✓\n- WS-008-03: 12 Operator scenarios ✓\n- GPU scenarios: 12 per component (36 total) ✓\n- Iceberg scenarios: 12 per component (36 total) ✓\n- Connect scenarios: 14 total ✓\n- Security scenarios: 12 total ✓\n- Performance scenarios: 12 total ✓\n- Load scenarios: 11 total ✓\n\nBreakdown by component:\n- 49 jupyter scenarios\n- 48 mlflow scenarios\n- 42 airflow scenarios","status":"closed","priority":0,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:29:38.534035466+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:59:26.32937229+03:00","closed_at":"2026-02-04T20:59:26.32937229+03:00","close_reason":"Target achieved: 139/139 smoke test scenarios (100%) created successfully"}
{"id":"spark_k8s-jva","title":"F29: Certification Program","description":"Cluster configuration validation script. Checks against best practices (security, observability, operations). Badge display for certified clusters. Public registry of certified deployments. Partner program for certified vendors.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 4 Authority","status":"open","priority":3,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:16.595354523+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:16.595354523+03:00"}
{"id":"spark_k8s-jva.1","title":"WS-029-01: Validation script design","description":"Design cluster validation script. Checks: security (PSS/SCC compliance), observability (metrics, logging), operations (runbooks exist, backup configured), best practices (resource limits, affinity rules). Pass/fail with detailed report.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:29.921148428+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:29.921148428+03:00","dependencies":[{"issue_id":"spark_k8s-jva.1","depends_on_id":"spark_k8s-jva","type":"parent-child","created_at":"2026-02-04T15:26:29.922214751+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jva.2","title":"WS-029-02: Badge system implementation","description":"Create badge system for certified clusters. SVG badge with version, date, validity period. HTML embed code. Verification endpoint (check if certification current). Display options: light/dark themes.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:30.148326753+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:30.148326753+03:00","dependencies":[{"issue_id":"spark_k8s-jva.2","depends_on_id":"spark_k8s-jva","type":"parent-child","created_at":"2026-02-04T15:26:30.149422887+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jva.2","depends_on_id":"spark_k8s-jva.1","type":"blocks","created_at":"2026-02-04T15:37:44.730310186+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jva.3","title":"WS-029-03: Public registry","description":"Build public registry of certified deployments. Simple web app or GitHub Pages. List of certified clusters (anonymized option). Statistics: total certified, by version, by distribution. Search and filter functionality.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:26:30.370430032+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:30.370430032+03:00","dependencies":[{"issue_id":"spark_k8s-jva.3","depends_on_id":"spark_k8s-jva","type":"parent-child","created_at":"2026-02-04T15:26:30.371890295+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jva.3","depends_on_id":"spark_k8s-jva.2","type":"blocks","created_at":"2026-02-04T15:38:41.233198964+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jva.3","depends_on_id":"spark_k8s-jva.1","type":"blocks","created_at":"2026-02-04T15:38:41.479622114+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jva.4","title":"WS-029-04: Partner program","description":"Design certification partner program. For cloud providers, distros, consultants. Partner tiers: certified, gold, platinum. Benefits: listing, co-marketing, early access. Application process and renewal requirements.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:30.590070991+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:30.590070991+03:00","dependencies":[{"issue_id":"spark_k8s-jva.4","depends_on_id":"spark_k8s-jva","type":"parent-child","created_at":"2026-02-04T15:26:30.591247412+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jva.4","depends_on_id":"spark_k8s-jva.3","type":"blocks","created_at":"2026-02-04T15:37:45.154806071+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jva.5","title":"WS-029-05: Continuous validation","description":"Set up automated re-validation. Periodic checks (quarterly). Alert on certification expiry. Update badges automatically. Notify owners of upcoming expiration. Grace period handling.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:30.800599089+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:30.800599089+03:00","dependencies":[{"issue_id":"spark_k8s-jva.5","depends_on_id":"spark_k8s-jva","type":"parent-child","created_at":"2026-02-04T15:26:30.801692112+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jva.5","depends_on_id":"spark_k8s-jva.3","type":"blocks","created_at":"2026-02-04T15:38:41.7199065+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jvi","title":"F26: Telegram Integration","description":"Telegram chat group link in README. Pin project description in Telegram channel. GitHub → Telegram webhook for issue/PR notifications. Weekly digest automation from GitHub to Telegram.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 2","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:06.855515127+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:06.855515127+03:00"}
{"id":"spark_k8s-jvi.1","title":"WS-026-01: Telegram bot setup","description":"Create Telegram bot for spark_k8s community. BotFather token. Configure webhook endpoint. Basic commands: /start, /help, /status, /roadmap. Privacy-first design (no data collection).","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:20.746362186+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:20.746362186+03:00","dependencies":[{"issue_id":"spark_k8s-jvi.1","depends_on_id":"spark_k8s-jvi","type":"parent-child","created_at":"2026-02-04T15:26:20.747508126+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jvi.2","title":"WS-026-02: GitHub webhook integration","description":"Set up GitHub webhook to Telegram. Events: issues opened/closed, PRs opened/merged, releases published. Formatted messages with links. Rate limiting to avoid spam. Filter by label (optional notifications).","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:20.969865777+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:20.969865777+03:00","dependencies":[{"issue_id":"spark_k8s-jvi.2","depends_on_id":"spark_k8s-jvi","type":"parent-child","created_at":"2026-02-04T15:26:20.970989846+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jvi.2","depends_on_id":"spark_k8s-jvi.1","type":"blocks","created_at":"2026-02-04T15:37:37.359613365+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jvi.3","title":"WS-026-03: Weekly digest automation","description":"Script to generate weekly digest from GitHub activity. Format: summary of closed issues, new contributors, test coverage changes, upcoming features. Auto-post to Telegram channel via bot. Schedule: every Friday 18:00 UTC.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:21.191177994+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:21.191177994+03:00","dependencies":[{"issue_id":"spark_k8s-jvi.3","depends_on_id":"spark_k8s-jvi","type":"parent-child","created_at":"2026-02-04T15:26:21.192491387+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jvi.3","depends_on_id":"spark_k8s-703.3","type":"blocks","created_at":"2026-02-04T15:37:55.976487767+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jvi.3","depends_on_id":"spark_k8s-jvi.2","type":"blocks","created_at":"2026-02-04T15:38:39.560382661+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jvi.3","depends_on_id":"spark_k8s-jvi.1","type":"blocks","created_at":"2026-02-04T15:38:39.804483408+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-jvi.4","title":"WS-026-04: Chat group integration","description":"Link Telegram chat group in README. Pin message with community guidelines. Bot commands for chat: /issues, /prs, /contributors. Bridge between GitHub discussions and Telegram (optional).","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":60,"created_at":"2026-02-04T15:26:21.395683256+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:21.395683256+03:00","dependencies":[{"issue_id":"spark_k8s-jvi.4","depends_on_id":"spark_k8s-jvi","type":"parent-child","created_at":"2026-02-04T15:26:21.396861728+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-jvi.4","depends_on_id":"spark_k8s-jvi.1","type":"blocks","created_at":"2026-02-04T15:37:37.873228672+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-l75","title":"WS-014-07: S3 security (6 scenarios)","description":"6 S3 security test scenarios for data protection.\n\n- TLS in-flight (HTTPS only)\n- Server-side encryption (AES256/aws:kms)\n- IRSA annotation for EKS\n- No HTTP endpoints\n\nScope: MEDIUM (~500 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:30.069115077+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:30.069115077+03:00","dependencies":[{"issue_id":"spark_k8s-l75","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:37.199379633+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-lve","title":"WS-017-02: Go smoke tests","description":"12 smoke test scenarios for Go client.\n\n- Connection tests: Spark 3.5.7, 3.5.8, 4.1.0, 4.1.1\n- SQL operations: basic queries, aggregations\n- DataFrame operations: Collect, Show, Count\n- Connection lifecycle: multiple sessions, close\n- Error handling: invalid SQL, connection failures\n- Table-driven tests for version matrix\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T13:03:32.956622182+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T13:03:32.956622182+03:00","dependencies":[{"issue_id":"spark_k8s-lve","depends_on_id":"spark_k8s-cqy","type":"blocks","created_at":"2026-02-04T13:03:40.112626015+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-lve","depends_on_id":"spark_k8s-1cb","type":"blocks","created_at":"2026-02-04T13:03:40.831957698+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-mhp","title":"WS-015-03: CI/CD integration","description":"GitHub Actions workflows for automated testing.\n\n- Smoke tests workflow (push/PR)\n- E2E tests workflow (daily scheduled)\n- Load tests workflow (weekly scheduled)\n- Scheduled full run workflow\n- PR validation with result publishing\n- Test result artifacts\n\nWorkflows:\n- .github/workflows/smoke-tests.yml\n- .github/workflows/e2e-tests.yml\n- .github/workflows/load-tests.yml\n- .github/workflows/scheduled-tests.yml\n\nScope: MEDIUM (~700 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:58:37.917011397+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:58:37.917011397+03:00","dependencies":[{"issue_id":"spark_k8s-mhp","depends_on_id":"spark_k8s-dyz","type":"blocks","created_at":"2026-02-04T10:58:45.975255616+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-mhp","depends_on_id":"spark_k8s-wvm","type":"blocks","created_at":"2026-02-04T10:58:46.400019691+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-nxo","title":"F09: Phase 3 - Docker Base Layers","description":"Create base Docker layers (JDK 17, Python 3.10, CUDA 12.1) with unit tests for optimized Spark images.","status":"open","priority":1,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:41:23.610820469+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:41:23.610820469+03:00"}
{"id":"spark_k8s-t2l","title":"WS-016-06: Spark UI integration","description":"Spark UI integration with observability stack.\n\n- Spark History Server + Prometheus metrics\n- Spark UI + Jaeger trace links\n- Embedded Grafana dashboards\n- Unified observability view\n- Integration tests\n\nScope: MEDIUM (~800 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:47.351910707+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:47.351910707+03:00","dependencies":[{"issue_id":"spark_k8s-t2l","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:04.287778084+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-t2l","depends_on_id":"spark_k8s-0su","type":"blocks","created_at":"2026-02-04T12:31:05.422346358+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-t2l","depends_on_id":"spark_k8s-dfv","type":"blocks","created_at":"2026-02-04T12:31:05.681726959+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ta8","title":"WS-008-04: History Server validation scenarios (32)","description":"Create smoke test scenarios validating History Server integration","status":"closed","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:30:09.780803041+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T20:39:54.221848283+03:00","closed_at":"2026-02-04T20:39:54.221848283+03:00","close_reason":"All 14 History Server validation scenarios created: jupyter, airflow, mlflow combinations"}
{"id":"spark_k8s-tlu","title":"WS-014-06: Container security (8 scenarios)","description":"8 container security test scenarios for hardening.\n\n- Non-root user validation (runAsUser \u003e 0)\n- No privilege escalation\n- Read-only root filesystem\n- Dropped capabilities\n\nScope: MEDIUM (~700 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:29.842421974+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:29.842421974+03:00","dependencies":[{"issue_id":"spark_k8s-tlu","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:36.972056368+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-uiu","title":"WS-013-04: Comparison load (4 scenarios)","description":"4 comparison scenarios (3.5.8 vs 4.1.1) for performance regression detection.\n\n- Same queries run on both versions\n- Performance comparison report generated\n- No significant regressions (\u003e 20% slowdown)\n- Both versions stable under load\n- 30 minutes per version per scenario\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T01:18:06.901233758+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T01:18:06.901233758+03:00","dependencies":[{"issue_id":"spark_k8s-uiu","depends_on_id":"spark_k8s-47g","type":"blocks","created_at":"2026-02-04T01:18:22.22949911+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ux1","title":"F28: Troubleshooting Wizard","description":"Interactive troubleshooting decision tree web tool. User selects symptoms → wizard suggests fixes based on 27+ recipes. Embedded in docs, deploy as standalone tool. GitHub Codespaces integration for hands-on debugging.","notes":"See docs/plans/2026-02-04-product-branding-strategy.md Phase 3. Content cascade from issues → interactive format.","status":"open","priority":2,"issue_type":"feature","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T15:24:14.70160775+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:24:14.70160775+03:00"}
{"id":"spark_k8s-ux1.1","title":"WS-028-01: Wizard backend design","description":"Design troubleshooting wizard backend. Decision tree data structure from 27+ recipes. Symptom → diagnosis → resolution flow. JSON schema for wizard data. REST API or static generation approach.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:26.817872165+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:26.817872165+03:00","dependencies":[{"issue_id":"spark_k8s-ux1.1","depends_on_id":"spark_k8s-ux1","type":"parent-child","created_at":"2026-02-04T15:26:26.818943658+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ux1.2","title":"WS-028-02: Frontend implementation","description":"Build web-based troubleshooting wizard. Progressive question flow. Auto-advance based on answers. Show relevant recipe at end. Copy-paste ready solutions. Mobile-responsive design. Deploy to GitHub Pages.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":240,"created_at":"2026-02-04T15:26:27.040769472+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:27.040769472+03:00","dependencies":[{"issue_id":"spark_k8s-ux1.2","depends_on_id":"spark_k8s-ux1","type":"parent-child","created_at":"2026-02-04T15:26:27.041868557+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ux1.2","depends_on_id":"spark_k8s-ux1.3","type":"blocks","created_at":"2026-02-04T15:38:40.995659241+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ux1.3","title":"WS-028-03: Recipe data conversion","description":"Convert 27+ troubleshooting recipes to wizard format. Extract symptoms, diagnosis steps, resolution commands. Tag with Spark version, K8s distribution, error patterns. Create decision tree for each recipe.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":180,"created_at":"2026-02-04T15:26:27.275266669+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:27.275266669+03:00","dependencies":[{"issue_id":"spark_k8s-ux1.3","depends_on_id":"spark_k8s-ux1","type":"parent-child","created_at":"2026-02-04T15:26:27.2764463+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ux1.3","depends_on_id":"spark_k8s-ux1.1","type":"blocks","created_at":"2026-02-04T15:37:43.763458092+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ux1.4","title":"WS-028-04: Integration with docs","description":"Embed wizard in documentation site. Add to troubleshooting section. Link from error messages. Interactive widget in README preview. Docs as code: wizard data in repo.","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":90,"created_at":"2026-02-04T15:26:27.494983849+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:27.494983849+03:00","dependencies":[{"issue_id":"spark_k8s-ux1.4","depends_on_id":"spark_k8s-ux1","type":"parent-child","created_at":"2026-02-04T15:26:27.496186603+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ux1.4","depends_on_id":"spark_k8s-ux1.2","type":"blocks","created_at":"2026-02-04T15:37:44.208747159+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ux1.5","title":"WS-028-05: GitHub Codespaces template","description":"Create Codespaces template for hands-on debugging. Pre-configured environment with kubectl, helm, spark-client. Troubleshooting scripts pre-loaded. One-click to debug real issues. Tutorial for using wizard in Codespaces.","status":"open","priority":3,"issue_type":"task","owner":"a_v_zhukov@outlook.com","estimated_minutes":120,"created_at":"2026-02-04T15:26:27.714707339+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T15:26:27.714707339+03:00","dependencies":[{"issue_id":"spark_k8s-ux1.5","depends_on_id":"spark_k8s-ux1","type":"parent-child","created_at":"2026-02-04T15:26:27.715828906+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ux1.5","depends_on_id":"spark_k8s-ux1.4","type":"blocks","created_at":"2026-02-04T15:37:44.437074359+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-w10","title":"Build Spark 3.5.7 from source with Hadoop 3.4.2 for AWS SDK v2 support","description":"Critical: Hadoop 3.3.x doesn't support AWS API v2. Must build Spark 3.5.7 from source with Hadoop 3.4.2 to enable BulkDelete and AWS SDK v2 bundle.","notes":"Built successfully with Hadoop 3.4.2 and AWS SDK v2. Kafka support requires additional work. Image: 6.44GB compressed to 2.67GB.","status":"closed","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:43:29.524597237+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T11:45:23.099046213+03:00","closed_at":"2026-02-04T11:45:23.099046213+03:00","close_reason":"Spark 3.5.7 successfully built from source with Hadoop 3.4.2 and AWS SDK v2. Image loaded to minikube. Commit: 12f4ef7"}
{"id":"spark_k8s-w8l","title":"WS-009-02: Python 3.10 base layer + test","description":"Create Python 3.10 base Docker image with unit tests and \u003c100MB target size.","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T00:42:02.519859315+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T00:42:02.519859315+03:00","dependencies":[{"issue_id":"spark_k8s-w8l","depends_on_id":"spark_k8s-nxo","type":"blocks","created_at":"2026-02-04T00:42:38.51660906+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-wge","title":"WS-016-02: Logging aggregation (Loki)","description":"Loki + Promtail for log aggregation.\n\n- Loki lightweight log storage\n- Promtail log collector from pods\n- JSON structured logging\n- Trace ID correlation\n- Log sampling: INFO 10%, ERROR/WARN 100%\n- Grafana datasource\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:46.320651466+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:46.320651466+03:00","dependencies":[{"issue_id":"spark_k8s-wge","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:03.174604052+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-wvm","title":"WS-015-02: Result aggregation","description":"Result aggregation framework for test results.\n\n- JSON aggregation (machine parsing)\n- JUnit XML generation (CI/CD integration)\n- HTML report (human review)\n- Partial failure handling\n- Summary statistics (pass/fail/skip)\n- Per-scenario timings\n\nScripts:\n- scripts/aggregate/aggregate_json.py\n- scripts/aggregate/aggregate_junit.py\n- scripts/aggregate/generate_html.py\n\nScope: MEDIUM (~600 LOC)","status":"open","priority":2,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:58:37.675111283+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:58:37.675111283+03:00","dependencies":[{"issue_id":"spark_k8s-wvm","depends_on_id":"spark_k8s-dyz","type":"blocks","created_at":"2026-02-04T10:58:45.752765951+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-wvm","depends_on_id":"spark_k8s-648","type":"blocks","created_at":"2026-02-04T10:58:46.183782708+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-ye4","title":"WS-016-05: Alerting rules","description":"AlertManager rules for Spark K8s.\n\n- AlertManager with Slack notifications\n- Critical: pod crash, OOM, app failed\n- Warning: high GC, slow queries, shuffle spill\n- Info: app completed\n- Alert inhibition (warning if critical)\n- 12h repeat interval\n\nScope: MEDIUM (~400 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T12:30:47.078072065+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T12:30:47.078072065+03:00","dependencies":[{"issue_id":"spark_k8s-ye4","depends_on_id":"spark_k8s-74z","type":"blocks","created_at":"2026-02-04T12:31:04.006655723+03:00","created_by":"Andrey Zhukov"},{"issue_id":"spark_k8s-ye4","depends_on_id":"spark_k8s-0su","type":"blocks","created_at":"2026-02-04T12:31:05.168445525+03:00","created_by":"Andrey Zhukov"}]}
{"id":"spark_k8s-zaa","title":"WS-014-02: SCC tests (12 scenarios)","description":"12 SCC (Security Context Constraints) test scenarios with mocked oc commands.\n\n- anyuid, nonroot, restricted-v2 SCC types\n- OpenShift compatibility validation\n- Mock oc commands (no real cluster needed)\n- All Spark versions compatible\n\nScope: MEDIUM (~900 LOC)","status":"open","priority":1,"issue_type":"task","owner":"a_v_zhukov@outlook.com","created_at":"2026-02-04T10:48:28.863629418+03:00","created_by":"Andrey Zhukov","updated_at":"2026-02-04T10:48:28.863629418+03:00","dependencies":[{"issue_id":"spark_k8s-zaa","depends_on_id":"spark_k8s-cy5","type":"blocks","created_at":"2026-02-04T10:48:36.097928036+03:00","created_by":"Andrey Zhukov"}]}
