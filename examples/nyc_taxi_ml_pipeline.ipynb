{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi ML Pipeline - Interactive Analysis\n",
    "\n",
    "## Using Spark Connect with Pandas API on Spark\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Connecting to Spark via Spark Connect\n",
    "2. Loading NYC TLC taxi data from MinIO\n",
    "3. Feature engineering with Pandas API on Spark\n",
    "4. Training CatBoost models per borough\n",
    "5. Generating 7-day revenue/trip predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install catboost plotly kafka-python --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ML imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Visualization\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "print(f\"PySpark version: {os.popen('pyspark --version 2>&1').read()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Spark Connect (Standalone backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Connect configuration\n",
    "CONNECT_HOST = os.environ.get(\"SPARK_CONNECT_HOST\", \"scenario1-spark-35-connect\")\n",
    "CONNECT_PORT = os.environ.get(\"SPARK_CONNECT_PORT\", \"15002\")\n",
    "CONNECT_URL = f\"sc://{CONNECT_HOST}:{CONNECT_PORT}\"\n",
    "\n",
    "# MinIO configuration\n",
    "MINIO_ENDPOINT = os.environ.get(\"S3_ENDPOINT\", \"http://minio.spark-infra.svc.cluster.local:9000\")\n",
    "MINIO_ACCESS_KEY = os.environ.get(\"AWS_ACCESS_KEY_ID\", \"minioadmin\")\n",
    "MINIO_SECRET_KEY = os.environ.get(\"AWS_SECRET_ACCESS_KEY\", \"minioadmin\")\n",
    "\n",
    "print(f\"Connecting to: {CONNECT_URL}\")\n",
    "print(f\"MinIO: {MINIO_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session via Spark Connect\n",
    "spark = SparkSession.builder \\\n",
    "    .remote(CONNECT_URL) \\\n",
    "    .appName(\"nyc-taxi-exploration\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", MINIO_ENDPOINT) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", MINIO_ACCESS_KEY) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", MINIO_SECRET_KEY) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark session created: {spark.sparkContext.applicationId}\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas API on Spark\n",
    "ps.set_option(\"compute.default_index_type\", \"distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw TLC data from MinIO\n",
    "raw_path = \"s3a://nyc-taxi/raw/*.parquet\"\n",
    "\n",
    "print(f\"Loading data from {raw_path}...\")\n",
    "df_raw = spark.read.parquet(raw_path)\n",
    "\n",
    "print(f\"Schema:\")\n",
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(f\"Total records: {df_raw.count():,}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df_raw.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality check\n",
    "df_clean = df_raw.filter(\n",
    "    (F.col(\"trip_distance\") > 0) &\n",
    "    (F.col(\"fare_amount\") > 0) &\n",
    "    (F.col(\"total_amount\") > 0) &\n",
    "    (F.col(\"tpep_pickup_datetime\") >= \"2023-01-01\") &\n",
    "    (F.col(\"tpep_pickup_datetime\") < \"2023-04-01\")\n",
    ")\n",
    "\n",
    "print(f\"Clean records: {df_clean.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily trip statistics\n",
    "daily_stats = df_clean \\\n",
    "    .withColumn(\"pickup_date\", F.to_date(\"tpep_pickup_datetime\")) \\\n",
    "    .groupBy(\"pickup_date\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"trip_count\"),\n",
    "        F.sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\")\n",
    "    ) \\\n",
    "    .orderBy(\"pickup_date\")\n",
    "\n",
    "daily_stats_pd = daily_stats.toPandas()\n",
    "daily_stats_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize daily trends\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_stats_pd['pickup_date'],\n",
    "    y=daily_stats_pd['trip_count'],\n",
    "    mode='lines',\n",
    "    name='Daily Trips'\n",
    "))\n",
    "fig.update_layout(\n",
    "    title='NYC Taxi Daily Trip Count (Jan-Mar 2023)',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Trip Count'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_temporal_features(df):\n",
    "    \"\"\"Add temporal features.\"\"\"\n",
    "    # US Holidays 2023\n",
    "    holidays = [\n",
    "        \"2023-01-01\", \"2023-01-16\", \"2023-02-20\", \"2023-05-29\", \"2023-06-19\",\n",
    "        \"2023-07-04\", \"2023-09-04\", \"2023-10-09\", \"2023-11-11\", \"2023-11-23\",\n",
    "        \"2023-12-25\"\n",
    "    ]\n",
    "\n",
    "    df = df \\\n",
    "        .withColumn(\"pickup_date\", F.to_date(\"tpep_pickup_datetime\")) \\\n",
    "        .withColumn(\"hour_of_day\", F.hour(\"tpep_pickup_datetime\")) \\\n",
    "        .withColumn(\"day_of_week\", F.dayofweek(\"tpep_pickup_datetime\")) \\\n",
    "        .withColumn(\"month\", F.month(\"tpep_pickup_datetime\")) \\\n",
    "        .withColumn(\"is_weekend\", F.when(F.col(\"day_of_week\").isin([1, 7]), 1).otherwise(0)) \\\n",
    "        .withColumn(\"is_rush_hour\", F.when(\n",
    "            (F.col(\"hour_of_day\").between(7, 9)) | (F.col(\"hour_of_day\").between(17, 19)), 1\n",
    "        ).otherwise(0)) \\\n",
    "        .withColumn(\"is_holiday\", F.when(F.col(\"pickup_date\").isin(holidays), 1).otherwise(0))\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_geospatial_features(df):\n",
    "    \"\"\"Add geospatial features.\"\"\"\n",
    "    # Simplified borough mapping\n",
    "    df = df.withColumn(\"pickup_borough\",\n",
    "        F.when(F.col(\"PULocationID\").between(1, 10), \"Staten Island\")\n",
    "         .when(F.col(\"PULocationID\").between(11, 50), \"Brooklyn\")\n",
    "         .when(F.col(\"PULocationID\").between(51, 150), \"Queens\")\n",
    "         .when(F.col(\"PULocationID\").between(151, 220), \"Manhattan\")\n",
    "         .when(F.col(\"PULocationID\").between(221, 265), \"Bronx\")\n",
    "         .otherwise(\"Unknown\"))\n",
    "\n",
    "    # Trip duration\n",
    "    df = df.withColumn(\"trip_duration\",\n",
    "        (F.unix_timestamp(\"tpep_dropoff_datetime\") - F.unix_timestamp(\"tpep_pickup_datetime\")) / 60)\n",
    "\n",
    "    # Average speed\n",
    "    df = df.withColumn(\"avg_speed\",\n",
    "        F.when(F.col(\"trip_duration\") > 0,\n",
    "               F.col(\"trip_distance\") / (F.col(\"trip_duration\") / 60))\n",
    "         .otherwise(0))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply features\n",
    "df_features = add_temporal_features(df_clean)\n",
    "df_features = add_geospatial_features(df_features)\n",
    "\n",
    "print(\"Features added:\")\n",
    "df_features.select(\n",
    "    \"pickup_date\", \"hour_of_day\", \"day_of_week\", \"is_weekend\", \"is_rush_hour\",\n",
    "    \"pickup_borough\", \"trip_distance\", \"trip_duration\", \"avg_speed\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to daily by borough for ML\n",
    "daily_borough = df_features \\\n",
    "    .groupBy(\"pickup_date\", \"pickup_borough\") \\\n",
    "    .agg(\n",
    "        F.sum(\"total_amount\").alias(\"daily_revenue\"),\n",
    "        F.count(\"*\").alias(\"daily_trips\"),\n",
    "        F.avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        F.avg(\"trip_duration\").alias(\"avg_duration\"),\n",
    "        F.sum(\"is_weekend\").alias(\"is_weekend\"),\n",
    "        F.sum(\"is_holiday\").alias(\"is_holiday\")\n",
    "    ) \\\n",
    "    .orderBy(\"pickup_date\", \"pickup_borough\")\n",
    "\n",
    "daily_borough_pd = daily_borough.toPandas()\n",
    "print(f\"Daily borough aggregates: {len(daily_borough_pd)} rows\")\n",
    "daily_borough_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training (CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for training\n",
    "# Create 7-day ahead targets\n",
    "daily_borough_pd = daily_borough_pd.sort_values(['pickup_borough', 'pickup_date'])\n",
    "\n",
    "# Shift for targets (7-day sum)\n",
    "for borough in daily_borough_pd['pickup_borough'].unique():\n",
    "    mask = daily_borough_pd['pickup_borough'] == borough\n",
    "    daily_borough_pd.loc[mask, 'revenue_7d_ahead'] = daily_borough_pd.loc[mask, 'daily_revenue'].shift(-7).rolling(7, min_periods=1).sum()\n",
    "    daily_borough_pd.loc[mask, 'trips_7d_ahead'] = daily_borough_pd.loc[mask, 'daily_trips'].shift(-7).rolling(7, min_periods=1).sum()\n",
    "\n",
    "# Drop rows with NaN targets\n",
    "daily_borough_pd = daily_borough_pd.dropna()\n",
    "\n",
    "print(f\"Training data: {len(daily_borough_pd)} rows\")\n",
    "daily_borough_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature columns\n",
    "feature_cols = ['daily_revenue', 'daily_trips', 'avg_distance', 'avg_duration', 'is_weekend', 'is_holiday']\n",
    "\n",
    "# Train models for each borough\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "for borough in ['Manhattan', 'Brooklyn', 'Queens']:\n",
    "    print(f\"\\nTraining models for {borough}...\")\n",
    "    \n",
    "    borough_data = daily_borough_pd[daily_borough_pd['pickup_borough'] == borough].copy()\n",
    "    \n",
    "    if len(borough_data) < 20:\n",
    "        print(f\"  Skipping {borough} - insufficient data\")\n",
    "        continue\n",
    "    \n",
    "    X = borough_data[feature_cols]\n",
    "    y_revenue = borough_data['revenue_7d_ahead']\n",
    "    y_trips = borough_data['trips_7d_ahead']\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_rev_train, y_rev_test, y_trip_train, y_trip_test = train_test_split(\n",
    "        X, y_revenue, y_trips, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train revenue model\n",
    "    model_revenue = CatBoostRegressor(\n",
    "        iterations=500,\n",
    "        depth=6,\n",
    "        learning_rate=0.05,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False\n",
    "    )\n",
    "    model_revenue.fit(X_train, y_rev_train, eval_set=(X_test, y_rev_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Train trips model\n",
    "    model_trips = CatBoostRegressor(\n",
    "        iterations=500,\n",
    "        depth=6,\n",
    "        learning_rate=0.05,\n",
    "        loss_function='RMSE',\n",
    "        verbose=False\n",
    "    )\n",
    "    model_trips.fit(X_train, y_trip_train, eval_set=(X_test, y_trip_test), early_stopping_rounds=50, verbose=False)\n",
    "    \n",
    "    # Evaluate\n",
    "    pred_revenue = model_revenue.predict(X_test)\n",
    "    pred_trips = model_trips.predict(X_test)\n",
    "    \n",
    "    mape_rev = mean_absolute_percentage_error(y_rev_test, pred_revenue)\n",
    "    mape_trips = mean_absolute_percentage_error(y_trip_test, pred_trips)\n",
    "    rmse_rev = np.sqrt(mean_squared_error(y_rev_test, pred_revenue))\n",
    "    rmse_trips = np.sqrt(mean_squared_error(y_trip_test, pred_trips))\n",
    "    \n",
    "    print(f\"  Revenue - MAPE: {mape_rev:.4f}, RMSE: {rmse_rev:.2f}\")\n",
    "    print(f\"  Trips   - MAPE: {mape_trips:.4f}, RMSE: {rmse_trips:.2f}\")\n",
    "    \n",
    "    models[borough] = {\n",
    "        'revenue': model_revenue,\n",
    "        'trips': model_trips\n",
    "    }\n",
    "    \n",
    "    results.append({\n",
    "        'borough': borough,\n",
    "        'mape_revenue': mape_rev,\n",
    "        'mape_trips': mape_trips,\n",
    "        'rmse_revenue': rmse_rev,\n",
    "        'rmse_trips': rmse_trips\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if 'Manhattan' in models:\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance_revenue': models['Manhattan']['revenue'].feature_importances_,\n",
    "        'importance_trips': models['Manhattan']['trips'].feature_importances_\n",
    "    })\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='Revenue Model', x=importance_df['feature'], y=importance_df['importance_revenue']),\n",
    "        go.Bar(name='Trips Model', x=importance_df['feature'], y=importance_df['importance_trips'])\n",
    "    ])\n",
    "    fig.update_layout(\n",
    "        title='Feature Importance (Manhattan)',\n",
    "        barmode='group'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate 7-Day Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecast for next 7 days\n",
    "forecast_dates = pd.date_range(start=datetime.now(), periods=7, freq='D')\n",
    "\n",
    "forecasts = []\n",
    "for borough, borough_models in models.items():\n",
    "    # Use latest day's features for prediction\n",
    "    latest = daily_borough_pd[daily_borough_pd['pickup_borough'] == borough].iloc[-1]\n",
    "    X_forecast = latest[feature_cols].values.reshape(1, -1)\n",
    "    \n",
    "    for i, forecast_date in enumerate(forecast_dates):\n",
    "        pred_revenue = borough_models['revenue'].predict(X_forecast)[0]\n",
    "        pred_trips = borough_models['trips'].predict(X_forecast)[0]\n",
    "        \n",
    "        forecasts.append({\n",
    "            'forecast_date': forecast_date.strftime('%Y-%m-%d'),\n",
    "            'borough': borough,\n",
    "            'predicted_revenue': pred_revenue * (1 + i * 0.02),  # Simple trend\n",
    "            'predicted_trips': pred_trips * (1 + i * 0.01)\n",
    "        })\n",
    "\n",
    "forecasts_df = pd.DataFrame(forecasts)\n",
    "forecasts_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize forecast\n",
    "fig = px.bar(\n",
    "    forecasts_df,\n",
    "    x='forecast_date',\n",
    "    y='predicted_revenue',\n",
    "    color='borough',\n",
    "    barmode='group',\n",
    "    title='7-Day Revenue Forecast by Borough'\n",
    ")\n",
    "fig.update_layout(xaxis_title='Date', yaxis_title='Predicted Revenue ($)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results to MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save forecasts to MinIO\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=MINIO_ACCESS_KEY,\n",
    "    aws_secret_access_key=MINIO_SECRET_KEY\n",
    ")\n",
    "\n",
    "# Save forecasts as CSV\n",
    "csv_buffer = forecasts_df.to_csv(index=False)\n",
    "s3.put_object(\n",
    "    Bucket='nyc-taxi',\n",
    "    Key='predictions/notebook_forecast.csv',\n",
    "    Body=csv_buffer\n",
    ")\n",
    "print(\"Saved forecasts to s3a://nyc-taxi/predictions/notebook_forecast.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "import pickle\n",
    "\n",
    "for borough, borough_models in models.items():\n",
    "    model_bytes = pickle.dumps(borough_models)\n",
    "    s3.put_object(\n",
    "        Bucket='ml-models',\n",
    "        Key=f'taxi-predictor/notebook/{borough.lower().replace(\" \", \"_\")}.pkl',\n",
    "        Body=model_bytes\n",
    "    )\n",
    "    print(f\"Saved {borough} model to s3a://ml-models/taxi-predictor/notebook/{borough.lower()}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ✅ Connected to Spark via Spark Connect\n",
    "2. ✅ Loaded NYC TLC taxi data from MinIO (3 months)\n",
    "3. ✅ Created temporal and geospatial features\n",
    "4. ✅ Trained CatBoost models per borough\n",
    "5. ✅ Generated 7-day revenue/trip forecasts\n",
    "6. ✅ Saved predictions and models to MinIO\n",
    "\n",
    "### Next Steps\n",
    "- Load more data (full 2 years)\n",
    "- Add more features (weather, events)\n",
    "- Deploy models via Airflow DAG\n",
    "- Set up monitoring and retraining"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
